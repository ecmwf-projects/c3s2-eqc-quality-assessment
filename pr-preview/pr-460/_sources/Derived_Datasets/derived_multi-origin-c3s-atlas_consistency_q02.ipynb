{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f433151",
   "metadata": {
    "tags": []
   },
   "source": [
    "![logo](../../LogoLine_horizon_C3S.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb08c23",
   "metadata": {
    "tags": [
     "disclaimer"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Consistency between the dataset underpinning the Copernicus Interactive Climate Atlas and its origins: Multiple indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "\n",
    "Production date: DD-MM-YYYY\n",
    "\n",
    "Dataset version: 2.0.\n",
    "\n",
    "Produced by: C3S2_521 contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üåç Use case: Retrieving climate indicators from the Copernicus Interactive Climate Atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ‚ùì Quality assessment question\n",
    "* **Are the climate indicators in the dataset underpinning the Copernicus Interactive Climate Atlas consistent with their origin datasets?**\n",
    "* **Can the dataset underpinning the Copernicus Interactive Climate Atlas be reproduced from its origin datasets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "The [_Copernicus Interactive Climate Atlas_](https://atlas.climate.copernicus.eu/atlas), or _Atlas_ for short, is a C3S web application providing an easy-to-access tool for exploring climate projections, reanalyses, and observational data [[Guti24](https://doi.org/10.21957/ah52ufc369)].\n",
    "Version 2.0 of the application allows the user to interact with 12 datasets:\n",
    "\n",
    "| Type               | Dataset       |\n",
    "|--------------------|---------------|\n",
    "| Climate Projection | CMIP6         |\n",
    "| Climate Projection | CMIP5         |\n",
    "| Climate Projection | CORDEX-CORE   |\n",
    "| Climate Projection | CORDEX-EUR-11 |\n",
    "| Reanalysis         | ERA5          |\n",
    "| Reanalysis         | ERA5-Land     |\n",
    "| Reanalysis         | ORAS5         |\n",
    "| Reanalysis         | CERRA         |\n",
    "| Observations       | E-OBS         |\n",
    "| Observations       | BERKEARTH     |\n",
    "| Observations       | CPC           |\n",
    "| Observations       | SST-CCI       |\n",
    "\n",
    "These datasets are provided through an intermediary dataset, the [_Gridded dataset underpinning the Copernicus Interactive Climate Atlas_](https://doi.org/10.24381/cds.h35hb680) or _Atlas dataset_ for short [[AtlasData](https://doi.org/10.24381/cds.h35hb680)].\n",
    "Compared to their origins, the versions of the climate datasets within the Atlas dataset have been processed following the workflow in Figure {numref}`{number} <multi-origin-c3s-atlas_consistency_q02_workflow-fig>`.\n",
    "\n",
    "```{figure} atlas_dataset_workflow.png\n",
    "---\n",
    "height: 360px\n",
    "name: multi-origin-c3s-atlas_consistency_q02_workflow-fig\n",
    "---\n",
    "Schematic representation of the workflow for the production of the Atlas dataset from its origin datasets, from the [User-tools for the C3S Atlas](https://ecmwf-projects.github.io/c3s-atlas/chapter01.html).\n",
    "```\n",
    "\n",
    "Because a wide range of users interact with climate data through the Atlas application, it is crucial that the underpinning dataset represent its origins correctly.\n",
    "In other words, the Atlas dataset must be consistent with and reproducible from its origins.\n",
    "Here, we assess this consistency and reproducibility by comparing climate indicators retrieved from the Atlas dataset with their equivalents calculated from the origin dataset, mirroring the workflow from Figure {numref}`{number} <multi-origin-c3s-atlas_consistency_q02_workflow-fig>`.\n",
    "While a full analysis and reproduction of every record within the Atlas dataset is outside the scope of quality assessment\n",
    "(and would require high-performance computing infrastructure),\n",
    "a case study with a narrower scope probes these quality attributes of the dataset\n",
    "and can be a jumping-off point for further analysis by the reader.\n",
    "\n",
    "This notebook is part of a series:\n",
    "| Notebook | Contents |\n",
    "|---|---|\n",
    "| [](./derived_multi-origin-c3s-atlas_consistency_q01) | Comparison between Atlas dataset and one origin dataset (CMIP6) for one indicator (`tx35`), including detailed setup. |\n",
    "| [](./derived_multi-origin-c3s-atlas_consistency_q02) | Comparison between Atlas dataset and one origin dataset (CMIP6) for multiple indicators. |\n",
    "| [](./derived_multi-origin-c3s-atlas_consistency_q03) | Comparison between Atlas dataset and multiple origin datasets for one indicator. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üì¢ Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Finding 1: will be a statement on the findings regarding the consistency \n",
    "* Finding 2\n",
    "* Finding 3\n",
    "* etc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üìã Methodology\n",
    "This quality assessment tests the consistency between climate indicators retrieved from the [_Gridded dataset underpinning the Copernicus Interactive Climate Atlas_](https://doi.org/10.24381/cds.h35hb680) [[AtlasData](https://doi.org/10.24381/cds.h35hb680)] and their equivalents calculated from the origin datasets,\n",
    "as well as the reproducibility of said dataset.\n",
    "\n",
    "This notebook expands the analysis set out in [the case study](./derived_multi-origin-c3s-atlas_consistency_q01)\n",
    "to investigate multiple indicators\n",
    "(listed below, descriptions from the [User-tools for the C3S Atlas](https://ecmwf-projects.github.io/c3s-atlas/chapter01.html))\n",
    "derived from the CMIP6 multi-model ensemble [[CMIP6data](https://doi.org/10.24381/cds.c866074c)]:\n",
    "\n",
    "| Indicator | Unit | Full description |\n",
    "|-----------|------|------------------|\n",
    "| `t`       | ¬∞C   | Monthly mean of daily mean near-surface (2-metre) air temperature |\n",
    "| `tn`      | ¬∞C   | Monthly mean of daily minimum near-surface (2-metre) air temperature |\n",
    "| `tx`      | ¬∞C   | Monthly mean of daily maximum near-surface (2-metre) air temperature |\n",
    "| `dtr`     | ¬∞C   | Monthly mean of near-surface (2-metre) air temperature difference between the maximum and minimum daily temperature |\n",
    "| `tnn`     | ¬∞C   | Monthly minimum of daily minimum near-surface (2-metre) air temperature |\n",
    "| `txx`     | ¬∞C   | Monthly maximum of daily maximum near-surface (2-metre) air temperature |\n",
    "| `tx35`    | d    | Monthly count of days with maximum near-surface (2-metre) temperature above 35 ¬∞C |\n",
    "| `tx40`    | d    | Monthly count of days with maximum near-surface (2-metre) temperature above 40 ¬∞C |\n",
    "| `tr`      | d    | Monthly count of tropical nights (days with minimum temperature above 20 ¬∞C) |\n",
    "| `fd`      | d    | Monthly count of days with minimum near-surface (2-metre) temperature below 0 ¬∞C |\n",
    "| `r`       | mm   | Monthly mean of daily accumulated precipitation of liquid water equivalent from all phases |\n",
    "| `sdii`    | mm   | Monthly average of daily precipitation amount of liquid water equivalent from all phases on days with precipitation amount above or equal to 1 mm |\n",
    "| `prsn`    | mm   | Monthly mean of daily accumulated liquid water equivalent thickness snowfall |\n",
    "| `rx1day`  | mm   | Monthly maximum of 1-day accumulated precipitation of liquid water equivalent from all phases |\n",
    "| `r01`     | d    | Monthly count of days with daily accumulated precipitation of liquid water equivalent from all phases above 1 mm |\n",
    "| `r10`     | d    | Monthly count of days with daily accumulated precipitation of liquid water equivalent from all phases above 10 mm |\n",
    "| `r20`     | d    | Monthly count of days with daily accumulated precipitation of liquid water equivalent from all phases above 20 mm |\n",
    "| `pet`     | mm   | Monthly mean daily accumulated potential evapotranspiration (Hargreaves method, 1985), which is the rate at which evapotranspiration would occur under ambient conditions from a uniformly vegetated area when the water supply is not limiting |\n",
    "| `evspsbl` | mm   | Monthly mean of daily amount of water in the atmosphere due to conversion of both liquid and solid phases to vapor (from underlying surface and vegetation) |\n",
    "| `huss`    | g/kg | Monthly amount of moisture in the air near the surface divided by amount of air plus moisture at that location |\n",
    "| `mrsos`   | kg/m¬≤| Monthly soil shallow moisture content, as the vertical sum per unit area of water in all phases contained in the upper soil portion to a depth of 7 to 10 cm (depending on the dataset) |\n",
    "| `mrro`    | mm   | Monthly mean of daily amount per unit area of surface and subsurface liquid water which drains from land |\n",
    "| `psl`     | hPa  | Monthly average air pressure at mean sea level |\n",
    "| `sfcwind` | m/s  | Monthly mean of daily mean near-surface (10-metre) wind speed |\n",
    "| `clt`     | %    | Monthly mean cloud cover area percentage |\n",
    "| `rsds`    | W/m¬≤ | Monthly mean incident solar (shortwave) radiation that reaches a horizontal plane at the surface |\n",
    "| `rlds`    | W/m¬≤ | Monthly mean incident thermal (longwave) radiation at the surface (during cloudless and overcast conditions) |\n",
    "<!--\n",
    "| `cdd`     | d    | Annual maximum of consecutive days when daily accumulated precipitation amount is below 1 mm |\n",
    "| `hd`      | ¬∞C d | Annual energy consumption to heat the deficit of temperature below 15.5 ¬∞C |\n",
    "| `cd`      | ¬∞C d | Annual energy consumption to cool the excess of temperature above 22 ¬∞C |\n",
    "-->\n",
    "<!--\n",
    "| `rx5day`  | mm   | Monthly maximum of 5-day accumulated precipitation of liquid water equivalent from all phases |\n",
    "| `spi6`    | ‚Äî    | Monthly index that compares accumulated precipitation for 6 months with the long-term precipitation distribution for the same location and accumulation period, as the number of standard deviations from the mean. The reference period corresponds to 1971-2010. |\n",
    "| `spei6`   | ‚Äî    | Monthly index that compares accumulated precipitation minus potential evapotranspiration (Hargreaves method, 1985) for 6 months with the long-term distribution for the same location and accumulation period, as the number of standard deviations from the mean. The reference period corresponds to 1971-2010.\n",
    "-->\n",
    "\n",
    "The analysis and results are organised in the following steps, which are detailed in the sections below:\n",
    "\n",
    "**[](derived_multi-origin-c3s-atlas_consistency_q02:section-codesetup)**\n",
    " * Install User-tools for the C3S Atlas.\n",
    " * Import all required libraries.\n",
    " * Definition of helper functions.\n",
    "\n",
    "**[](derived_multi-origin-c3s-atlas_consistency_q02:section-origin)**\n",
    " * Download data from the origin dataset(s).\n",
    " * Homogenise data.\n",
    " * Calculate indicator(s).\n",
    " * Interpolate to a common and regular grid.\n",
    "\n",
    "**[](derived_multi-origin-c3s-atlas_consistency_q02:section-atlas)**\n",
    " * Download data from the Atlas dataset.\n",
    "\n",
    "**[](derived_multi-origin-c3s-atlas_consistency_q02:section-results)**\n",
    " * Consistency: Compare the Atlas and reproduced datasets on native grids.\n",
    " * Reproducibility: Compare the Atlas and reproduced datasets on the Atlas grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üìà Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(derived_multi-origin-c3s-atlas_consistency_q02:section-codesetup)=\n",
    "### 1. Code setup\n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for \n",
    "downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data)) \n",
    "and visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data.\n",
    "Because earthkit is in active development, some functionality may change after this notebook is published.\n",
    "If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Install the User-tools for the C3S Atlas\n",
    "This notebook uses the [User-tools for the C3S Atlas](https://github.com/ecmwf-projects/c3s-atlas), which can be installed from GitHub using `pip`.\n",
    "For convenience, the following cell can do this from within the notebook.\n",
    "Further details and alternative options for installing this library are available in its [documentation](https://github.com/ecmwf-projects/c3s-atlas?tab=readme-ov-file#requirements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ecmwf-projects/c3s-atlas.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import required libraries\n",
    "In this section, we import all the relevant packages needed for running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Input / Output\n",
    "from pathlib import Path\n",
    "import earthkit.data as ekd\n",
    "import warnings\n",
    "\n",
    "# General data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "from dask.array.core import PerformanceWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=PerformanceWarning)\n",
    "\n",
    "# Data pre-processing\n",
    "from c3s_atlas.fixers import apply_fixers\n",
    "import c3s_atlas.interpolation as xesmfCICA\n",
    "\n",
    "# Climate indicators\n",
    "import xclim\n",
    "xclim.set_options(cf_compliance=\"log\")  # Mute warnings\n",
    "import c3s_atlas.indexes\n",
    "\n",
    "# Fix for bug affecting sfcWind units\n",
    "from c3s_atlas.units import VALID_UNITS\n",
    "VALID_UNITS[\"sfcWind\"] = r\"(m s-1|m s\\^-1|m/s)\"\n",
    "\n",
    "# Visualisation\n",
    "import earthkit.plots as ekp\n",
    "from earthkit.plots.styles import Style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "from tqdm import tqdm  # Progress bars\n",
    "\n",
    "# Visualisation in Jupyter book -- automatically ignored otherwise\n",
    "try:\n",
    "    from myst_nb import glue\n",
    "except ImportError:\n",
    "    glue = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Daily data -> Monthly indicators\n",
    "def cal_t(ds):\n",
    "    \"\"\" Monthly mean of daily mean near-surface (2-metre) air temperature \"\"\"\n",
    "    ds_t = ds['tas'].resample(time='MS').mean().to_dataset(name='t')\n",
    "    return ds_t\n",
    "\n",
    "def cal_tn(ds):\n",
    "    \"\"\" Monthly mean of daily minimum near-surface (2-metre) air temperature \"\"\"\n",
    "    ds_tn = ds['tasmin'].resample(time='MS').mean().to_dataset(name='tn')\n",
    "    return ds_tn \n",
    "\n",
    "def cal_tx(ds):\n",
    "    \"\"\" Monthly mean of daily maximum near-surface (2-metre) air temperature \"\"\"\n",
    "    ds_tx = ds['tasmax'].resample(time='MS').mean().to_dataset(name='tx')\n",
    "    return ds_tx\n",
    "\n",
    "def cal_tnn(ds):\n",
    "    \"\"\" Monthly minimum of daily minimum near-surface (2-metre) air temperature \"\"\"\n",
    "    ds_tnn = ds['tasmin'].resample(time='MS').min().to_dataset(name='tnn')\n",
    "    return ds_tnn\n",
    "    \n",
    "def cal_txx(ds):\n",
    "    \"\"\" Monthly maximum of daily maximum near-surface (2-metre) air temperature \"\"\"\n",
    "    ds_txx = ds['tasmax'].resample(time='MS').max().to_dataset(name='txx')\n",
    "    return ds_txx\n",
    "\n",
    "def cal_tx35(ds):\n",
    "    \"\"\" Monthly count of days with maximum near-surface (2-metre) temperature above 35 ¬∞C \"\"\"\n",
    "    ds_tx35 = xclim.indices.tx_days_above(ds['tasmax'], thresh='35.0 degC', freq='MS', op='>').to_dataset(name='tx35')\n",
    "    return ds_tx35\n",
    "\n",
    "def cal_tx40(ds):\n",
    "    \"\"\" Monthly count of days with maximum near-surface (2-metre) temperature above 40 ¬∞C \"\"\"\n",
    "    ds_tx40 = xclim.indices.tx_days_above(ds['tasmax'], thresh='40.0 degC', freq='MS', op='>').to_dataset(name='tx40')\n",
    "    return ds_tx40\n",
    "\n",
    "def cal_tr(ds):\n",
    "    \"\"\" Monthly count of tropical nights (days with minimum temperature above 20 degC) \"\"\"\n",
    "    ds_tr = xclim.indicators.atmos.tropical_nights(ds['tasmin'], thresh='20.0 degC', freq='MS', op='>').to_dataset(name='tr')\n",
    "    return ds_tr\n",
    "\n",
    "def cal_dtr(ds):\n",
    "    \"\"\" Monthly mean of near-surface (2-metre) air temperature difference between the maximum and minimum daily temperature \"\"\"\n",
    "    ds_dtr = xclim.indices.daily_temperature_range(ds['tasmin'], ds['tasmax'], freq='MS', op='mean').to_dataset(name='dtr')\n",
    "    return ds_dtr\n",
    "\n",
    "def cal_fd(ds):\n",
    "    \"\"\" Monthly count of days with minimum near-surface (2-metre) temperature below 0 ¬∞C \"\"\"\n",
    "    ds_fd = xclim.indicators.atmos.frost_days(ds['tasmin'], thresh='0 degC', freq='MS').to_dataset(name='fd')\n",
    "    return ds_fd   \n",
    "\n",
    "def cal_r(ds):\n",
    "    \"\"\" Monthly mean of daily accumulated precipitation of liquid water equivalent from all phases \"\"\"\n",
    "    ds_r = ds['pr'].resample(time='MS').mean().to_dataset(name='r')\n",
    "    return ds_r\n",
    "\n",
    "def cal_r01(ds):\n",
    "    \"\"\" Monthly count of days with daily accumulated precipitation of liquid water equivalent from all phases above 1 mm \"\"\"\n",
    "    pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "    per0 = xr.zeros_like(pr_flux).assign_attrs(units='mm/day')\n",
    "    ds_r01 = xclim.indices.days_over_precip_thresh(pr_flux, per0, thresh='1 mm/day', freq='MS', bootstrap=False, op='>').to_dataset(name='r01')\n",
    "    return ds_r01\n",
    "\n",
    "def cal_sdii(ds):\n",
    "    \"\"\" Monthly average of daily precipitation amount of liquid water equivalent from all phases on days with precipitation amount above or equal to 1 mm \"\"\"\n",
    "    pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "    ds_sdii = xclim.indicators.atmos.daily_pr_intensity(pr_flux, thresh='1 mm/day', freq='MS', op='>=').to_dataset(name='sdii')\n",
    "    return ds_sdii\n",
    "\n",
    "def cal_r10(ds):  \n",
    "    \"\"\" Monthly count of days with daily accumulated precipitation of liquid water equivalent from all phases above 10 mm \"\"\"\n",
    "    pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "    per0 = xr.zeros_like(pr_flux).assign_attrs(units='mm/day')\n",
    "    ds_r10 = xclim.indices.days_over_precip_thresh(pr_flux, per0, thresh='10 mm/day', freq='MS', bootstrap=False, op='>').to_dataset(name='r10')\n",
    "    return ds_r10\n",
    "\n",
    "def cal_r20(ds):\n",
    "    \"\"\" Monthly count of days with daily accumulated precipitation of liquid water equivalent from all phases above 20 mm \"\"\"\n",
    "    pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "    per0 = xr.zeros_like(pr_flux).assign_attrs(units='mm/day')\n",
    "    ds_r20 = xclim.indices.days_over_precip_thresh(pr_flux, per0, thresh='20 mm/day', freq='MS', bootstrap=False, op='>').to_dataset(name='r20')\n",
    "    return ds_r20\n",
    "\n",
    "def cal_rx1day(ds):\n",
    "    \"\"\" Monthly maximum of 1-day accumulated precipitation of liquid water equivalent from all phases \"\"\"\n",
    "    pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "    ds_rx1day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr_flux, window=1, freq='MS').to_dataset(name='rx1day')\n",
    "    return ds_rx1day\n",
    "\n",
    "# def cal_rx5day(ds):\n",
    "#     \"\"\" Monthly maximum of 5-day accumulated precipitation of liquid water equivalent from all phases \"\"\"\n",
    "#     pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "#     ds_rx5day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr_flux, window=5, freq='MS').to_dataset(name='rx5day')\n",
    "#     return ds_rx5day\n",
    "\n",
    "# def cal_spi6(ds):\n",
    "#     \"\"\" Monthly index that compares accumulated precipitation for 6 months with the long-term precipitation distribution for the same location and accumulation period, as the number of standard deviations from the mean. The reference period corresponds to 1971-2010 \"\"\"\n",
    "#     pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "#     ds_spi6 = xclim.indices.standardized_precipitation_index(pr_flux, freq='MS', window=6, dist='gamma', method='ML').to_dataset(name='spi6')\n",
    "#     return ds_spi6\n",
    "\n",
    "# def cal_spei6(ds):\n",
    "#      \"\"\" Monthly index that compares accumulated precipitation minus potential evapotranspiration (Hargreaves method, 1985) for 6 months with the long-term distribution for the same location and accumulation period, as the number of standard deviations from the mean. The reference period corresponds to 1971-2010 \"\"\"\n",
    "#     pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "#     ds_spei6 = xclim.indices.standardized_precipitation_index(pr_flux, freq='MS', window=6, dist='gamma', method='ML').to_dataset(name='spei6')\n",
    "#     return ds_spei6\n",
    "\n",
    "def cal_pet(ds):\n",
    "    \"\"\" Monthly mean daily accumulated potential evapotranspiration (Hargreaves method, 1985), which is the rate at which evapotranspiration would occur under ambient conditions from a uniformly vegetated area when the water supply is not limiting \"\"\"\n",
    "    ds_pet = xclim.indices.potential_evapotranspiration(ds['tasmin'], ds['tasmax'], method='HG85').resample(time='MS').mean().to_dataset(name='pet')\n",
    "    # Convert to mm (assuming kg water /m¬≤ = mm)\n",
    "    ds_pet[\"pet\"] *= 86400\n",
    "    ds_pet[\"pet\"] = ds_pet[\"pet\"].assign_attrs({\"units\": \"mm\"})\n",
    "    return ds_pet\n",
    "\n",
    "def cal_huss(ds):\n",
    "    \"\"\" Monthly amount of moisture in the air near the surface divided by amount of air plus moisture at that location \"\"\"\n",
    "    ds_huss = ds['huss'].resample(time='MS').mean().to_dataset(name='huss')\n",
    "    # Convert to g/kg\n",
    "    ds_huss[\"huss\"] *= 1000\n",
    "    ds_huss[\"huss\"] = ds_huss[\"huss\"].assign_attrs({\"units\": \"gr kg-1\"})\n",
    "    return ds_huss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Monthly data -> Monthly indicators\n",
    "def cal_evspsbl(ds):\n",
    "    \"\"\" Monthly mean of daily amount of water in the atmosphere due to conversion of both liquid and solid phases to vapor (from underlying surface and vegetation) \"\"\"\n",
    "    ds_evspsbl = ds['evspsbl'].resample(time='MS').mean().to_dataset(name='evspsbl')\n",
    "    return ds_evspsbl\n",
    "\n",
    "def cal_mrsos(ds):\n",
    "    \"\"\" Monthly soil shallow moisture content, as the vertical sum per unit area of water in all phases contained in the upper soil portion to a depth of 7 to 10 cm (depending on the dataset) \"\"\"\n",
    "    ds_mrsos = ds['mrsos'].resample(time='MS').mean().to_dataset(name='mrsos')\n",
    "    return ds_mrsos\n",
    "\n",
    "def cal_mrro(ds):\n",
    "    \"\"\" Monthly mean of daily amount per unit area of surface and subsurface liquid water which drains from land \"\"\"\n",
    "    ds_mrro = ds['mrro'].resample(time='MS').mean().to_dataset(name='mrro')\n",
    "    return ds_mrro\n",
    "\n",
    "def cal_prsn(ds):\n",
    "    \"\"\" Monthly mean of daily accumulated liquid water equivalent thickness snowfall \"\"\"\n",
    "    ds_prsn = ds['prsn'].resample(time='MS').mean().to_dataset(name='prsn')\n",
    "    return ds_prsn\n",
    "\n",
    "def cal_sfcwind(ds):\n",
    "    \"\"\" Monthly mean of daily mean near-surface (10-metre) wind speed \"\"\"\n",
    "    ds_sfcwind = ds['sfcWind'].resample(time='MS').mean().to_dataset(name='sfcwind')\n",
    "    return ds_sfcwind\n",
    "\n",
    "def cal_clt(ds):\n",
    "    \"\"\" Monthly mean cloud cover area percentage \"\"\"\n",
    "    ds_clt = ds['clt'].resample(time='MS').mean().to_dataset(name='clt')\n",
    "    return ds_clt\n",
    "\n",
    "def cal_rsds(ds):\n",
    "    \"\"\" Monthly mean incident solar (shortwave) radiation that reaches a horizontal plane at the surface \"\"\"\n",
    "    ds_rsds = ds['rsds'].resample(time='MS').mean().to_dataset(name='rsds')\n",
    "    return ds_rsds\n",
    "\n",
    "def cal_rlds(ds):\n",
    "    \"\"\" Monthly mean incident thermal (longwave) radiation at the surface (during cloudless and overcast conditions) \"\"\"\n",
    "    ds_rlds = ds['rlds'].resample(time='MS').mean().to_dataset(name='rlds')\n",
    "    return ds_rlds\n",
    "\n",
    "def cal_psl(ds):\n",
    "    \"\"\" Monthly average air pressure at mean sea level \"\"\"\n",
    "    ds_psl = ds['psl'].resample(time='MS').mean().to_dataset(name='psl')\n",
    "    # Convert to hPa\n",
    "    ds_psl[\"psl\"] /= 100\n",
    "    ds_psl[\"psl\"] = ds_psl[\"psl\"].assign_attrs({\"units\": \"hPa\"})\n",
    "    return ds_psl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Daily data -> Yearly indicators\n",
    "def cal_cdd(ds):\n",
    "    \"\"\" Annual maximum of consecutive days when daily accumulated precipitation amount is below 1 mm \"\"\"\n",
    "    pr_flux = ds['pr'].copy().assign_attrs(units = 'mm/day')\n",
    "    ds_cdd = xclim.indicators.atmos.maximum_consecutive_dry_days(pr_flux, thresh='1 mm/day', freq='YS', resample_before_rl=True).to_dataset(name='cdd')\n",
    "    return ds_cdd\n",
    "\n",
    "def cal_hd(ds):\n",
    "    \"\"\" Annual energy consumption to heat the deficit of temperature below 15.5 ¬∞C \"\"\"\n",
    "    ds_hd = c3s_atlas.indexes.heating_degree_days(ds['tas'], ds['tasmax'], ds['tasmin'], freq='YS', thresh=15.5).to_dataset(name='hd')\n",
    "    return ds_hd\n",
    "\n",
    "def cal_cd(ds):\n",
    "    \"\"\" Annual energy consumption to cool the excess of temperature above 22 ¬∞C \"\"\"\n",
    "    ds_cd = c3s_atlas.indexes.cooling_degree_days(ds['tas'], ds['tasmax'], ds['tasmin'], freq='YS', thresh=22).to_dataset(name='cd')\n",
    "    return ds_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Combine functions into dictionaries for easy access by name\n",
    "indicators_daily2monthly = {\n",
    "    \"t\": cal_t,\n",
    "    \"tn\": cal_tn,\n",
    "    \"tx\": cal_tx,\n",
    "    \"dtr\": cal_dtr,\n",
    "    \"tnn\": cal_tnn,\n",
    "    \"txx\": cal_txx,\n",
    "    \"tx35\": cal_tx35,\n",
    "    \"tx40\": cal_tx40,\n",
    "    \"tr\": cal_tr,\n",
    "    \"fd\": cal_fd,\n",
    "    \"r\": cal_r,\n",
    "    \"sdii\": cal_sdii,\n",
    "    \"rx1day\": cal_rx1day,\n",
    "    \"r01\": cal_r01,\n",
    "    \"r10\": cal_r10,\n",
    "    \"r20\": cal_r20,\n",
    "    # \"rx5day\": cal_rx5day,\n",
    "    # \"spi6\": cal_spi6,\n",
    "    # \"spei6\": cal_spei6,\n",
    "    \"pet\": cal_pet,\n",
    "    \"huss\": cal_huss,\n",
    "}\n",
    "\n",
    "indicators_monthly2monthly = {\n",
    "    \"prsn\": cal_prsn,\n",
    "    \"evspsbl\": cal_evspsbl,\n",
    "    \"mrsos\": cal_mrsos,\n",
    "    \"mrro\": cal_mrro,\n",
    "    \"psl\": cal_psl,\n",
    "    \"sfcwind\": cal_sfcwind,\n",
    "    \"clt\": cal_clt,\n",
    "    \"rsds\": cal_rsds,\n",
    "    \"rlds\": cal_rlds,\n",
    "}\n",
    "\n",
    "indicators_daily2annual = {\n",
    "    \"cdd\": cal_cdd,\n",
    "    \"hd\": cal_hd,\n",
    "    \"cd\": cal_cd,\n",
    "}\n",
    "\n",
    "# Easier access in loops\n",
    "indicators_monthly = indicators_daily2monthly | indicators_monthly2monthly\n",
    "indicators_annual  = indicators_daily2annual\n",
    "indicators         = indicators_daily2monthly | indicators_monthly2monthly | indicators_daily2annual\n",
    "\n",
    "# Hard-code monthly indicator names to match table in intro\n",
    "indicators_monthly_names = [\n",
    "    \"t\", \"tn\", \"tx\", \"dtr\", \"tnn\", \"txx\", \"tx35\", \"tx40\", \"tr\", \"fd\",\n",
    "    \"r\", \"sdii\", \"prsn\", \"rx1day\", \"r01\", \"r10\", \"r20\",\n",
    "    # \"rx5day\",\n",
    "    # \"spi6\",\n",
    "    # \"spei6\",\n",
    "    \"pet\", \"evspsbl\",\n",
    "    \"huss\",\n",
    "    \"mrsos\",\n",
    "    \"mrro\",\n",
    "    \"psl\", \"sfcwind\",\n",
    "    \"clt\",\n",
    "    \"rsds\", \"rlds\",\n",
    "]\n",
    "# indicators_monthly_names = list(indicators_monthly.keys())\n",
    "indicators_annual_names  = list(indicators_annual.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Styles for indicators\n",
    "n_diff = 5  # Levels in difference charts\n",
    "\n",
    "_style_monthly_days      = {\"vmin\": 0,     \"vmax\": 30,    \"extend\": \"neither\"}\n",
    "_style_monthly_days_diff = {\"vmin\": -2.5,  \"vmax\": 2.5,   \"extend\": \"both\"}\n",
    "_style_annual_days       = {\"vmin\": 0,     \"vmax\": 366,   \"extend\": \"neither\"}\n",
    "_style_annual_days_diff  = {\"vmin\": -7,    \"vmax\": 7,     \"extend\": \"both\"}\n",
    "_style_degreedays        = {\"vmin\": 0,     \"vmax\": 20000, \"extend\": \"max\"}\n",
    "_style_degreedays_diff   = {\"vmin\": -5000, \"vmax\": 5000,  \"extend\": \"both\"}\n",
    "\n",
    "# Temperature\n",
    "_style_t        = {\"cmap\": plt.cm.YlOrBr.resampled(10),   \"vmin\": -5, \"vmax\": 45, \"extend\": \"both\"}\n",
    "_style_t_diff   = {\"cmap\": plt.cm.RdBu.resampled(n_diff), \"vmin\": -2, \"vmax\": 2,  \"extend\": \"both\"}\n",
    "_style_dtr      = _style_t | {\"vmin\": 0, \"vmax\": 20}\n",
    "_style_dtr_diff = _style_t_diff\n",
    "\n",
    "# Temperature day indices\n",
    "_style_tx35      = _style_monthly_days      | {\"cmap\": plt.cm.Oranges.resampled(10)}\n",
    "_style_tx35_diff = _style_monthly_days_diff | {\"cmap\": plt.cm.RdBu_r.resampled(n_diff)}\n",
    "_style_fd        = _style_monthly_days      | {\"cmap\": plt.cm.Blues.resampled(10)}\n",
    "_style_fd_diff   = _style_monthly_days_diff | {\"cmap\": plt.cm.RdBu.resampled(n_diff)}\n",
    "\n",
    "# Precipitation\n",
    "_style_r           = {\"cmap\": plt.cm.GnBu.resampled(10),     \"vmin\": 0,  \"vmax\": 30, \"extend\": \"max\"}\n",
    "_style_r_diff      = {\"cmap\": plt.cm.BrBG.resampled(n_diff), \"vmin\": -2, \"vmax\": 2,  \"extend\": \"both\"}\n",
    "_style_rx1day      = _style_r                 |             {\"vmax\": 200}\n",
    "_style_rx1day_diff = _style_r_diff            | {\"vmin\": -5, \"vmax\": 5}\n",
    "_style_r01         = _style_monthly_days      | {\"cmap\": plt.cm.Blues.resampled(10)}\n",
    "_style_r01_diff    = _style_monthly_days_diff | {\"cmap\": plt.cm.RdBu.resampled(n_diff)}\n",
    "_style_cdd         = _style_annual_days       | {\"cmap\": plt.cm.Oranges.resampled(10)}\n",
    "\n",
    "# Evapotranspiration\n",
    "_style_pet          = {\"cmap\": plt.cm.GnBu.resampled(8),      \"vmin\": 0,  \"vmax\": 8, \"extend\": \"max\"}\n",
    "_style_pet_diff     = {\"cmap\": plt.cm.BrBG.resampled(n_diff), \"vmin\": -3, \"vmax\": 3, \"extend\": \"both\"}\n",
    "_style_evspsbl      = _style_pet      |             {\"vmax\": 16}\n",
    "_style_evspsbl_diff = _style_pet_diff | {\"vmin\": -6, \"vmax\": 6}\n",
    "\n",
    "# Humidity\n",
    "_style_huss      = {\"cmap\": plt.cm.GnBu.resampled(10),     \"vmin\": 0,  \"vmax\": 30, \"extend\": \"max\"}\n",
    "_style_huss_diff = {\"cmap\": plt.cm.BrBG.resampled(n_diff), \"vmin\": -5, \"vmax\": 5,  \"extend\": \"both\"}\n",
    "\n",
    "# Soil moisture\n",
    "_style_mrsos      = {\"cmap\": plt.cm.YlGn.resampled(8),      \"vmin\": 0,  \"vmax\": 80, \"extend\": \"max\"}\n",
    "_style_mrsos_diff = {\"cmap\": plt.cm.BrBG.resampled(n_diff), \"vmin\": -5, \"vmax\": 5,  \"extend\": \"both\"}\n",
    "_style_mrro       = {\"cmap\": plt.cm.YlGn.resampled(8),      \"vmin\": -5, \"vmax\": 75, \"extend\": \"both\"}\n",
    "_style_mrro_diff  = {\"cmap\": plt.cm.BrBG.resampled(n_diff), \"vmin\": -2, \"vmax\": 2,  \"extend\": \"both\"}\n",
    "\n",
    "# General meteorology\n",
    "_style_sfcwind      = {\"cmap\": plt.cm.Purples.resampled(8),   \"vmin\": 0,    \"vmax\": 16,   \"extend\": \"max\"}\n",
    "_style_sfcwind_diff = {\"cmap\": plt.cm.PuOr.resampled(n_diff), \"vmin\": -1.5, \"vmax\": 1.5,  \"extend\": \"both\"}\n",
    "_style_clt          = {\"cmap\": plt.cm.Greys.resampled(10),    \"vmin\": 0,    \"vmax\": 100,  \"extend\": \"neither\"}\n",
    "_style_clt_diff     = {\"cmap\": plt.cm.RdBu.resampled(n_diff), \"vmin\": -2.5, \"vmax\": 2.5,  \"extend\": \"both\"}\n",
    "_style_psl          = {\"cmap\": plt.cm.RdBu_r.resampled(10),   \"vmin\": 983,  \"vmax\": 1043, \"extend\": \"neither\"}\n",
    "_style_psl_diff     = {\"cmap\": plt.cm.RdBu.resampled(n_diff), \"vmin\": -15,  \"vmax\": 15,   \"extend\": \"both\"}\n",
    "\n",
    "# Irradiation\n",
    "_style_rsds      = {\"cmap\": plt.cm.YlOrRd.resampled(10),   \"vmin\": 0,  \"vmax\": 500, \"extend\": \"max\"}\n",
    "_style_rsds_diff = {\"cmap\": plt.cm.RdBu.resampled(n_diff), \"vmin\": -5, \"vmax\": 5,   \"extend\": \"both\"}\n",
    "\n",
    "# Degree days\n",
    "_style_hd      = _style_degreedays      | {\"cmap\": plt.cm.Reds.resampled(10)}\n",
    "_style_hd_diff = _style_degreedays_diff | {\"cmap\": plt.cm.RdBu.resampled(n_diff)}\n",
    "_style_cd      = _style_degreedays      | {\"cmap\": plt.cm.Blues.resampled(10)}\n",
    "_style_cd_diff = _style_degreedays_diff | {\"cmap\": plt.cm.RdBu_r.resampled(n_diff)}\n",
    "\n",
    "# Individual styles\n",
    "# Set up like this so they can still be edited individually\n",
    "styles = {\n",
    "    \"t\": Style(**_style_t),             \"t_diff\": Style(**_style_t_diff),\n",
    "    \"tn\": Style(**_style_t),            \"tn_diff\": Style(**_style_t_diff),\n",
    "    \"tx\": Style(**_style_t),            \"tx_diff\": Style(**_style_t_diff),\n",
    "    \"tnn\": Style(**_style_t),           \"tnn_diff\": Style(**_style_t_diff),\n",
    "    \"txx\": Style(**_style_t),           \"txx_diff\": Style(**_style_t_diff),\n",
    "    \"dtr\": Style(**_style_dtr),         \"dtr_diff\": Style(**_style_dtr_diff),\n",
    "    \"tx35\": Style(**_style_tx35),       \"tx35_diff\": Style(**_style_tx35_diff),\n",
    "    \"tx40\": Style(**_style_tx35),       \"tx40_diff\": Style(**_style_tx35_diff),\n",
    "    \"tr\": Style(**_style_tx35),         \"tr_diff\": Style(**_style_tx35_diff),\n",
    "    \"fd\": Style(**_style_fd),           \"fd_diff\": Style(**_style_fd_diff),\n",
    "    \"r\": Style(**_style_r),             \"r_diff\": Style(**_style_r_diff),\n",
    "    \"sdii\": Style(**_style_r),          \"sdii_diff\": Style(**_style_r_diff),\n",
    "    \"prsn\": Style(**_style_r),          \"prsn_diff\": Style(**_style_r_diff),\n",
    "    \"rx1day\": Style(**_style_rx1day),   \"rx1day_diff\": Style(**_style_rx1day_diff),\n",
    "    \"r01\": Style(**_style_r01),         \"r01_diff\": Style(**_style_r01_diff),\n",
    "    \"r10\": Style(**_style_r01),         \"r10_diff\": Style(**_style_r01_diff),\n",
    "    \"r20\": Style(**_style_r01),         \"r20_diff\": Style(**_style_r01_diff),\n",
    "    \"cdd\": Style(**_style_cdd),         \"cdd_diff\": Style(**_style_r01_diff),\n",
    "    # \"rx5day\": Style(),\n",
    "    # \"spi6\": Style(),\n",
    "    # \"spei6\": Style(),\n",
    "    \"pet\": Style(**_style_pet),         \"pet_diff\": Style(**_style_pet_diff),\n",
    "    \"evspsbl\": Style(**_style_evspsbl), \"evspsbl_diff\": Style(**_style_evspsbl_diff),\n",
    "    \"huss\": Style(**_style_huss),       \"huss_diff\": Style(**_style_huss_diff),\n",
    "    \"mrsos\": Style(**_style_mrsos),     \"mrsos_diff\": Style(**_style_mrsos_diff),\n",
    "    \"mrro\": Style(**_style_mrro),       \"mrro_diff\": Style(**_style_mrro_diff),\n",
    "    \"sfcwind\": Style(**_style_sfcwind), \"sfcwind_diff\": Style(**_style_sfcwind_diff),\n",
    "    \"clt\": Style(**_style_clt),         \"clt_diff\": Style(**_style_clt_diff),\n",
    "    \"psl\": Style(**_style_psl),         \"psl_diff\": Style(**_style_psl_diff),\n",
    "    \"rsds\": Style(**_style_rsds),       \"rsds_diff\": Style(**_style_rsds_diff),\n",
    "    \"rlds\": Style(**_style_rsds),       \"rlds_diff\": Style(**_style_rsds_diff),\n",
    "    \"hd\": Style(**_style_hd),           \"hd_diff\": Style(**_style_hd_diff),\n",
    "    \"cd\": Style(**_style_cd),           \"cd_diff\": Style(**_style_cd_diff),\n",
    "}\n",
    "\n",
    "# Apply general settings\n",
    "for style in styles.values():\n",
    "    style.normalize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Type hints\n",
    "from typing import Iterable, Optional\n",
    "from earthkit.plots.geo.domains import Domain\n",
    "AnyDomain = (Domain | str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Create requests for multiple daily / monthly variables\n",
    "def create_requests_for_variables(main_request: dict, variables: Iterable[str]) -> list[dict]:\n",
    "    \"\"\" Given a `main_request` (e.g. experiment / model / year / ...), add an entry `variable: var` for every var. \"\"\"\n",
    "    requests_for_variables = [{\"variable\": var} for var in variables]\n",
    "    requests = [(main_request | req) for req in requests_for_variables]\n",
    "    return requests\n",
    "\n",
    "# Drop \"bnds\" variables which can mess with merge later on\n",
    "def drop_bnds(data: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Remove any \"bnds\" variables from a dataset \"\"\"\n",
    "    bnds = [var for var in data.data_vars if var.endswith(\"_bnds\")]\n",
    "    data = data.drop_vars(bnds)\n",
    "    return data\n",
    "\n",
    "# Download multiple variables at once\n",
    "def download_multiple_variables(dataset_id: str, *requests: dict, coordinate_decimals: int=4) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Download multiple variables from the same dataset.\n",
    "    Force-rounds the coordinates to `coordinate_decimals` to prevent floating-point errors\n",
    "        which otherwise cause misalignment between variables.\n",
    "    The current implementation requires data to be downloaded in series, not parallel.\n",
    "    \"\"\"\n",
    "    # Download individual variables\n",
    "    ds_all = [ekd.from_source(\"cds\", dataset_id, request) for request in requests]\n",
    "    data = [ds.to_xarray() for ds in ds_all]\n",
    "\n",
    "    # Drop bnds\n",
    "    data = [drop_bnds(d) for d in data]\n",
    "\n",
    "    # Round coordinates\n",
    "    round_mapping = {\"lat\": (lambda dataset: dataset[\"lat\"].round(coordinate_decimals)),\n",
    "                     \"lon\": (lambda dataset: dataset[\"lon\"].round(coordinate_decimals))}\n",
    "    data_rounded = [d.assign_coords(round_mapping) for d in data]\n",
    "\n",
    "    # Stack data\n",
    "    data_combined = xr.merge(data_rounded, compat=\"equals\")\n",
    "    \n",
    "    return data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Select (multiple) years in a dataset\n",
    "def select_years_in_dataset(data: xr.Dataset, years: list[int]) -> xr.Dataset:\n",
    "    \"\"\" Select only data for the given year(s). \"\"\"\n",
    "    years_int = [int(y) for y in years]\n",
    "    return data.sel(time=data.time.dt.year.isin(years_int))\n",
    "\n",
    "# Select one month in multiple datasets\n",
    "def select_month_in_multiple_datasets(*data: xr.Dataset, month: int=8) -> list[xr.Dataset]:\n",
    "    \"\"\" Select only data for the given month, in any year. \"\"\"\n",
    "    data_month = [d.groupby(\"time.month\")[month] for d in data]\n",
    "    return data_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Atlas dataset: Individual model selection\n",
    "def select_model_from_atlas_dataset(data: xr.Dataset, model: str) -> xr.Dataset:\n",
    "    \"\"\" Select only data for the given model. \"\"\"\n",
    "    # Ensure the model ID is provided in the right format\n",
    "    model_id = model.replace(\"_\", \"-\")\n",
    "\n",
    "    # Find the corresponding model ID in the list of models\n",
    "    # This cannot use .sel because the coordinate is not indexed\n",
    "    select_member = [str(mem) for mem in data.member_id.values if model_id in mem.lower()][0]\n",
    "\n",
    "    # Find the corresponding data and return those\n",
    "    member_ind = np.where(data.member_id == select_member)[0]\n",
    "    data_member = data.sel(member=member_ind).squeeze(\"member\")\n",
    "\n",
    "    return data_member\n",
    "\n",
    "# Atlas dataset: Download all data, pulling out years and model members of interest\n",
    "def _download_atlas_single(request: dict, years: Iterable[int | str], model: str) -> xr.Dataset:\n",
    "    \"\"\" Helper function for download_atlas_data_oneyear_onemember; download and process a single Atlas request. \"\"\"\n",
    "    # Download data\n",
    "    ATLAS_ID = \"multi-origin-c3s-atlas\"\n",
    "    ds = ekd.from_source(\"cds\", ATLAS_ID, request)\n",
    "    data = ds.to_xarray(compat=\"equals\")\n",
    "\n",
    "    # Drop \"bnds\" variables which can mess with merge later on\n",
    "    data = drop_bnds(data)\n",
    "\n",
    "    # Pick out member\n",
    "    data = select_model_from_atlas_dataset(data, model)\n",
    "\n",
    "    # Pick out years\n",
    "    data = select_years_in_dataset(data, years)\n",
    "\n",
    "    return data\n",
    "\n",
    "def download_atlas_data_onemember(requests: Iterable[dict], years: Iterable[int | str], model: str) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Download data from the Atlas dataset, picking out only the year(s) and model member of interest.\n",
    "    Works in series rather than in parallel, so much slower than a regular earthkit-data download,\n",
    "    but prevents memory issues from loading several decades and members at once.\n",
    "    \"\"\"\n",
    "    data_combined = [_download_atlas_single(req, years, model) for req in requests]\n",
    "    data_combined = xr.merge(data_combined, compat=\"equals\")\n",
    "    return data_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Calculation of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculation of multiple indicators\n",
    "def calculate_indicators_daily2monthly(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Calculate all daily -> monthly indicators and return consolidated dataset. \"\"\"\n",
    "    ds_indicators = xr.merge([func(ds) for name, func in indicators_daily2monthly.items()], compat=\"no_conflicts\")\n",
    "    return ds_indicators\n",
    "\n",
    "def calculate_indicators_monthly2monthly(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Calculate all monthly -> monthly indicators and return consolidated dataset. \"\"\"\n",
    "    ds_indicators = xr.merge([func(ds) for name, func in indicators_monthly2monthly.items()], compat=\"no_conflicts\")\n",
    "    return ds_indicators\n",
    "\n",
    "def calculate_indicators_monthly(ds_daily: xr.Dataset, ds_monthly: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Calculate all daily/monthly -> monthly indicators and return consolidated dataset. \"\"\"\n",
    "    with warnings.catch_warnings(action=\"ignore\"):  # Catch repetitive warning from dask\n",
    "        ds_daily2monthly   = calculate_indicators_daily2monthly(ds_daily)\n",
    "        ds_monthly2monthly = calculate_indicators_monthly2monthly(ds_monthly)\n",
    "        \n",
    "    ds_indicators = xr.merge([ds_daily2monthly, ds_monthly2monthly], compat=\"no_conflicts\", join=\"outer\")\n",
    "    return ds_indicators\n",
    "\n",
    "def calculate_indicators_annual(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Calculate all daily -> annual indicators and return consolidated dataset. \"\"\"\n",
    "    with warnings.catch_warnings(action=\"ignore\"):  # Catch repetitive divide-by-zero warning\n",
    "        ds_indicators = xr.merge([func(ds) for name, func in indicators_daily2annual.items()], compat=\"no_conflicts\")\n",
    "\n",
    "    return ds_indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Data (pre-)processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Homogenisation of origin dataset\n",
    "def homogenise(ds: xr.Dataset, var_name: str, project_id: str) -> xr.Dataset:\n",
    "    \"\"\" Homogenise a dataset `ds` for one variable `var_name` \"\"\"\n",
    "    var_mapping = {\n",
    "                \"dataset_variable\": {var_name: \"data\"},\n",
    "                \"aggregation\": {\"data\": \"mean\"},\n",
    "        }\n",
    "    data = apply_fixers(ds, var_name, project_id, var_mapping)\n",
    "    return data\n",
    "\n",
    "def homogenise_multiple_variables(ds: xr.Dataset, variable_names: Iterable[str], project_id: str) -> xr.Dataset:\n",
    "    \"\"\" Apply the homogenise function across multiple variables `variable_names` in a dataset `ds` \"\"\" \n",
    "    homogenised_data = [homogenise(ds, var_name, project_id) for var_name in variable_names]\n",
    "    homogenised_dataset = xr.merge(homogenised_data, compat=\"no_conflicts\")\n",
    "    return homogenised_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Interpolation from native grid to Atlas grid\n",
    "# NOTE this only works for monthly not for annual\n",
    "def interpolate(ds: xr.Dataset, var_name: str) -> xr.Dataset:\n",
    "    \"\"\" Interpolate a dataset `ds` to the Atlas grid for one variable `var_name` \"\"\"\n",
    "    int_attr = {\"interpolation_method\": \"conservative_normed\", \n",
    "                \"lats\": np.arange(-89.5, 90.5, 1),\n",
    "                \"lons\": np.arange(-179.5, 180.5, 1),\n",
    "                \"var_name\": var_name,\n",
    "    }\n",
    "    INTER = xesmfCICA.Interpolator(int_attr)\n",
    "    ds_interp = INTER(ds)\n",
    "    return ds_interp\n",
    "\n",
    "\n",
    "def interpolate_multiple_variables(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Apply the interpolate function across all variables in a dataset \"\"\" \n",
    "    # Note: skipping rx5day due to window length error\n",
    "    variables = tqdm([var_name for var_name in list(ds.data_vars) if var_name != \"rx5day\"], desc=\"Interpolating variables\", leave=False)\n",
    "\n",
    "    # Ignore repeated warnings on [-90, 90] bounds\n",
    "    with warnings.catch_warnings(action=\"ignore\"):\n",
    "        data_interpolated = [interpolate(ds, var_name) for var_name in variables]\n",
    "    \n",
    "    dataset_interpolated = xr.merge(data_interpolated, compat=\"no_conflicts\")\n",
    "    return dataset_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "## Statistics\n",
    "# Difference between datasets\n",
    "def difference_between_datasets(data1: xr.Dataset, data2: xr.Dataset, diff_variables: Iterable[str]) -> xr.Dataset:\n",
    "    \"\"\" Calculate the difference between two datasets, preserving CRS and metadata. \"\"\"\n",
    "    # Subtract\n",
    "    data1, data2 = [d.drop_vars([\"lat_bnds\", \"lon_bnds\", \"time_bnds\", \"height\"], errors=\"ignore\") for d in (data1, data2)]\n",
    "    difference = xr.ufuncs.subtract(data1, data2)\n",
    "    return difference\n",
    "\n",
    "def relative_difference_between_datasets(data1: xr.Dataset, data2: xr.Dataset, reldiff_variables: Iterable[str]) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate the relative [%] difference between two datasets, preserving CRS and updating metadata.\n",
    "    Relative difference is calculated relative to the first dataset.\n",
    "    Where data1 == 0 and data2 == 0, the relative difference is set to 0 too.\n",
    "    \"\"\"\n",
    "    # Select and calculate\n",
    "    data1, data2 = [dataset.drop_vars([var for var in dataset.data_vars if var not in [*reldiff_variables, \"crs\"]]) \\\n",
    "                        for dataset in (data1, data2)]\n",
    "\n",
    "    relative_difference = (data1 - data2) / data1 * 100.\n",
    "\n",
    "    # Replace 0/0 with 0\n",
    "    data1_zero = (data1 <= 1e-5)  # Threshold slightly > 0 because of floating-point errors\n",
    "    relative_difference = relative_difference.where(~data1_zero, 0.)\n",
    "\n",
    "    # Add name\n",
    "    relative_difference = relative_difference.assign_attrs({\"name\": \"Atlas ‚Äì Reproduced [%]\"})\n",
    "\n",
    "    return relative_difference\n",
    "\n",
    "\n",
    "def comparison_statistics(dataset1: xr.Dataset, dataset2: xr.Dataset, indicator: str, *,\n",
    "                          reldiff_variables: Iterable[str]=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given two datasets, calculate a number of statistics for each variable and return the result in a table.\n",
    "    This version is hardcoded for one indicator in multiple years.\n",
    "    \"\"\"\n",
    "    # # If reldiff_variables is not specified explicitly, assume it is the same as diff_variables\n",
    "    # if reldiff_variables is None:\n",
    "    #     reldiff_variables = diff_variables\n",
    "\n",
    "    # Calculate differences\n",
    "    differences     =          difference_between_datasets(dataset1, dataset2, diff_variables=[indicator])\n",
    "    differences_rel = relative_difference_between_datasets(dataset1, dataset2, reldiff_variables=[indicator])\n",
    "\n",
    "    # Convert to pandas\n",
    "    differences = differences.to_dataframe()[diff_variables]\n",
    "    differences_abs = differences.abs()\n",
    "\n",
    "    differences_rel = differences_rel.to_dataframe()[reldiff_variables]\n",
    "    differences_rel_abs = differences_rel.abs()\n",
    "\n",
    "    # In this notebook: Group by year first\n",
    "    differences, differences_abs, differences_rel, differences_rel_abs = [\n",
    "        d.groupby(differences.index.get_level_values(\"time\").year) for d in\n",
    "        (differences, differences_abs, differences_rel, differences_rel_abs)\n",
    "    ]\n",
    "\n",
    "    # Calculate aggregate statistics\n",
    "    # TO DO: Add % |Œî| non-zero? (e.g. 1e-5)\n",
    "    md   =         differences.agg([\"mean\", \"median\"])  \\\n",
    "                              .rename(columns={\"median\": r\"Median Œî\", \"mean\": \"Mean Œî\"})\n",
    "    mad  =     differences_abs.agg([\"median\"])  \\\n",
    "                              .rename(columns={\"median\": r\"Median |Œî|\"})\n",
    "    mapd = differences_rel_abs.agg([\"median\"])  \\\n",
    "                              .rename(columns={\"median\": r\"Median |Œî| [%]\"})\n",
    "\n",
    "    # Calculate correlation coefficients\n",
    "    nr_years, data1_years, data2_years = _group_multiple_datasets_by_years(dataset1, dataset2)\n",
    "\n",
    "    \n",
    "    # Combine statistics into one dataframe\n",
    "    md, mad, mapd = [df.droplevel(0, axis=1) for df in (md, mad, mapd)]\n",
    "    stats = pd.concat([md, mad, mapd], axis=1)\n",
    "    # Adjust for case where diff != reldiff:\n",
    "    # stats = stats[diff_variables].T\n",
    "\n",
    "    return stats\n",
    "\n",
    "def display_difference_stats(dataset1: xr.Dataset, dataset2: xr.Dataset, **kwargs) -> str:\n",
    "    \"\"\" Given two datasets, calculate a number of statistics for each variable and display the result in a table. \"\"\"\n",
    "    comparison_stats = comparison_statistics(dataset1, dataset2, **kwargs)\n",
    "    comparison_stats = comparison_stats.droplevel(0, axis=1)\n",
    "    formatted = comparison_stats.style \\\n",
    "                                .format(precision=5)  \\\n",
    "                                .set_caption(\"Atlas ‚Äì Reproduced\")  \\\n",
    "                                # .relabel_index([label_with_unit(differences, var) for var in difference_stats.index])\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualisation: Helper functions, general\n",
    "def _glue_or_show(fig: plt.Figure, glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    If `glue` is available, glue the figure using the provided label.\n",
    "    If not, display the figure in the notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        glue(glue_label, fig, display=False)\n",
    "    except TypeError:\n",
    "        plt.show()\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def _add_textbox_to_subplots(text: str, *axs: Iterable[plt.Axes | ekp.Subplot], right=False) -> None:\n",
    "    \"\"\" Add a text box to each of the specified subplots. \"\"\"\n",
    "    # Get the plt.Axes for each ekp.Subplot\n",
    "    axs = [subplot.ax if isinstance(subplot, ekp.Subplot) else subplot for subplot in axs]\n",
    "\n",
    "    # Set up location\n",
    "    x = 0.95 if right else 0.05\n",
    "    horizontalalignment = \"right\" if right else \"left\"\n",
    "\n",
    "    # Add the text\n",
    "    for ax in axs:\n",
    "        ax.text(x, 0.95, text, transform=ax.transAxes,\n",
    "        horizontalalignment=horizontalalignment, verticalalignment=\"top\",\n",
    "        bbox={\"facecolor\": \"white\", \"edgecolor\": \"black\", \"boxstyle\": \"round\",\n",
    "              \"alpha\": 1})\n",
    "\n",
    "def _sharexy(axs: np.ndarray) -> None:\n",
    "    \"\"\" Force all of the axes in axs to share x and y with the first element. \"\"\"\n",
    "    main_ax = axs.ravel()[0]\n",
    "    for ax in axs.ravel():\n",
    "        ax.sharex(main_ax)\n",
    "        ax.sharey(main_ax)\n",
    "\n",
    "def _symmetric_xlim(ax: plt.Axes) -> None:\n",
    "    \"\"\" Adjust the xlims for one Axes to be symmetric, based on existing values. \"\"\"\n",
    "    current = ax.get_xlim()\n",
    "    current = np.abs(current)\n",
    "    maxlim = np.max(current)\n",
    "    newlim = (-maxlim, maxlim)\n",
    "\n",
    "    ax.set_xlim(newlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualisation: Helper functions for geospatial plots\n",
    "def _spatial_plot_append_subplots(fig: ekp.Figure, *data: xr.Dataset, domain: Optional[AnyDomain]=None, **kwargs) -> list[ekp.Subplot]:\n",
    "    \"\"\" Plot any number of datasets into new subplots in an existing earthkit figure. \"\"\"\n",
    "    # Create subplots\n",
    "    subplots = [fig.add_map(domain=domain) for d in data]\n",
    "\n",
    "    # Plot\n",
    "    for subplot, d in zip(subplots, data):\n",
    "        subplot.grid_cells(d, **kwargs)\n",
    "\n",
    "    return subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualisation: Plot indicators geospatially\n",
    "def geospatial_comparison_multiple_indicators(data1: xr.Dataset, data2: xr.Dataset, indicators: Iterable[str], month: int, *,\n",
    "                                              label1: str=\"Atlas dataset\", label2: str=\"Reproduced from origin\",\n",
    "                                              domain: Optional[str | Domain]=None) -> ekp.Figure:\n",
    "    \"\"\"\n",
    "    Plot a list of indicators in two datasets.\n",
    "    Assumes the data are from a single year.\n",
    "    A specific month has to be specified.\n",
    "        TO DO: glue\n",
    "    \"\"\"\n",
    "    # Pre-process: Select data in one month\n",
    "    data1_month, data2_month = select_month_in_multiple_datasets(data1, data2, month=month)\n",
    "\n",
    "    # Setup indicators\n",
    "    n_indicators = len(indicators)\n",
    "    loop_indicators = tqdm(indicators, desc=\"Plotting indicators\", leave=False)\n",
    "\n",
    "    # Create figure\n",
    "    fig = ekp.Figure(rows=n_indicators, columns=2, size=(7.5, 3*n_indicators))\n",
    "\n",
    "    # Plot indicators\n",
    "    for indicator in loop_indicators:\n",
    "        # Plot individual datasets\n",
    "        subplots_data = _spatial_plot_append_subplots(fig, data1_month, data2_month, domain=domain, \n",
    "                                                      z=indicator, style=styles[indicator])\n",
    "    \n",
    "        # Decorate: Text + Colour bar\n",
    "        # _add_textbox_to_subplots(year, *subplots_data)\n",
    "        subplots_data[-1].legend(label=indicator, location=\"right\")\n",
    "\n",
    "    # Titles on top\n",
    "    titles = [label1, label2]\n",
    "    for title, subplot in zip(titles, fig.subplots):\n",
    "        subplot.ax.set_title(title)\n",
    "\n",
    "    # Decorate figure\n",
    "    fig.land()\n",
    "    fig.coastlines()\n",
    "    fig.gridlines(linestyle=plt.rcParams[\"grid.linestyle\"])\n",
    "    \n",
    "    # Uncomment if running this notebook yourself:\n",
    "    # Show result\n",
    "    plt.show()\n",
    "\n",
    "    # TO DO: glue\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualisation: Plot indicators geospatially\n",
    "def geospatial_comparison_multiple_indicators_with_difference(data1: xr.Dataset, data2: xr.Dataset, indicators: Iterable[str], month: int, *,\n",
    "                                                              label1: str=\"Atlas dataset\", label2: str=\"Reproduced from origin\",\n",
    "                                                              domain: Optional[str | Domain]=None) -> ekp.Figure:\n",
    "    \"\"\"\n",
    "    Plot a list of indicators in two datasets.\n",
    "    Assumes the data are from a single year.\n",
    "    A specific month has to be specified.\n",
    "        TO DO: glue\n",
    "    \"\"\"\n",
    "    # Pre-process: Select data in one month, calculate difference\n",
    "    data1_month, data2_month = select_month_in_multiple_datasets(data1, data2, month=month)\n",
    "    difference = difference_between_datasets(data1_month, data2_month)\n",
    "\n",
    "    # Setup indicators\n",
    "    n_indicators = len(indicators)\n",
    "    loop_indicators = tqdm(indicators, desc=\"Plotting indicators\", leave=False)\n",
    "\n",
    "    # Create figure\n",
    "    fig = ekp.Figure(rows=n_indicators, columns=3, size=(7.5, 2*n_indicators))\n",
    "\n",
    "    # Plot indicators\n",
    "    for indicator in loop_indicators:\n",
    "        # Plot individual datasets\n",
    "        subplots_data = _spatial_plot_append_subplots(fig, data1_month, data2_month, domain=domain, \n",
    "                                                      z=indicator, style=styles[indicator])\n",
    "\n",
    "        # Plot difference\n",
    "        subplot_diff = fig.add_map(domain=domain)\n",
    "        subplot_diff.grid_cells(difference, z=indicator, style=styles[f\"{indicator}_diff\"])\n",
    "    \n",
    "        # Decorate: Text + Colour bar\n",
    "        subplots_data[0].legend(label=indicator, location=\"left\")\n",
    "        subplot_diff.legend(label=f\"Œî {indicator}\", location=\"right\")\n",
    "\n",
    "    # Titles on top\n",
    "    titles = [label1, label2, \"Difference\"]\n",
    "    for title, subplot in zip(titles, fig.subplots):\n",
    "        subplot.ax.set_title(title)\n",
    "\n",
    "    # Decorate figure\n",
    "    fig.land()\n",
    "    fig.coastlines()\n",
    "    fig.gridlines(linestyle=plt.rcParams[\"grid.linestyle\"])\n",
    "    \n",
    "    # Uncomment if running this notebook yourself:\n",
    "    # Show result\n",
    "    plt.show()\n",
    "\n",
    "    # TO DO: glue\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualisation: Plot data in histograms\n",
    "def histogram_comparison_by_indicator(data1: xr.Dataset, data2: xr.Dataset, indicators: Iterable[str], *,\n",
    "                                      label1: str=\"Atlas dataset\", label2: str=\"Reproduced from origin\") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a histogram for each indicator in two datasets.\n",
    "    Flattens all data in the datasets, including spatial and temporal dimensions.\n",
    "        TO DO: glue\n",
    "    \"\"\"\n",
    "    # Setup indicators\n",
    "    n_indicators = len(indicators)\n",
    "    loop_indicators = tqdm(indicators, desc=\"Plotting indicators\", leave=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(nrows=n_indicators, ncols=2, sharex=\"row\", sharey=\"row\",\n",
    "                            figsize=(5, 2*n_indicators), layout=\"constrained\", squeeze=False)\n",
    "    \n",
    "    # Plot histograms of data\n",
    "    # Loop over rows / indicators\n",
    "    for ax_row, indicator in zip(axs, loop_indicators):\n",
    "        # Loop over columns / data\n",
    "        for ax, data in zip(ax_row, (data1, data2)):\n",
    "            # Flatten data\n",
    "            d = data[indicator].values.ravel()\n",
    "\n",
    "            # Create histogram\n",
    "            ax.hist(d, bins=31, density=True, log=False, color=\"black\")\n",
    "    \n",
    "            # Labels\n",
    "            ax.grid(True, axis=\"both\")\n",
    "            ax.set_xlabel(indicator)\n",
    "    \n",
    "        ax_row[0].set_ylabel(\"Frequency\")\n",
    "        \n",
    "        # Identify panel\n",
    "        _add_textbox_to_subplots(indicator, *ax_row, right=True)\n",
    "    \n",
    "    # Titles on top\n",
    "    titles = [label1, label2]\n",
    "    for title, ax in zip(titles, axs[0]):\n",
    "        ax.set_title(title)\n",
    "        \n",
    "    # Uncomment if running this notebook yourself:\n",
    "    # Show result\n",
    "    plt.show()\n",
    "    \n",
    "    # TO DO: glue\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualisation: Plot data + difference in histograms\n",
    "def histogram_comparison_by_indicator_with_difference(data1: xr.Dataset, data2: xr.Dataset, indicators: Iterable[str], *,\n",
    "                                                      label1: str=\"Atlas dataset\", label2: str=\"Reproduced from origin\") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a histogram for each indicator in two datasets, including the point-by-point difference.\n",
    "    Flattens all data in the datasets, including spatial and temporal dimensions.\n",
    "        TO DO: glue\n",
    "    \"\"\"\n",
    "    # Setup indicators\n",
    "    n_indicators = len(indicators)\n",
    "    loop_indicators = tqdm(indicators, desc=\"Plotting indicators\", leave=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(nrows=n_indicators, ncols=3,\n",
    "                            figsize=(8, 2*n_indicators), layout=\"constrained\", squeeze=False)\n",
    "\n",
    "    # Setup x/y share -- cannot be done in plt.subplots because of difference panel not sharing these\n",
    "    for ax_row in axs:\n",
    "        _sharexy(ax_row[:-1])\n",
    "    \n",
    "    # Plot histograms of data\n",
    "    # Loop over rows / indicators\n",
    "    for ax_row, indicator in zip(axs, loop_indicators):\n",
    "        # Calculate difference\n",
    "        difference = difference_between_datasets(data1, data2)\n",
    "        \n",
    "        # Loop over columns / data\n",
    "        for ax, data in zip(ax_row, (data1, data2)):\n",
    "            # Flatten data\n",
    "            d = data[indicator].values.ravel()\n",
    "    \n",
    "            # Create histogram\n",
    "            ax.hist(d, bins=31, density=True, log=False, color=\"black\")\n",
    "\n",
    "            # Labels\n",
    "            ax.grid(True, axis=\"both\")\n",
    "            ax.set_xlabel(indicator)\n",
    "\n",
    "            # Plot difference\n",
    "            difference_here = difference[indicator].values.ravel()\n",
    "            ax_row[-1].hist(difference_here, bins=31, density=True, log=True, color=\"black\")\n",
    "    \n",
    "        ax_row[0].set_ylabel(\"Frequency\")\n",
    "        \n",
    "        # Identify panel\n",
    "        _add_textbox_to_subplots(indicator, *ax_row[:-1], right=True)\n",
    "        _add_textbox_to_subplots(f\"Œî {indicator}\", ax_row[-1], right=True)\n",
    "\n",
    "    for ax in axs[:, -1]:  # Symmetric xlims for difference\n",
    "        _symmetric_xlim(ax)\n",
    "    \n",
    "    # Titles on top\n",
    "    titles = [label1, label2, \"Difference\"]\n",
    "    for title, ax in zip(titles, axs[0]):\n",
    "        ax.set_title(title)\n",
    "        \n",
    "    # Uncomment if running this notebook yourself:\n",
    "    # Show result\n",
    "    plt.show()\n",
    "    \n",
    "    # TO DO: glue\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(derived_multi-origin-c3s-atlas_consistency_q02:section-origin)=\n",
    "### 2. Calculate indicators from the origin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Download data\n",
    "This notebook uses [earthkit-data](https://github.com/ecmwf/earthkit-data) to download files from the CDS.\n",
    "If you intend to run this notebook multiple times, it is highly recommended that you [enable caching](https://earthkit-data.readthedocs.io/en/latest/guide/caching.html) to prevent having to download the same files multiple times.\n",
    "\n",
    "The first step is to define the parameters that will be shared between the download of the origin dataset (here CMIP6) and the Atlas dataset (in the [next section](derived_multi-origin-c3s-atlas_consistency_q02:section-atlas)), namely the experiment and model member.\n",
    "Next, the request to download the corresponding data from CMIP6 is defined,\n",
    "in this notebook choosing several daily and monthly variables\n",
    "defined in the following cell.\n",
    "To simplify the data processing,\n",
    "daily and monthly variables are downloaded separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "ORIGIN_ID = \"projections-cmip6\"\n",
    "ORIGIN = \"cmip6\"  # Used in Atlas download; defined here to improve customisability\n",
    "EXPERIMENT = \"ssp5_8_5\"\n",
    "MODEL = \"cmcc_esm2\"\n",
    "\n",
    "YEARS = [\"2080\"]\n",
    "MONTHS = [f\"{month:02d}\" for month in range(1, 13)]\n",
    "DAYS = [f\"{day:02d}\" for day in range(1, 32)]\n",
    "\n",
    "VARIABLES_DAILY   = [\"tas\", \"tasmin\", \"tasmax\", \"pr\", \"huss\"]\n",
    "VARIABLES_MONTHLY = [\"evspsbl\", \"mrsos\", \"mrro\", \"prsn\", \"sfcWind\", \"clt\", \"rsds\", \"rlds\", \"psl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup: General request\n",
    "request_origin = {\n",
    "    \"experiment\": EXPERIMENT,\n",
    "    \"model\": MODEL,\n",
    "    \"year\": YEARS,\n",
    "    \"month\": MONTHS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Download CMIP6 daily data\n",
    "request_cmip6_daily = {\n",
    "    \"temporal_resolution\": \"daily\",\n",
    "    \"day\": DAYS,\n",
    "} | request_origin\n",
    "\n",
    "requests_cmip6_daily_variables = create_requests_for_variables(request_cmip6_daily, VARIABLES_DAILY)\n",
    "data_cmip6_daily = download_multiple_variables(ORIGIN_ID, *requests_cmip6_daily_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_cmip6_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Download CMIP6 monthly data\n",
    "request_cmip6_monthly = {\n",
    "    \"temporal_resolution\": \"monthly\",\n",
    "} | request_origin\n",
    "\n",
    "requests_cmip6_monthly_variables = create_requests_for_variables(request_cmip6_monthly, VARIABLES_MONTHLY)\n",
    "data_cmip6_monthly = download_multiple_variables(ORIGIN_ID, *requests_cmip6_monthly_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_cmip6_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Homogenise data\n",
    "One of the steps in the Atlas dataset production chain is homogenisation, i.e. ensuring consistency between data from different origin datasets.\n",
    "This homogenisation is implemented in the [User-tools for the C3S Atlas](https://github.com/ecmwf-projects/c3s-atlas/tree/main/c3s_atlas), specifically the `c3s_atlas.fixers.apply_fixers` function.\n",
    "The following changes are applied:\n",
    "\n",
    "- The names of the spatial coordinates are standardised to `[lon, lat]`.\n",
    "- Longitude is converted from `[0...360]` to `[-180...180]` format.\n",
    "- The time coordinate is standardised to the CF standard calendar.\n",
    "- Variable units are standardised (e.g. ¬∞C for temperature).\n",
    "- Variables are resampled / aggregated to the required temporal resolution.\n",
    "\n",
    "The homogenisation is applied in the following code cells, separately for the daily and monthly data.\n",
    "The `apply_fixers` function describes the different homogenisation steps as it applies them;\n",
    "this can be read by expanding the following cell outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_cmip6_daily_homogenised = homogenise_multiple_variables(data_cmip6_daily, VARIABLES_DAILY, ORIGIN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_cmip6_monthly_homogenised = homogenise_multiple_variables(data_cmip6_monthly, VARIABLES_MONTHLY, ORIGIN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate indicators\n",
    "The climate indicators\n",
    "are calculated using [xclim](https://xclim.readthedocs.io/en/stable/).\n",
    "The functions defined [above](derived_multi-origin-c3s-atlas_consistency_q02:section-codesetup) perform the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "indicators_cmip6_monthly = calculate_indicators_monthly(data_cmip6_daily_homogenised, data_cmip6_monthly_homogenised)\n",
    "indicators_cmip6_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Annual indicators temporarily disabled due to issues with CF metadata\n",
    "# indicators_cmip6_annual = calculate_indicators_annual(data_cmip6_daily_homogenised)\n",
    "# indicators_cmip6_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Interpolate to a common and regular grid\n",
    "```{note}\n",
    "This notebook uses [xESMF](https://github.com/pangeo-data/xESMF) for regridding data.\n",
    "xESMF is most easily installed using mamba/conda as explained in its documentation.\n",
    "Users who cannot or do not wish to use mamba/conda can manually compile and install [ESMF](https://earthsystemmodeling.org/docs/release/latest/ESMF_usrdoc/node10.html) on their machines.\n",
    "In future, this notebook will use [earthkit-regrid](https://github.com/ecmwf/earthkit-regrid) instead, once it reaches suitable maturity.\n",
    "```\n",
    "\n",
    "The final step in the processing is regridding and interpolation to a standard grid (Figure {numref}`{number} <multi-origin-c3s-atlas_consistency_q01_workflow-fig>`).\n",
    "This is performed through a custom function in the [User-tools for the C3S Atlas](https://github.com/ecmwf-projects/c3s-atlas/tree/main/c3s_atlas),\n",
    "specifically `c3s_atlas.interpolation`.\n",
    "This function is based on ESMF, as noted above.\n",
    "\n",
    "Note that the Atlas workflow calculates indicators first, then regrids.\n",
    "For operations that involve averaging, like smoothing and regridding, the order of operations can affect the result, especially in areas with steep gradients [[Bur20](https://doi.org/10.1364/OE.391470)].\n",
    "Examples of such areas for a temperature index are coastlines and mountain ranges.\n",
    "In the case of Atlas, this order of operations was a conscious choice to preserve the \"raw\" signals,\n",
    "e.g. preventing extreme temperatures from being smoothed out.\n",
    "However, it can affect the indicator values and therefore must be considered when using the Atlas application or dataset.\n",
    "\n",
    "Due to the number of variables involved, this section can take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "indicators_cmip6_monthly_interpolated = interpolate_multiple_variables(indicators_cmip6_monthly)\n",
    "indicators_cmip6_monthly_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# indicators_cmip6_annual_interpolated = interpolate_multiple_variables(indicators_cmip6_annual)\n",
    "# indicators_cmip6_annual_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "tags": []
   },
   "source": [
    "(derived_multi-origin-c3s-atlas_consistency_q02:section-atlas)= \n",
    "### 3. Retrieve indicators from the Atlas dataset\n",
    "Here, we download the same indicators as above directly from the [Gridded dataset underpinning the Copernicus Interactive Climate Atlas](https://doi.org/10.24381/cds.h35hb680) so the values can be compared.\n",
    "\n",
    "When downloading the Atlas dataset from the CDS, it is not possible to specify a specific year or model like it is for e.g. CMIP6.\n",
    "Instead, data are downloaded in blocks of several decades and include all model members.\n",
    "To prevent memory issues from loading so many data at once,\n",
    "a custom function is used that downloads the data for each indicator and pulls out only the year and model member of interest.\n",
    "Because this is done in sequence\n",
    "(one indicator after another)\n",
    "rather than in parallel (all at the same time, like a normal earthkit-data download),\n",
    "this can result in the following cells taking relatively long (>1 hour) to run the first time.\n",
    "After the first time, caching in earthkit-data will (if enabled) speed this section up significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup: General request\n",
    "DOMAIN = \"global\"\n",
    "BIAS_ADJUSTMENT = \"no_bias_adjustment\"\n",
    "\n",
    "request_atlas = {\n",
    "    \"origin\": ORIGIN,\n",
    "    \"experiment\": EXPERIMENT,\n",
    "    \"domain\": DOMAIN,\n",
    "    \"period\": YEARS,  # Automatically expanded, e.g. 2080 becomes 2015-2100 on the CDS\n",
    "    \"bias_adjustment\": BIAS_ADJUSTMENT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Download Atlas data\n",
    "# Monthly indicators\n",
    "requests_atlas_monthly = create_requests_for_variables(request_atlas, indicators_monthly_names)\n",
    "indicators_atlas_monthly = download_atlas_data_onemember(requests_atlas_monthly, YEARS, MODEL)\n",
    "\n",
    "# Annual indicators\n",
    "# requests_atlas_annual = create_requests_for_variables(request_atlas, indicators_annual_names)\n",
    "# indicators_atlas_annual = download_atlas_data_onemember(requests_atlas_annual, YEARS, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "indicators_atlas_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# indicators_atlas_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.245188,
     "end_time": "2024-03-08T17:39:21.277354",
     "exception": false,
     "start_time": "2024-03-08T17:39:21.032166",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(derived_multi-origin-c3s-atlas_consistency_q02:section-results)=\n",
    "### 4. Results\n",
    "This section contains the comparison between the indicator values retrieved from the Atlas dataset vs those reproduced from the origin dataset.\n",
    "\n",
    "The datasets are first compared on their native grids.\n",
    "This means a point-by-point comparison is not possible\n",
    "(because the points are not equivalent),\n",
    "but the distributions can be compared geospatially and overall.\n",
    "This comparison probes the consistency quality attribute:\n",
    "Are the climate indicators in the dataset underpinning the Copernicus Interactive Climate Atlas consistent with their origin datasets?\n",
    "\n",
    "The second comparison uses the regridded version of the indicators derived from the origin dataset.\n",
    "This makes a point-by-point comparison possible.\n",
    "This second comparison probes how well the dataset underpinning the Copernicus Interactive Climate Atlas can be reproduced from its origin datasets,\n",
    "based on the workflow (Figure {numref}`{number} <multi-origin-c3s-atlas_consistency_q02_workflow-fig>`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Consistency: Comparison on native grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For the geospatial comparison, \n",
    "we display the values of the indicators for one month,\n",
    "across one region and globally.\n",
    "In the first example, we display the results across\n",
    "Europe\n",
    "in\n",
    "June,\n",
    "which should provide significant spatial variation.\n",
    "\n",
    "This region can easily be modified in the following code cell using the [domains provided by earthkit-plots](https://earthkit-plots.readthedocs.io/en/latest/examples/guide/05-domains.html).\n",
    "Some examples are provided in the cell (commented out using `#`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup: Choose a month to display\n",
    "month = 6\n",
    "\n",
    "# Setup: Pick domain using earthkit-plots\n",
    "domain = \"Europe\"\n",
    "# domain = \"Mediterranean\"\n",
    "\n",
    "# Other examples -- uncomment where desired\n",
    "# domain = ekp.geo.domains.union([\"Portugal\", \"Spain\"], name=\"Iberia\")\n",
    "# domain = ekp.geo.domains.union([\"Ireland\", \"United Kingdom\"], name=\"UK & Ireland\")\n",
    "# domain = \"Italy\"\n",
    "# domain = \"South America\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Create plot with function defined at the start\n",
    "geospatial_comparison_multiple_indicators(indicators_atlas_monthly, indicators_cmip6_monthly, indicators_monthly_names, month,\n",
    "                                          domain=domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# geospatial_comparison_multiple_indicators(indicators_atlas_annual, indicators_cmip6_annual, indicators_annual_names, 1,\n",
    "#                                           domain=domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For the overall comparison, we compare the distribution of indicator values across all pixels and months within each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig_hist = histogram_comparison_by_indicator(indicators_atlas_monthly, indicators_cmip6_monthly, indicators_monthly_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "# fig_hist = histogram_comparison_by_indicator(indicators_atlas_annual, indicators_cmip6_annual, indicators_annual_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reproducibility: Comparison on Atlas grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "First, we recreate the geospatial comparison plots.\n",
    "This time, because both datasets are on the same grid, \n",
    "this includes the 1-to-1 difference per pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Create plot with function defined at the start\n",
    "geospatial_comparison_multiple_indicators_with_difference(indicators_atlas_monthly, indicators_cmip6_monthly_interpolated, indicators_monthly_names, month,\n",
    "                                                          domain=domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# geospatial_comparison_multiple_indicators_with_difference(indicators_atlas_annual, indicators_cmip6_annual_interpolated, indicator, 1,\n",
    "#                                                           domain=domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {
    "tags": []
   },
   "source": [
    "For a quantitative measure of the differences between the Atlas dataset and the indicators reproduced from the origin dataset,\n",
    "we perform a point-by-point comparison across the full spatial and temporal dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig_hist = histogram_comparison_by_indicator_with_difference(indicators_atlas_monthly, indicators_cmip6_monthly_interpolated, indicators_monthly_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {
    "tags": []
   },
   "source": [
    "The point-by-point comparison can be summarised into the following metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell will contain metrics calaulation code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ‚ÑπÔ∏è If you want to know more\n",
    "\n",
    "### Key resources\n",
    "The CDS catalogue entries for the data used were:\n",
    "* Gridded dataset underpinning the Copernicus Interactive Climate Atlas: [multi-origin-c3s-atlas](https://doi.org/10.24381/cds.h35hb680)\n",
    "  * [](./derived_multi-origin-c3s-atlas_consistency_q01)\n",
    "  * [](./derived_multi-origin-c3s-atlas_consistency_q02)\n",
    "  * [](./derived_multi-origin-c3s-atlas_consistency_q03)\n",
    "* CMIP6 climate projections: [projections-cmip6](https://doi.org/10.24381/cds.c866074c)\n",
    "  * [Quality assessments for CMIP6](../Climate_Projections/CMIP6/CMIP6.md)\n",
    "\n",
    "\n",
    "Code libraries used:\n",
    "* [earthkit](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-data](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-plots](https://github.com/ecmwf/earthkit-plots)\n",
    "* [User-tools for the C3S Atlas](https://github.com/ecmwf-projects/c3s-atlas)\n",
    "* [xclim](https://xclim.readthedocs.io/en/stable/) climate indicator tools\n",
    "\n",
    "\n",
    "More about the Copernicus Interactive Climate Atlas and its IPCC predecessor:\n",
    "* [Copernicus Interactive Climate Atlas application](https://atlas.climate.copernicus.eu/)\n",
    "* [Gridded data underpinning the Copernicus Interactive Climate Atlas: Description of the datasets and variables](https://confluence.ecmwf.int/display/CKB/Gridded+data+underpinning+the+Copernicus+Interactive+Climate+Atlas%3A+Description+of+the+datasets+and+variables)\n",
    "* [The Copernicus Interactive Climate Atlas: a tool to explore regional climate change](https://doi.org/10.21957/ah52ufc369)\n",
    "* [Copernicus Interactive Climate Atlas: a new tool to visualise climate variability and change](https://www.ecmwf.int/en/newsletter/179/news/copernicus-interactive-climate-atlas-new-tool-visualise-climate-variability)\n",
    "* [Implementation of FAIR principles in the IPCC: the WGI AR6 Atlas repository](https://doi.org/10.1038/s41597-022-01739-y)\n",
    "* [Climate Change 2021 ‚Äì The Physical Science Basis: Atlas](https://doi.org/10.1017/9781009157896.021)\n",
    "\n",
    "### References\n",
    "_To be replaced with numerical references once the text is finished_\n",
    "\n",
    "[[Guti24](https://doi.org/10.21957/ah52ufc369)] J. M. Guti√©rrez et al., ‚ÄòThe Copernicus Interactive Climate Atlas: a tool to explore regional climate change‚Äô, ECMWF Newsletter, vol. 181, pp. 38‚Äì45, Oct. 2024, doi: 10.21957/ah52ufc369.\n",
    "\n",
    "[[AtlasData](https://doi.org/10.24381/cds.h35hb680)] Copernicus Climate Change Service, ‚ÄòGridded dataset underpinning the Copernicus Interactive Climate Atlas‚Äô. Copernicus Climate Change Service (C3S) Climate Data Store (CDS), Jun. 17, 2024. doi: 10.24381/cds.h35hb680.\n",
    "\n",
    "[[CMIP6data](https://doi.org/10.24381/cds.c866074c)] Copernicus Climate Change Service, ‚ÄòCMIP6 climate projections‚Äô. Copernicus Climate Change Service (C3S) Climate Data Store (CDS), Mar. 23, 2021. doi: 10.24381/cds.c866074c.\n",
    "\n",
    "[[Bur20](https://doi.org/10.1364/OE.391470)] O. Burggraaff, ‚ÄòBiases from incorrect reflectance convolution‚Äô, Optics Express, vol. 28, no. 9, pp. 13801‚Äì13816, Apr. 2020, doi: 10.1364/OE.391470."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
