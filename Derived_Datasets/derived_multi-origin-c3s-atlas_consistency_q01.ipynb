{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Consistency Assessment of the Atlas Underpinning Dataset with Original #WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "Production date: DD-MM-YYYY\n",
    "Dataset version: 2.0.\n",
    "Produced by: C3S2_521 contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 🌍 Use case: Consistency of the tx35 indicator from the Gridded Dataset Underpinning the Copernicus Interactive Climate Atlas in comparison with the tx35 indicator from the CMIP6 CLimate Projections dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## ❓ Quality assessment question\n",
    "* **Are the output indexes consistent between the Gridded Dataset Underpinning the Copernicus Interactive Climate Atlas and the CMIP6 Climate Projections dataset?**\n",
    "* **etc**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "This box will be the introduction to the assessment, including:\n",
    "- Purpose and aims of the assessment. \n",
    "- \n",
    "\n",
    "(NOTE: need to find the correct terminology when referring to the non-Atlas datasets throughout this, option: original origin datasets, non-Atlas datasets, ...  have chosen origin datasets)\n",
    "\n",
    "The purpose of this assessment is to evaluate the consistency between the Gridded Dataset Underpinning the Copernicus Interactive Climate Atlas (Atlas dataset hereafter) and the origin datasets. This is done through \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 📢 Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Finding 1: will be a statement on the findings regarding the consistency \n",
    "* Finding 2\n",
    "* Finding 3\n",
    "* etc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 📋 Methodology\n",
    "\n",
    "To include:\n",
    "- *Dimensions of the Atlas dataset and the rationale behind the scope of this assessment*\n",
    "Due to the extend of the Atlas\n",
    "\n",
    "- Justification for the assessment being performed (justification for the t.b.d metric chosen also)\n",
    "- Methodology used, i.e. each step:\n",
    "  \n",
    "      - Download model data\n",
    "  \n",
    "      - Set parameters (variable, time, location)\n",
    "  \n",
    "      - Load data\n",
    "  \n",
    "      - Homogenisation to match Atlas dataset\n",
    "  \n",
    "      - Calculate the index\n",
    "  \n",
    "      - Interpolate to a common and regular grid\n",
    "  \n",
    "      - Download coresponding Atlas dataset data\n",
    "  \n",
    "      - Analyse results\n",
    "          - plots \n",
    "          - similarity/comparison metric\n",
    "          - results matrix \n",
    "\n",
    "This Jupyter notebook is currently a test case to build the workflow. We have chosen to reproduce the [Monthly count of days with maximum near-surface air temperature above 35 deg](https://ecmwf-projects.github.io/c3s-atlas/notebooks/tx35.html) notebook as an initial test. \n",
    "\n",
    "**[](section-1)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-2)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-3)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-4)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    " \n",
    "**[](section-5)** \n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-6)** \n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-7)** \n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-8)** \n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "Any further notes on the method could go here (explanations, caveats or limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 📈 Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-1)=\n",
    "### 1. Set-up \n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for \n",
    "downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data)) \n",
    "and visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data.\n",
    "Because earthkit is in active development, some functionality may change after this notebook is published.\n",
    "If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```\n",
    "\n",
    "#### Install the C3S Atlas User Tools\n",
    "This notebook uses the [C3S Atlas User Tools](https://github.com/ecmwf-projects/c3s-atlas), which can be installed using git: `pip install git+https://github.com/ecmwf-projects/c3s-atlas.git`\n",
    "Further details and alternative options for installing this library are available in its [README file](https://github.com/ecmwf-projects/c3s-atlas?tab=readme-ov-file#requirements).\n",
    "\n",
    "The following cell imports all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xesmf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mc3s_atlas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     apply_fixers\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# For regridding \u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mc3s_atlas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxesmfCICA\u001b[39;00m\n",
      "File \u001b[0;32m~/Git/c3s-atlas/c3s_atlas/interpolation.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxesmf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxe\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mInterpolator\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    A class for interpolating data using the specified method and resolution.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    data (xarray): The data to be interpolated.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xesmf'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# For reading files\n",
    "from pathlib import Path\n",
    "\n",
    "# For accessing data in the Climate Data Store\n",
    "import earthkit.data\n",
    "\n",
    "# For calculating spatiotemporal aggregations\n",
    "import earthkit.transforms\n",
    "\n",
    "# For regridding and interpolations\n",
    "import earthkit.regrid\n",
    "from earthkit.regrid import interpolate\n",
    "\n",
    "# For climate data handling\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xclim\n",
    "\n",
    "# For plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# For standarsising the data (NR rewrite this)\n",
    "from c3s_atlas.fixers import (\n",
    "    apply_fixers\n",
    ")\n",
    "\n",
    "# For regridding \n",
    "import c3s_atlas.interpolation as xesmfCICA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-2)=\n",
    "### 2. Download Climate Data\n",
    "\n",
    "*(note: section 2 will be functions if they are neccessary)*\n",
    "The following cell uses [earthkit](https://earthkit-data.readthedocs.io/en/latest/index.html) to download the data from the origin dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Use earthkit to download some data (Decided to unpack the dictionary as this is how it is in official docs)\n",
    "\n",
    "# Define request\n",
    "dataset = \"projections-cmip6\"\n",
    "request = {\n",
    "    \"temporal_resolution\": \"daily\",\n",
    "    \"experiment\": \"ssp5_8_5\",\n",
    "    \"variable\": \"daily_maximum_near_surface_air_temperature\",\n",
    "    \"model\": \"cmcc_esm2\",\n",
    "    \"year\": [\"2080\"],\n",
    "    \"month\": [f\"{month:02d}\" for month in range(1, 13)],\n",
    "    \"day\": [f\"{day:02d}\" for day in range(1, 32)],\n",
    "    \"format\": \"netcdf\"\n",
    "}\n",
    "\n",
    "# Download data\n",
    "ds = earthkit.data.from_source(\"cds\", dataset, request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-3)=\n",
    "### 3. Load the data\n",
    "\n",
    "The following cell loads the file with [xarray](https://docs.xarray.dev/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "xr.open_dataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-4)=\n",
    "### 4. Homogenisation \n",
    "\n",
    "Once the data is downloaded from the CDS it undergoes a process of homogenization:\n",
    "\n",
    "- The metadata of the spatial coordinates is homogenised to use standard names, in particular [lon, lat].\n",
    "\n",
    "- Fix any non-standard calendars used in the data. This typically involves converting the calendars to the CF standard calendar (Mixed Gregorian/Julian) commonly used in climate data.\n",
    "\n",
    "- Convert the units of the data to a common format (e.g. Celsius for temperature). This prevents us from working with the same variables in different units, for example.\n",
    "\n",
    "- Convert the longitude values from the [0, 360] format to the [-180, 180] one. This is done to ensure that the longitude variable is common between the different datasets.\n",
    "\n",
    "- Aggregated to the required temporal resolution. For example, hourly datasets (such as ERA5, ERA5-Land, WFDE5, etc.) will be resampled to daily resolution. This involves using a temporal aggregation method, such as taking the maximum or minimum value for a given variable. As part of this last step, some variable transformations are necessarily applied. For instance, fluxes variables in ERA5 are accumulated, and therefore, the last hour of the day represent daily accumulations. To mention another case, the surface wind is computed as a combination of both the u- and v-components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 3.749769,
     "end_time": "2024-03-08T17:24:00.248720",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.498951",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Homogenisation code \n",
    "project_id = \"cmip6\"\n",
    "variable = 'tasmax'\n",
    "var_mapping = {\n",
    "            \"dataset_variable\": {\"tasmax\": \"data\"},\n",
    "            \"aggregation\": {\"data\": \"mean\"},\n",
    "        }\n",
    "data = apply_fixers(data, variable, project_id, var_mapping)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "(section-5)= \n",
    "### 5. Calculate index (tx35) and aggregate to monthly (MS) temporal resolution using xclim\n",
    "\n",
    "[xclim](https://xclim.readthedocs.io/en/stable/) is an operational Python library for climate services, providing a framework for constructing custom climate indicators and indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to calculate tx35 and change temporal resolution \n",
    "da_tx35 = xclim.indices.tx_days_above(data['tasmax'], thresh='35.0 degC', \n",
    "                                      freq='MS', op='>') # \"freq\" attribute indicates output time frequency following pandas timeserie codes\n",
    "\n",
    "# Convert DataArray to Dataset with specified variable name\n",
    "ds_tx35 = da_tx35.to_dataset(name='tx35')\n",
    "ds_tx35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "(section-6)= \n",
    "### 6. Interpolation to a common and regular grid\n",
    "```{note}\n",
    "This notebook uses [xESMF](https://github.com/pangeo-data/xESMF) for regridding data.\n",
    "xESMF is most easily installed using conda as explained in its documentation.\n",
    "Users who cannot or do not wish to use conda will have to manually compile and install [ESMF](https://earthsystemmodeling.org/docs/release/latest/ESMF_usrdoc/node10.html) on their machines, which is not trivial.\n",
    "In future, this notebook will use [earthkit-regrid](https://github.com/ecmwf/earthkit-regrid) instead, once it reaches suitable maturity.\n",
    "```\n",
    "\n",
    "Interpolation to a common and regular grid using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the data \n",
    "int_attr \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "(section-7)= \n",
    "### 7. Download the data from the Atlas dataset\n",
    "\n",
    "In this section, the dataset produced above is downloaded from the [Gridded dataset underpinning the Copernicus Interactive Climate Atlas](https://cds.climate.copernicus.eu/datasets/multi-origin-c3s-atlas?tab=overview) using [earthkit](https://earthkit.readthedocs.io/en/latest/). The results of both of the datasets are compared to determine reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use earthkit to download the Atlas dataset\n",
    "\n",
    "# Define request\n",
    "dataset = \"multi-origin-c3s-atlas\"\n",
    "request = {\n",
    "    \"origin\": \"cmip6\",\n",
    "    \"experiment\": \"ssp5_8_5\",\n",
    "    \"period\": \"2015-2100\",\n",
    "    \"variable\": \"monthly_extreme_hot_days\",\n",
    "    \"bias_adjustment\": \"no_bias_adjustment\",\n",
    "    'area': [44.5, -9.5, 35.5, 3.5]\n",
    "}\n",
    "\n",
    "# Download data\n",
    "ds_C3S_Atlas = earthkit.data.from_source(\"cds\", dataset, request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with xarray \n",
    "ds_tx35_C3S_Atlas = xr.open_dataset(ds_C3S_Atlas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the same dataset\n",
    "# select a specific member of the ensemble\n",
    "select_member = [\n",
    "    str(mem.data) for mem in ds_tx35_C3S_Atlas.member_id if \"cmcc-esm2\" in str(mem.data).lower()\n",
    "][0]\n",
    "print(select_member)\n",
    "\n",
    "ds_tx35_C3S_Atlas_member_year = ds_tx35_C3S_Atlas.sel(\n",
    "    member = np.where(ds_tx35_C3S_Atlas.member_id == select_member)[0], \n",
    "    time = \"2080\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.245188,
     "end_time": "2024-03-08T17:39:21.277354",
     "exception": false,
     "start_time": "2024-03-08T17:39:21.032166",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-8)=\n",
    "### 8. Compare the results \n",
    "\n",
    "#### Results Subsections\n",
    "Describe what is done in this step/section and what the `code` in the cell does (if code is included). \n",
    "\n",
    "If this is the **results section**, we expect the final plots to be created here with a description of how to interpret them, and what information can be extracted for the specific use case and user question. The information in the 'quality assessment statement' should be derived here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 3.749769,
     "end_time": "2024-03-08T17:24:00.248720",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.498951",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot results \n",
    "\n",
    "zoomin_extent = [-9.5, 3.5, 35.5, 44.5]\n",
    "\n",
    "# zoom for Spain\n",
    "proj = ccrs.PlateCarree()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, subplot_kw={'projection': proj}, figsize=(20, 6))\n",
    "# user-tools\n",
    "#plot_month(ax[0], ds_tx35_i, 'tx35', 8, 'Jupyter-book result', 'hot_r')\n",
    "#ax[0].set_extent(zoomin_extent)\n",
    "# workflow (intermediate dataset)\n",
    "plot_month(ax[1], ds_tx35_C3S_Atlas_member_year, 'tx35', 8, 'C3S Atlas Dataset', 'hot_r')\n",
    "ax[1].set_extent(zoomin_extent)\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric of similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ℹ️ If you want to know more\n",
    "\n",
    "### Key resources\n",
    "\n",
    "List some key resources related to this assessment. E.g. CDS entries, applications, dataset documentation, external pages.\n",
    "Also list any code libraries used (if applicable).\n",
    "\n",
    "Code libraries used:\n",
    "* [C3S EQC custom functions](https://github.com/bopen/c3s-eqc-automatic-quality-control/tree/main/c3s_eqc_automatic_quality_control), `c3s_eqc_automatic_quality_control`,  prepared by [B-Open](https://www.bopen.eu/)\n",
    "\n",
    "### References\n",
    "\n",
    "List the references used in the Notebook here.\n",
    "\n",
    "E.g.\n",
    "\n",
    "[[1]](https://doi.org/10.1038/s41598-018-20628-2) Rodriguez, D., De Voil, P., Hudson, D., Brown, J. N., Hayman, P., Marrou, H., & Meinke, H. (2018). Predicting optimum crop designs using crop models and seasonal climate forecasts. Scientific reports, 8(1), 2231."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
