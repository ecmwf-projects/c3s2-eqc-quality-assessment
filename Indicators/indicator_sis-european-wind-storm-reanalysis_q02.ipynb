{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Windstorm tracks and footprints derived from reanalysis over Europe between 1940 to present: Windstorm statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Production date: 2026-MM-DD\n",
    "\n",
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "\n",
    "Produced by: Olivier Burggraaff (National Physical Laboratory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üåç Use case: Use case listed here in full "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## ‚ùì Quality assessment question\n",
    "* **In most cases there should be one question listed here in bold**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "**‚ÄòContext paragraph‚Äô (no title/heading)** - a very short introduction before the assessment statement describing approach taken to answer the user question. One or two key references could be useful, if the assessment summarises literature.\n",
    "\n",
    "**Background**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üì¢ Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Finding 1\n",
    "* Finding 2\n",
    "* Finding 3\n",
    "* etc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üìã Methodology\n",
    "\n",
    "* Internal consistency: TempestExtremes vs TRACK/Hodges? (read papers)\n",
    "* \n",
    "\n",
    "A ‚Äòfree text‚Äô introduction to the data analysis steps or a description of the literature synthesis, with a justification of the approach taken, and limitations mentioned. **Mention which CDS catalogue entry is used, including a link, and also any other entries used for the assessment**.\n",
    "\n",
    "[Windstorm tracks and footprints derived from reanalysis over Europe between 1940 to present\n",
    "](https://doi.org/10.24381/bf1f06a9)\n",
    "\n",
    "Hodges (TRACK) algorithm [[Hoskins+02](https://doi.org/10.1175/1520-0469(2002)059%3C1041:NPOTNH%3E2.0.CO;2), [Hodges+99](https://doi.org/10.1175/1520-0493(1999)127%3C1362:ACFFT%3E2.0.CO;2), [Hodges+95](https://doi.org/10.1175/1520-0493(1995)123%3C3458:FTOTUS%3E2.0.CO;2)]\n",
    "\n",
    "TempestExtremes [[Ullrich+21](https://doi.org/10.5194/gmd-14-5023-2021), [Ullrich+17](https://doi.org/10.5194/gmd-10-1069-2017)]\n",
    "\n",
    "**Note:** This notebook is currently just a brain-dump in anticipation of starting the actual quality assessment at a later stage.\n",
    "\n",
    "E.g. 'The analysis and results are organised in the following steps, which are detailed in the sections below:' \n",
    "\n",
    "**[](section-setup)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-download)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-analysis)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "**[](section-results)**\n",
    " * Sub-steps or key points listed in bullet below. No strict requirement to match and link to sub-headings.\n",
    "\n",
    "Any further notes on the method could go here (explanations, caveats or limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## üìà Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-setup)=\n",
    "### 1. Code setup\n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for\n",
    "downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data))\n",
    "and visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data.\n",
    "Because earthkit is in active development, some functionality may change after this notebook is published.\n",
    "If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Input / Output\n",
    "from pathlib import Path\n",
    "import earthkit.data as ekd\n",
    "import warnings\n",
    "\n",
    "# General data handling\n",
    "import numpy as np\n",
    "np.seterr(divide=\"ignore\")  # Ignore divide-by-zero warnings\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from functools import partial, reduce\n",
    "from operator import and_ as bitwise_and\n",
    "from dask.array.core import PerformanceWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=PerformanceWarning)\n",
    "\n",
    "# Visualisation\n",
    "import earthkit.plots as ekp\n",
    "from earthkit.plots.styles import Style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True\n",
    "plt.rcParams[\"figure.labelweight\"] = \"bold\"\n",
    "plt.rcParams[\"figure.titleweight\"] = \"bold\"\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.transforms import Affine2D\n",
    "import cartopy\n",
    "import shapely\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import cmcrameri as cmc\n",
    "from tqdm import tqdm  # Progress bars\n",
    "\n",
    "# Visualisation in Jupyter book -- automatically ignored otherwise\n",
    "try:\n",
    "    from myst_nb import glue\n",
    "except ImportError:\n",
    "    glue = None\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Iterable, Optional\n",
    "from cartopy.mpl.geoaxes import GeoAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "##### Data (pre-)processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The following cell contains some pre-defined constants for convenience,\n",
    "such as a list of variable names in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "TRACKING_ALGORITHMS = [\"hodges\", \"tempest_extremes\"]\n",
    "NUTS_LEVELS         = [0, 1, 2]\n",
    "\n",
    "# Columns in data\n",
    "SELECTION_COLUMNS   = [\"algorithm\", \"threshold\", \"year\",]\n",
    "VARIABLES           = [\"storms_number\", \"mean_wind_gust\", \"ssi\", \"normalised_ssi\", \"area_ratio\", \"wind_gust_ratio\",]\n",
    "NUTS_VARIABLES      = [\"region\", \"country_code\", \"NUTS_level\", \"NUTS_name\",]\n",
    "\n",
    "# Organisation of data\n",
    "INDEX_COLUMNS       = [\"algorithm\", \"threshold\", \"region\", \"year\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The following functions select data from a (Geo)DataFrame according to one or multiple conditions,\n",
    "e.g. a specific year and tracking algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_from_column(df: pd.DataFrame, col: str, val) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Create a True/False mask for one column `col` in a (Geo)DataFrame `df`\n",
    "    where the value is `val`.\n",
    "    Checks for iterable/non-iterable values and switches between .isin and == accordingly.\n",
    "    \"\"\"\n",
    "    # Check for single / multiple values\n",
    "    if df[col].dtype == \"O\":  # String column\n",
    "        if isinstance(val, str):\n",
    "            # Value is str -> Single value\n",
    "            iterable_val = False\n",
    "        elif isinstance(val, Iterable):\n",
    "            # Value is Iterable but not str -> assume Iterable[str]\n",
    "            iterable_val = True\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot parse value of type `{type(val)}` for column `{col}`.\")\n",
    "    else:  # Non-string column, assume number or similar\n",
    "        iterable_val = isinstance(val, Iterable)\n",
    "\n",
    "    # Create True/False mask\n",
    "    selection = (df[col].isin(val)) if iterable_val else (df[col] == val)\n",
    "    return selection\n",
    "\n",
    "def select_data(df: pd.DataFrame, **kwargs):\n",
    "    \"\"\"\n",
    "    Select data from a given (Geo)DataFrame `df` according to any number of conditions,\n",
    "    matching its column names.\n",
    "    \"\"\"\n",
    "    # Create masks for all col/val pairs in kwargs, then combine with & (bitwise and)\n",
    "    selection_all = [_select_from_column(df, col, val) for col, val in kwargs.items()]\n",
    "    selection = reduce(bitwise_and, selection_all)\n",
    "\n",
    "    # Apply and return\n",
    "    df_selection = df[selection]\n",
    "    return df_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "##### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry / Projection\n",
    "EPSG = 3035\n",
    "CRS = cartopy.crs.epsg(EPSG)\n",
    "MAP_KWARGS={\"projection\": CRS,\n",
    "            \"xlim\": (0.25e7, 0.74e7), \"ylim\": (1.3e6, 5.5e6),  # Continental Europe\n",
    "           }\n",
    "\n",
    "# Define styles for land, borders, etc.\n",
    "STYLE_LAND            = {\"zorder\": 1, \"facecolor\": \"#ccced1\", \"edgecolor\": \"none\"}\n",
    "STYLE_COASTLINE       = {\"zorder\": 3, \"edgecolor\": \"black\", \"linewidth\": 1}\n",
    "STYLE_NATIONAL_BORDER = {\"zorder\": 3, \"edgecolor\": \"black\", \"linewidth\": 0.5}\n",
    "STYLE_CHOROPLETH      = {\"zorder\": 2, \"edgecolor\": STYLE_NATIONAL_BORDER[\"edgecolor\"], \"linewidth\": STYLE_NATIONAL_BORDER[\"linewidth\"]/5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "_style_footprint = {\"cmap\": plt.cm.cividis, \"vmin\": 0, \"vmax\": 40}\n",
    "\n",
    "styles = {\n",
    "    \"footprint\": Style(**_style_footprint),\n",
    "}\n",
    "\n",
    "# Apply general settings\n",
    "for style in styles.values():\n",
    "    style.normalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _glue_or_show(fig: plt.Figure, glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    If `glue` is available, glue the figure using the provided label.\n",
    "    If not, display the figure in the notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        glue(glue_label, fig, display=False)\n",
    "    except TypeError:\n",
    "        plt.show()\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def _add_textbox_to_subplots(text: str, *axs: Iterable[plt.Axes | ekp.Subplot], right=False) -> None:\n",
    "    \"\"\" Add a text box to each of the specified subplots. \"\"\"\n",
    "    # Get the plt.Axes for each ekp.Subplot\n",
    "    axs = [subplot.ax if isinstance(subplot, ekp.Subplot) else subplot for subplot in axs]\n",
    "\n",
    "    # Set up location\n",
    "    x = 0.95 if right else 0.05\n",
    "    horizontalalignment = \"right\" if right else \"left\"\n",
    "\n",
    "    # Add the text\n",
    "    for ax in axs:\n",
    "        ax.text(x, 0.95, text, transform=ax.transAxes,\n",
    "        horizontalalignment=horizontalalignment, verticalalignment=\"top\",\n",
    "        bbox={\"facecolor\": \"white\", \"edgecolor\": \"black\", \"boxstyle\": \"round\",\n",
    "              \"alpha\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The following cell contains functions for displaying Shapely geometries (e.g. a country shape) next to a plot title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iter_polygons(geom):\n",
    "    \"\"\"Yield polygon parts from Polygon/MultiPolygon; try buffer(0) for non-polygon inputs.\"\"\"\n",
    "    if isinstance(geom, Polygon):\n",
    "        yield geom\n",
    "    elif isinstance(geom, MultiPolygon):\n",
    "        for g in geom.geoms:\n",
    "            yield g\n",
    "    else:\n",
    "        g = geom.buffer(0)  # attempt to polygonize (e.g., fix invalid rings)\n",
    "        if isinstance(g, Polygon):\n",
    "            yield g\n",
    "        elif isinstance(g, MultiPolygon):\n",
    "            for p in g.geoms:\n",
    "                yield p\n",
    "        else:\n",
    "            raise ValueError(\"Geometry is not polygonal and cannot be polygonized.\")\n",
    "\n",
    "def _polys_to_path(polys, bounds=None):\n",
    "    \"\"\"\n",
    "    Build a single compound Path from a list of polygons.\n",
    "    Normalize to unit box using `bounds=(minx,miny,maxx,maxy)` if provided.\n",
    "    \"\"\"\n",
    "    if bounds is None:\n",
    "        u = shapely.unary_union(list(polys))\n",
    "        minx, miny, maxx, maxy = u.bounds\n",
    "    else:\n",
    "        minx, miny, maxx, maxy = bounds\n",
    "\n",
    "    w = max(maxx - minx, 1e-12)\n",
    "    h = max(maxy - miny, 1e-12)\n",
    "\n",
    "    vertices = []\n",
    "    codes = []\n",
    "    for poly in polys:\n",
    "        # exterior\n",
    "        ex = np.asarray(poly.exterior.coords)\n",
    "        ex_norm = np.column_stack(((ex[:, 0] - minx) / w, (ex[:, 1] - miny) / h))\n",
    "        vertices += ex_norm.tolist()\n",
    "        codes    += [Path.MOVETO] + [Path.LINETO] * (len(ex_norm) - 2) + [Path.CLOSEPOLY]\n",
    "\n",
    "        # holes\n",
    "        for ring in poly.interiors:\n",
    "            ri = np.asarray(ring.coords)\n",
    "            ri_norm = np.column_stack(((ri[:, 0] - minx) / w, (ri[:, 1] - miny) / h))\n",
    "            vertices += ri_norm.tolist()\n",
    "            codes    += [Path.MOVETO] + [Path.LINETO] * (len(ri_norm) - 2) + [Path.CLOSEPOLY]\n",
    "\n",
    "    return Path(vertices, codes), (minx, miny, maxx, maxy)\n",
    "\n",
    "def shapely_to_patch(geom, *, bounds=None, facecolor=\"#d9d9d9\", edgecolor=\"#555\", lw=0.4,\n",
    "                     transform=None, clip_on=False, zorder=10, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Convert any polygonal geometry to a PathPatch normalized to `bounds`.\n",
    "    If `bounds` is None, bounds of the geometry are used (not recommended when overlaying).\n",
    "    \"\"\"\n",
    "    polys = list(_iter_polygons(geom))\n",
    "    path, _ = _polys_to_path(polys, bounds=bounds)\n",
    "    patch = PathPatch(\n",
    "        path, facecolor=facecolor, edgecolor=edgecolor, linewidth=lw,\n",
    "        transform=transform, clip_on=clip_on, zorder=zorder, alpha=alpha\n",
    "    )\n",
    "    return patch\n",
    "\n",
    "def add_vector_icon_next_to_title(\n",
    "    ax,\n",
    "    geom,\n",
    "    geom_base=None,\n",
    "    where=\"right\",\n",
    "    size=0.1,\n",
    "    *,\n",
    "    # styling\n",
    "    facecolor=\"#2e6da4\", edgecolor=\"#1f3f67\", lw=0.5, alpha=1.0,\n",
    "    base_facecolor=\"#cfd8e3\", base_edgecolor=\"#4c5c74\", base_lw=0.4, base_alpha=1.0,\n",
    "    # placement & layering\n",
    "    y_anchor=1.02, x_anchor_right=0.93, x_anchor_left=0.07,\n",
    "    zorder_base=10, zorder_geom=11,\n",
    "    # behavior\n",
    "    to_figure=False, clip_on=False, pad=0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Place a vector icon near the title using the shapely_to_patch() helper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        Target axes (used for placement and for figure access).\n",
    "    geom : shapely geometry\n",
    "        The highlighted geometry to draw (e.g., Zeeland).\n",
    "    geom_base : shapely geometry or None\n",
    "        Optional base geometry to draw behind `geom` (e.g., Netherlands).\n",
    "    where : {\"right\",\"left\"}\n",
    "        Icon position relative to the title area of this axes.\n",
    "    size : float\n",
    "        Icon width/height in axes (or figure) coordinates.\n",
    "    facecolor, edgecolor, lw, alpha : styling for the highlighted geom.\n",
    "    base_facecolor, base_edgecolor, base_lw, base_alpha : styling for base geom.\n",
    "    y_anchor : float\n",
    "        Vertical anchor above the axes (axes/figure coords depending on `to_figure`).\n",
    "    x_anchor_right, x_anchor_left : float\n",
    "        Horizontal anchors for right/left placement (axes/figure coords).\n",
    "    zorder_base, zorder_geom : int\n",
    "        Z-orders for base and highlight geometries.\n",
    "    to_figure : bool\n",
    "        If True, draw in figure coordinates (never clipped by any axes).\n",
    "        If False (default), draw in axes coordinates.\n",
    "    clip_on : bool\n",
    "        If False (default), allow icon to extend beyond axes.\n",
    "    pad : float\n",
    "        Small offset added toward the right or left (same coordinate system as placement).\n",
    "    \"\"\"\n",
    "    # Decide anchor\n",
    "    x_anchor = (x_anchor_right if where == \"right\" else x_anchor_left) + (pad if where == \"right\" else -pad)\n",
    "\n",
    "    # Bounds for consistent normalization (preserve relative scale/position)\n",
    "    if geom_base is not None:\n",
    "        import shapely\n",
    "        union_bounds = shapely.unary_union([geom_base, geom]).bounds\n",
    "    else:\n",
    "        union_bounds = None  # falls back to geom's own bounds\n",
    "\n",
    "    # Build the placement transform in axes or figure coordinates\n",
    "    base_transform = ax.figure.transFigure if to_figure else ax.transAxes\n",
    "    trans = (Affine2D()\n",
    "             .scale(size, size)\n",
    "             .translate(x_anchor - size/2, y_anchor - size/2)) + base_transform\n",
    "\n",
    "    # Construct patches using shared bounds\n",
    "    patches = []\n",
    "\n",
    "    if geom_base is not None:\n",
    "        p_base = shapely_to_patch(\n",
    "            geom_base,\n",
    "            bounds=union_bounds,\n",
    "            facecolor=base_facecolor, edgecolor=base_edgecolor,\n",
    "            lw=base_lw, alpha=base_alpha,\n",
    "            transform=trans, clip_on=clip_on, zorder=zorder_base\n",
    "        )\n",
    "        patches.append(p_base)\n",
    "\n",
    "    p_geom = shapely_to_patch(\n",
    "        geom,\n",
    "        bounds=union_bounds,\n",
    "        facecolor=facecolor, edgecolor=edgecolor,\n",
    "        lw=lw, alpha=alpha,\n",
    "        transform=trans, clip_on=clip_on, zorder=zorder_geom\n",
    "    )\n",
    "    patches.append(p_geom)\n",
    "\n",
    "    # Attach patches to the appropriate container\n",
    "    container = ax.figure if to_figure else ax\n",
    "    for p in patches:\n",
    "        container.add_artist(p)\n",
    "\n",
    "    return tuple(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorate_fig(fig: ekp.Figure, *, title: Optional[str]=\"\") -> None:\n",
    "    \"\"\" Decorate an earthkit figure with land, coastlines, etc. \"\"\"\n",
    "    # Add progress bar because individual steps can be very slow for large plots\n",
    "    with tqdm(total=4, desc=\"Decorating\", leave=False) as progressbar:\n",
    "        fig.land()\n",
    "        progressbar.update()\n",
    "        fig.coastlines()\n",
    "        progressbar.update()\n",
    "        # fig.borders()\n",
    "        # progressbar.update()\n",
    "        fig.gridlines(linestyle=plt.rcParams[\"grid.linestyle\"])\n",
    "        progressbar.update()\n",
    "        fig.title(title)\n",
    "        progressbar.update()\n",
    "\n",
    "def decorate_fig(axs: Iterable[GeoAxes], *, title: Optional[str]=\"\") -> None:\n",
    "    \"\"\" Decorate a cartopy/matplotlib figure with land, coastlines, etc. \"\"\"\n",
    "    # Will be replaced by preceding (earthkit) function when earthkit-plots supports choropleth maps\n",
    "    try:  # Ravel if numpy array\n",
    "        axs = axs.ravel()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # Apply each decoration in order\n",
    "    for ax in axs:\n",
    "        ax.add_feature(cartopy.feature.LAND,      **STYLE_LAND)\n",
    "        ax.add_feature(cartopy.feature.COASTLINE, **STYLE_COASTLINE)\n",
    "        ax.add_feature(cartopy.feature.BORDERS,   **STYLE_NATIONAL_BORDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_by_variable_and_nuts(df: pd.DataFrame, *,\n",
    "                                      glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot a list of variables in one DataFrame, with one-to-one comparisons\n",
    "    between the two tracking algorithms.\n",
    "    Hard-coded for VARIABLES, NUTS_LEVELS, TRACKING_ALGORITHMS.\n",
    "    \"\"\"\n",
    "    # Move \"year\" to data column for this visualisation\n",
    "    df = df.reset_index(level=-1)\n",
    "\n",
    "    # Create figure\n",
    "    nrows, ncols = len(VARIABLES), len(NUTS_LEVELS)\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=\"row\", sharey=\"row\", figsize=(4*ncols, 4*nrows), squeeze=False)\n",
    "\n",
    "    # Loop over rows: variables\n",
    "    for ax_row, var in zip(axs, VARIABLES):\n",
    "        # Loop over columns: NUTS levels\n",
    "        for ax, nuts in zip(ax_row, NUTS_LEVELS):\n",
    "            # Select data\n",
    "            df_here = df[df[\"NUTS_level\"] == nuts]\n",
    "\n",
    "            # Split by tracking algorithm\n",
    "            x, y = df_here.loc[\"hodges\"], df_here.loc[\"tempest_extremes\"]\n",
    "\n",
    "            # Loop over thresholds: shape\n",
    "            for marker, threshold in zip(\"ovsX\", x.index.levels[0]):\n",
    "                x_here, y_here = x.loc[threshold, :, :], y.loc[threshold, :, :]\n",
    "\n",
    "                ax.scatter(x_here[var], y_here[var], marker=marker, c=x_here[\"year\"], cmap=plt.cm.cividis, alpha=0.7)\n",
    "\n",
    "    # Decorate panels\n",
    "    for ax in axs.ravel():\n",
    "        # Highlight diagonal\n",
    "        ax.axline((0, 0), slope=1, color=plt.rcParams[\"grid.color\"], linewidth=2, linestyle=\"-\")\n",
    "\n",
    "        # Panel shape\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        # limits left free to allow for scatter points around 0\n",
    "\n",
    "    # Label top row / left column\n",
    "    for ax, nuts in zip(axs[0], NUTS_LEVELS):\n",
    "        ax.set_title(f\"NUTS level {nuts}\")\n",
    "    for ax, var in zip(axs[:, 0], VARIABLES):\n",
    "        ax.set_ylabel(var)    \n",
    "\n",
    "    # Decorate figure\n",
    "    fig.suptitle(\"Point-by-point comparison across the dataset\")\n",
    "    fig.supxlabel(\"Hodges/TRACK\")\n",
    "    fig.supylabel(\"TempestExtremes\")\n",
    "    fig.align_labels()\n",
    "\n",
    "    # Display\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_choropleth_by_algorithm(df: gpd.GeoDataFrame, col: str, *,\n",
    "                                 year: int, threshold: float, NUTS_level: int,  # Selection\n",
    "                                 glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot data from column `col` in GeoDataFrame `df` in a choropleth map.\n",
    "    Compare between both algorithms for one year / threshold / NUTS level.\n",
    "    \"\"\"\n",
    "    # Select data\n",
    "    df_sel  = df.loc[:, threshold, :, year]\n",
    "    df_nuts = select_data(df_sel, NUTS_level=NUTS_level)\n",
    "\n",
    "    # Create figure\n",
    "    ncols = len(TRACKING_ALGORITHMS) + 1\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=ncols, figsize=(4*ncols, 4), squeeze=False, subplot_kw=MAP_KWARGS)\n",
    "\n",
    "    # Plot variable for each algorithm\n",
    "    for j, alg in enumerate(TRACKING_ALGORITHMS):\n",
    "        # Select data, panel for this algorithm\n",
    "        df_alg = df_nuts.loc[alg]\n",
    "        ax = axs[0, j]\n",
    "\n",
    "        # Plot\n",
    "        choro = df_alg.plot.geo(col, ax=ax,\n",
    "                                vmin=0, vmax=20,\n",
    "                                legend=True, legend_kwds={\"location\": \"bottom\", \"label\": col},\n",
    "                                cmap=plt.cm.cividis.resampled(8),\n",
    "                                **STYLE_CHOROPLETH)\n",
    "        ax.set_title(alg)\n",
    "\n",
    "    # Plot difference\n",
    "    df_diff = df_nuts.loc[\"difference\"]\n",
    "    ax = axs[0, -1]\n",
    "    choro = df_diff.plot.geo(col, ax=ax,\n",
    "                        vmin=-10, vmax=10,\n",
    "                        legend=True, legend_kwds={\"location\": \"bottom\", \"label\": \"Œî \"+col},\n",
    "                        cmap=plt.cm.PuOr_r.resampled(11),\n",
    "                        **STYLE_CHOROPLETH)\n",
    "    ax.set_title(\"Difference\")\n",
    "\n",
    "    # Decorate\n",
    "    decorate_fig(axs)\n",
    "\n",
    "    # Show result\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "(section-download)=\n",
    "### 2. Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### CDS: Windstorm summary indicators\n",
    "We download the full windstorm summary indicator table from the\n",
    "[sis-european-wind-storm-reanalysis](https://doi.org/10.24381/bf1f06a9)\n",
    "CDS entry.\n",
    "Because this is a simple table,\n",
    "the data are loaded into a Pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\n",
    "Geographical information will be added to this table in the next subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sis-european-wind-storm-reanalysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    \"product\": \"windstorm_summary_indicator\",\n",
    "    \"variable\": \"all\",\n",
    "    \"tracking_algorithm\": [\"hodges\", \"tempestextremes\"],\n",
    "    # Note that we do not use the TRACKING_ALGORITHMS constant here because the CDS\n",
    "    # does not have an _ in `tempestextremes` but the resulting table does.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ekd.from_source(\"cds\", dataset, request)\n",
    "data = data.to_pandas()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### Ancillary: NUTS shapefiles\n",
    "The summary table is organised by NUTS\n",
    "(Nomenclature of Territorial Units for Statistics)\n",
    "level 0, 1, and 2\n",
    "region.\n",
    "To visualise these areas,\n",
    "we need the corresponding shapefiles,\n",
    "which can be retrieved from [GISCO](https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/territorial-units-statistics).\n",
    "We load these data into a GeoPandas [GeoDataFrame](https://geopandas.org/en/latest/docs/reference/api/geopandas.GeoDataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GISCO URL and request\n",
    "base = \"https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/\"\n",
    "fname = \"NUTS_RG_20M_2021_3035_LEVL_{level}.geojson\"\n",
    "# RG: Polygons\n",
    "# 20M: 1:20 Million scale\n",
    "# 2021: Year\n",
    "# 3035: EPSG CRS (projection)\n",
    "# LEVEL: Iterate over NUTS_LEVELS (0, 1, 2)\n",
    "urls = [base + \"/\" + fname.format(level=level) for level in NUTS_LEVELS]\n",
    "\n",
    "# Download data from GISCO\n",
    "nuts_gdf = [gpd.read_file(url) for url in urls]\n",
    "\n",
    "# Merge NUTS levels into one table\n",
    "nuts_gdf = gpd.GeoDataFrame(pd.concat(nuts_gdf))\n",
    "nuts_gdf = nuts_gdf.rename(columns={\"NUTS_ID\": \"region\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "The NUTS shapes are merged into the CDS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge NUTS polygons into data\n",
    "data = nuts_gdf.merge(data, on=\"region\")\n",
    "\n",
    "# Rename some columns for ease of use\n",
    "data = data.rename(columns={\"LEVL_CODE\": \"NUTS_level\", \"CNTR_CODE\": \"country_code\", \"NAME_LATN\": \"NUTS_name\"})\n",
    "\n",
    "# Filter only desired columns, in pre-set order\n",
    "data = data[[*SELECTION_COLUMNS, *NUTS_VARIABLES, *VARIABLES, \"geometry\",]]\n",
    "\n",
    "# Display result\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### Re-index\n",
    "Lastly, we re-index the data by tracking algorithm, threshold, region, and year, for easier subsampling in the analysis later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index data for easier selection\n",
    "data = data.set_index(INDEX_COLUMNS)\n",
    "    \n",
    "# Display result\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Difference between algorithms\n",
    "Some of the following analysis will focus on the per-point difference between the Hodges and TempestExtremes algorithms.\n",
    "Here, we calculate this difference and append it to the GeoDataFrame as a third entry along the `algorithm` index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Copy DataFrame format\n",
    "difference = data.loc[\"hodges\"].copy()\n",
    "\n",
    "# Calculate difference\n",
    "difference[VARIABLES] = data.loc[\"hodges\"][VARIABLES] - data.loc[\"tempest_extremes\"][VARIABLES]\n",
    "\n",
    "# Append to existing DataFrame, convert back to GeoDataFrame\n",
    "difference = pd.concat({\"difference\": difference}, names=[\"algorithm\"])  # Add `algorithm` index level to `difference`\n",
    "data = pd.concat([data, difference])  # Append to existing data (converts to regular DataFrame)\n",
    "data = gpd.GeoDataFrame(data)  # Convert to GeoDataFrame again\n",
    "\n",
    "# Display result\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "(section-analysis)=\n",
    "### 3. Analysis\n",
    "Split by method for now because easier to experiment.\n",
    "Final analysis should probably be by topic rather than by visualisation.\n",
    "(time series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### Tabular comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### Scatter plot comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_by_variable_and_nuts(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "#### Time series comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import PathPatch\n",
    "\n",
    "COLOURS_DATA = \"#0077bb\", \"#ee7733\"\n",
    "\n",
    "df = data.copy()\n",
    "NUTS2_region = \"NL34\"\n",
    "threshold = 0.0\n",
    "\n",
    "\"\"\"\n",
    "Plot a list of variables in one DataFrame, with time series comparisons\n",
    "between the two tracking algorithms.\n",
    "Hard-coded for VARIABLES, NUTS_LEVELS, TRACKING_ALGORITHMS.\n",
    "Columns show one location at incremental NUTS levels (e.g. NL -> NUTS3 -> NUTS34).\n",
    "For now: one threshold (0.0).\n",
    "\"\"\"\n",
    "# Generate NUTS subdivisions\n",
    "assert len(NUTS2_region) == 4, f\"Please provide a NUTS2 region with argument `NUTS2_region`. Current value {NUTS2_region} is not understood.\"\n",
    "NUTS_region_here = [NUTS2_region[:2], NUTS2_region[:3], NUTS2_region]\n",
    "\n",
    "# Create figure\n",
    "nrows, ncols = len(VARIABLES), len(NUTS_LEVELS)\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=\"row\", sharey=\"row\", figsize=(4*ncols, 4*nrows), squeeze=False)\n",
    "\n",
    "# Loop over rows: variables\n",
    "for ax_row, var in zip(axs, VARIABLES):\n",
    "    # Loop over columns: NUTS regions\n",
    "    for ax, nuts in zip(ax_row, NUTS_region_here):\n",
    "        # Select data\n",
    "        df_here = df.loc[:, threshold, nuts]\n",
    "\n",
    "        # Loop over tracking algorithms\n",
    "        for alg, c in zip(TRACKING_ALGORITHMS, COLOURS_DATA):\n",
    "            df_here.loc[alg][var].plot.line(ax=ax, color=c, alpha=0.6, linewidth=2, label=alg)\n",
    "\n",
    "# Label top row / left column\n",
    "for ax, nuts in zip(axs[0], NUTS_region_here):\n",
    "    # Extract NUTS area name from data table\n",
    "    name = df.loc[:, :, nuts][\"NUTS_name\"].iloc[0]\n",
    "    ax.set_title(f\"{name} ({nuts})\")\n",
    "\n",
    "    # Add shape\n",
    "    geometry = df.loc[:, :, nuts][\"geometry\"].iloc[0]\n",
    "    geometry_base = df.loc[:, :, NUTS_region_here[0]][\"geometry\"].iloc[0]\n",
    "    add_vector_icon_next_to_title(ax, geometry, geometry_base)\n",
    "    # inset = ax.inset_axes([0, 1, 0.1, 0.1], xticks=[], yticks=[])\n",
    "    \n",
    "for ax, var in zip(axs[:, 0], VARIABLES):\n",
    "    ax.set_ylabel(var)    \n",
    "\n",
    "# Decorate figure\n",
    "fig.align_labels()\n",
    "\n",
    "# Display\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "#### Geospatial comparison\n",
    "Note: Choropleth maps are not supported in earthkit-plots yet, but will be soon. See GitHub issue [#160](https://github.com/ecmwf/earthkit-plots/issues/160)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for NUTS_level in NUTS_LEVELS:\n",
    "    plot_choropleth_by_algorithm(data, \"storms_number\", year=2024, threshold=0.0, NUTS_level=NUTS_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For earthkit-plots issue #160\n",
    "# data_nuts[selection].to_file(\"choropleth_example.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.245188,
     "end_time": "2024-03-08T17:39:21.277354",
     "exception": false,
     "start_time": "2024-03-08T17:39:21.032166",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-results)=\n",
    "### 5. Results\n",
    "\n",
    "#### Results Subsections\n",
    "Describe what is done in this step/section and what the `code` in the cell does (if code is included). \n",
    "\n",
    "If this is the **results section**, we expect the final plots to be created here with a description of how to interpret them, and what information can be extracted for the specific use case and user question. The information in the 'quality assessment statement' should be derived here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ‚ÑπÔ∏è If you want to know more\n",
    "\n",
    "### Key resources\n",
    "\n",
    "Code libraries used:\n",
    "* [GeoPandas](https://geopandas.org/en/stable/)\n",
    "* [earthkit](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-data](https://github.com/ecmwf/earthkit-data)\n",
    "  * [earthkit-plots](https://github.com/ecmwf/earthkit-plots)\n",
    "\n",
    "### References\n",
    "[[Hoskins+02](https://doi.org/10.1175/1520-0469(2002)059%3C1041:NPOTNH%3E2.0.CO;2)] B. J. Hoskins and K. I. Hodges, ‚ÄòNew Perspectives on the Northern Hemisphere Winter Storm Tracks‚Äô, Journal of the Atmospheric Sciences, vol. 59, no. 6, pp. 1041‚Äì1061, Mar. 2002, doi: 10.1175/1520-0469(2002)059%3C1041:NPOTNH%3E2.0.CO;2.\n",
    "\n",
    "[[Hodges+99](https://doi.org/10.1175/1520-0493(1999)127%3C1362:ACFFT%3E2.0.CO;2)] K. I. Hodges, ‚ÄòAdaptive Constraints for Feature Tracking‚Äô, Monthly Weather Review, vol. 127, no. 6, pp. 1362‚Äì1373, June 1999, doi: 10.1175/1520-0493(1999)127%3C1362:ACFFT%3E2.0.CO;2.\n",
    "\n",
    "[[Hodges+95](https://doi.org/10.1175/1520-0493(1995)123%3C3458:FTOTUS%3E2.0.CO;2)] K. I. Hodges, ‚ÄòFeature Tracking on the Unit Sphere‚Äô, Monthly Weather Review, vol. 123, no. 12, pp. 3458‚Äì3465, Dec. 1995, doi: 10.1175/1520-0493(1995)123%3C3458:FTOTUS%3E2.0.CO;2.\n",
    "\n",
    "[[Ullrich+21](https://doi.org/10.5194/gmd-14-5023-2021)] P. A. Ullrich, C. M. Zarzycki, E. E. McClenny, M. C. Pinheiro, A. M. Stansfield, and K. A. Reed, ‚ÄòTempestExtremes v2.1: a community framework for feature detection, tracking, and analysis in large datasets‚Äô, Geoscientific Model Development, vol. 14, no. 8, pp. 5023‚Äì5048, Aug. 2021, doi: 10.5194/gmd-14-5023-2021.\n",
    "\n",
    "[[Ullrich+17](https://doi.org/10.5194/gmd-10-1069-2017)] P. A. Ullrich and C. M. Zarzycki, ‚ÄòTempestExtremes: a framework for scale-insensitive pointwise feature tracking on unstructured grids‚Äô, Geoscientific Model Development, vol. 10, no. 3, pp. 1069‚Äì1090, Mar. 2017, doi: 10.5194/gmd-10-1069-2017."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
