{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Uncertainty in drought indicators for parametric insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Production date: 2026-02-xx\n",
    "\n",
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "\n",
    "Dataset version: 1.0.\n",
    "\n",
    "Produced by: Enis Gerxhalija, Olivier Burggraaff (National Physical Laboratory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ðŸŒ Use case: Parametric insurance for agriculture using reanalysis-based drought indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## â“ Quality assessment question\n",
    "* **What is the uncertainty on drought indicators in ERA5â€“Drought and how does this propagate into parametric insurance payouts?**\n",
    "* **Can the ensemble in ERA5â€“Drought provide additional information for parametric insurance, compared to only using the deterministic reanalysis?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Drought and extreme precipitation have far-reaching environmental, societal, and economic impacts.\n",
    "In the United Kingdom, the record-breaking hot and dry spring and summer of 2025 caused harvest losses worth more than Â£800 million [[ECIU+25](https://eciu.net/analysis/reports/2025/estimated-financial-losses-faced-by-uk-farmers-due-dry-weather-impacts-on-key-arable-crops)].\n",
    "An 18-month drought in Brazil in 2023â€“24,\n",
    "the most severe since monitoring began in 1954,\n",
    "led to 720 health centres in affected areas becoming non-operational [[UNICEF+24](https://reliefweb.int/node/4111326)].\n",
    "Finally, extreme rainfall killed hundreds of people and caused billions of â‚¬ in damages in Spain in 2024 [[Franch-Pardo+25](https://doi.org/10.48088/ejg.i.fra.16.2.286.297)].\n",
    "Climate change is thought to be the primary driver behind the increase in drought and extreme precipitation events since the 1950s [[IPCC+23](https://doi.org/10.59327/IPCC/AR6-9789291691647)],\n",
    "and this trend is expected to continue into the future.\n",
    "\n",
    "_Parametric insurance_ is a type of data-driven insurance,\n",
    "offering pre-set payouts when a trigger event happens,\n",
    "that has become popular in recent years [[Lin+20](https://doi.org/10.1111/rmir.12146)].\n",
    "In agriculture,\n",
    "parametric insurance policies are based on variables including\n",
    "temperature, humidity, and precipitation,\n",
    "with risks estimated from typical climatology and crop growth models [[Prokopchuk+20](https://doi.org/10.22004/ag.econ.320076), [World Bank Group+18](https://doi.org/10.1596/29784)].\n",
    "\n",
    "Tie parametric insurance and SPI/SPEI together    \n",
    "Two widely-employed indices are the \n",
    "_Standardised Precipitation Index (SPI)_ [[McKee+93](https://climate.colostate.edu/pdfs/relationshipofdroughtfrequency.pdf)]\n",
    "and\n",
    "_Standardised Precipitation-Evapotranspiration Index (SPEI)_ [[Vicente-Serrano+10](https://doi.org/10.1175/2009JCLI2909.1)].\n",
    "Both operate on the same principle,\n",
    "namely quantifying the amount of precipitation\n",
    "over a given time frame at a given location\n",
    "relative to its historical climatology.\n",
    "For example,\n",
    "an SPI value of +1 corresponds to a precipitation that is 1 standard deviation above the mean,\n",
    "for that site and time frame.\n",
    "Example for Indonesia â€“ details in methodology [[World Bank Group+18](https://doi.org/10.1596/29784)]\n",
    "\n",
    "Of course,\n",
    "proxies like SPI and SPEI depend on reliable input data in the form of historical meteorological time series.\n",
    "Weather stations can provide these data with high accuracy and precision for specific sites,\n",
    "but their coverage is sparse and their data are not always interoperable.\n",
    "Reanalyses,\n",
    "which integrate observations and forecast modelling,\n",
    "can provide similar data consistently with long-term global coverage.\n",
    "For example, ECMWF's fifth-generation reanalysis _ERA5_ provides meteorological data on a global ~31 km grid\n",
    "going back to 1940 [[Soci+24](https://doi.org/10.1002/qj.4803), [Hersbach+20](https://doi.org/10.1002/qj.3803)].\n",
    "_ERA5 is used in parametric insurance_ [[Evenflow+24](https://climate.copernicus.eu/sites/default/files/2024-12/Value-generated-by-ERA5-full-report.pdf)]\n",
    "\n",
    "The Copernicus Climate Change Service (C3S)\n",
    "now provides pre-calculated SPI and SPEI indices derived from ERA5\n",
    "in the ERA5â€“Drought dataset [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)],\n",
    "[available from the Climate Data Store (CDS)](https://doi.org/10.24381/9bea5e16).\n",
    "This derived dataset can be a valuable resource for applications in many sectors,\n",
    "since it can be used out of the box,\n",
    "freeing users from the need to find and process the underpinning meteorological data themselves.\n",
    "ERA5â€“Drought provides monthly SPI and SPEI for 7 different accumulation periods,\n",
    "interpolated to a 0.25Â° Ã— 0.25Â° grid.\n",
    "It includes ERA5's deterministic reanalysis as well as 10 propagated members of the ERA5-EDA ensemble.\n",
    "The latter can be used to quantify the uncertainty in SPI or SPEI resulting from uncertainty in the input data.\n",
    "Moreover, ERA5â€“Drought provides multiple quality flags that can be used to filter data that do not meet the requirements for SPI or SPEI to be applicable.\n",
    "_Replace some of this paragraph with a description of the ensemble_\n",
    "\n",
    "[[Isaksen+10](https://doi.org/10.21957/obke4k60)]\n",
    "\n",
    "This quality assessment tests the uncertainty in SPI and SPEI values in ERA5â€“Drought ([_Monthly drought indices from 1940 to present derived from ERA5 reanalysis_](https://doi.org/10.24381/9bea5e16))\n",
    "dataset.\n",
    "What is the added value?\n",
    "Is the uncertainty sufficient to make it useful?\n",
    "\n",
    "The Standardised Precipitation Index (SPI) and Standardised Precipitation-Evapotranspiration Index (SPEI), readily derived from ECMWF's fifth-generation deterministic reanalysis ERA5 as well as a probabilistic ERA5-EDA ensemble, may be used to quantify an estimate the uncertainty in SPI or SPEI resulting from uncertainty in the input data.  This study evaluates how the uncertainty information from the ERA5-EDA ensemble can be directly integrated into the design and evaluation of drought evaluation tools. We assess their relevance for the agricultural and wider sector applications, particularly that with parametric insurance schemes that rely on weather data to underwrite cropâ€‘related risk. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ“¢ Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Finding 1\n",
    "* Finding 2\n",
    "* Finding 3\n",
    "* etc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ðŸ“‹ Methodology\n",
    "\n",
    "This quality assessment tests the reproducibility of drought indices in the ERA5â€“Drought\n",
    "([_Monthly drought indices from 1940 to present derived from ERA5 reanalysis_](https://doi.org/10.24381/9bea5e16))\n",
    "dataset\n",
    "from their origins in ERA5.\n",
    "\n",
    "This notebook provides Python code to download all 10 ensemble members of SPI/SPEI, compute ensemble uncertainty, classify drought severity for each member, and calculate a parametricâ€‘insurance payout based on an SPIâ€‘indexed crop insurance product.\n",
    "\n",
    "Example for Indonesia â€“ details in methodology [[World Bank Group+18](https://doi.org/10.1596/29784)]\n",
    "\n",
    "Discuss uncertainty\n",
    "Ensemble in ERA5 probes synoptic uncertainty due to random errors [[Hersbach+20](https://doi.org/10.1002/qj.3803)]\n",
    "[[Isaksen+10](https://doi.org/10.21957/obke4k60)]\n",
    "Note that ERA5â€“Drought uses the monthly means\n",
    "Note that SPI / SPEI introduce correlation on time dimension due to reference period\n",
    "Ensemble can be used with mean + standard deviation [[JCGM+08](https://doi.org/10.59161/JCGM101-2008)]\n",
    "Only 10 members so limited statistics â†’ use a per-member approach\n",
    "\n",
    "This notebook is set up so that the test sites and dates are easily customised,\n",
    "so you can download it and apply it to your preferred domain.\n",
    "\n",
    "**[](section-code_setup)**\n",
    " * Import all required libraries.\n",
    " * Define helper functions.\n",
    "\n",
    "**[](section-download)**\n",
    " * Download SPI and SPEI from ERA5â€“Drought.\n",
    " * Download quality flags from ERA5â€“Drought.\n",
    " * Pre-process data and quality flags.\n",
    "\n",
    "**[](section-timeseries)**\n",
    " * Analyse SPI and SPEI time series with and without quality flags.\n",
    "\n",
    "**[](section-insurance)**\n",
    " * abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-code_setup)=\n",
    "### 1. Code setup\n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data)) and visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data. Because earthkit is in active development, some functionality may change after this notebook is published. If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Import required libraries\n",
    "In this section, we import all the relevant packages needed for running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Input / Output\n",
    "from pathlib import Path\n",
    "import earthkit.data as ekd\n",
    "import warnings\n",
    "\n",
    "# General data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "\n",
    "# Analysis\n",
    "import calendar\n",
    "from scipy import stats\n",
    "\n",
    "# Visualisation\n",
    "import earthkit.plots as ekp\n",
    "from earthkit.plots.styles import Style\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib.lines import Line2D\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "from tqdm import tqdm  # Progress bars\n",
    "\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "\n",
    "# Visualisation in Jupyter book -- automatically ignored otherwise\n",
    "try:\n",
    "    from myst_nb import glue\n",
    "except ImportError:\n",
    "    glue = None\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Iterable, Optional\n",
    "from earthkit.data.readers.netcdf.fieldlist import NetCDFMultiFieldList\n",
    "from earthkit.plots.geo.domains import Domain\n",
    "AnyDomain = (Domain | str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "This section defines some functions and variables used in the following analysis, allowing code cells in later sections to be shorter and ensuring consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "##### Data (pre-)processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The following functions handle downloading data in specific circumstances, e.g. a geographical or temporal subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographical\n",
    "def request_data_for_one_site(*, lat, lon, half_width=0.25):\n",
    "    \"\"\" Return a CDS request for a bounding box around a point (lon, lat). \"\"\"\n",
    "    north, south = lat + half_width, lat - half_width\n",
    "    east , west  = lon + half_width, lon - half_width\n",
    "    box = [north, west, south, east]\n",
    "    box = [round(x, 2) for x in box]  # Round all coordinates to 2 digits\n",
    "    request_box = {\"area\": box}\n",
    "    return request_box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The following functions restructure the ensemble members in the ERA5â€“Drought dataset along a new dimension, as in ERA5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MONTHS = range(1, 13)  # January to December (inclusive)\n",
    "\n",
    "# Convert SPI or SPEI data from ERA5â€“Drought to ERA5 format\n",
    "def add_number_dimension(data: xr.Dataset, *, n_members: int=10,\n",
    "                         time_dimension: str=\"time\", ensemble_dimension: str=\"number\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Convert a dataset\n",
    "    from ERA5â€“Drought format (10-duplicate `time` dimension)\n",
    "    to ERA5 format (`number` dimension for ensemble members)\n",
    "    \"\"\"\n",
    "    # Find unique times and use these to generate datasets for successive members\n",
    "    member_numbers = np.arange(n_members)\n",
    "    _, index = np.unique(data[time_dimension], return_index=True)\n",
    "    data = [data.isel({time_dimension: index + i}) for i in member_numbers]\n",
    "\n",
    "    # Combine into one dataset\n",
    "    data = xr.concat(data, dim=ensemble_dimension).assign_coords(number=member_numbers)\n",
    "\n",
    "    # Rechunk for memory efficiency if multiple lat/lon\n",
    "    if \"lat\" in data.dims and \"lon\" in data.dims:\n",
    "        data = data.chunk({ensemble_dimension: n_members, time_dimension: 48, \"lat\": 360, \"lon\": 103,})\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_era5drought_ensemble(fieldlist: NetCDFMultiFieldList) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Pre-process ERA5â€“Drought ensemble data that were downloaded in batches.\n",
    "    Find and open the files in the `fieldlist`, convert them to ERA5 structure (`number` dimension),\n",
    "        then merge them together into an xarray Dataset.\n",
    "    \"\"\"\n",
    "    # Load data from file\n",
    "    filenames = [reader.path for reader in fieldlist._indexes]  # Extract file paths from the earthkit FieldList\n",
    "    datasets = [xr.open_dataset(path) for path in filenames]  # Open each file in xarray\n",
    "\n",
    "    # Pre-process individual files\n",
    "    processed = [add_number_dimension(data) for data in datasets]  # Add the number dimension to each dataset\n",
    "\n",
    "    # Combine and return\n",
    "    final = xr.combine_by_coords(processed, join=\"outer\", combine_attrs=\"drop\")  # Stack all datasets together\n",
    "    final = final.chunk({\"time\": -1})  # Rechunk to single time dimension\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "##### Categorising SPI and SPEI\n",
    "The following cell defines categories for SPI and SPEI values, e.g. \"severe drought\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES_SPI = [  # Approximates the GDO scheme\n",
    "    (   2.00, 100,     \"Extremely wet\",            \"#7a007b\"),  # deepest purple \n",
    "    (   1.50,   2.00,  \"Severely wet\",             \"#af51c3\"),  # dark purple\n",
    "    (   1.00,   1.50,  \"Moderately wet\",           \"#eaccf8\"),  # medium purple\n",
    "    (   0.00,   1.00,  \"Nearâ€‘normal / mildly wet\", \"#ffffff\"),  # white\n",
    "    (  -1.00,   0.00,  \"Nearâ€‘normal / mildly dry\", \"#ffffff\"),  # white\n",
    "    (  -1.50,  -1.00,  \"Moderately dry\",           \"#fffc03\"),  # yellow\n",
    "    (  -2.00,  -1.50,  \"Severely dry\",             \"#feaa00\"),  # orange\n",
    "    (-100,     -2.00,  \"Extremely dry\",            \"#ff0100\"),  # red\n",
    "]\n",
    "\n",
    "CATEGORIES_SPEI = [\n",
    "    (   2.33, 100,    \"Extremely wet\",  \"#01148b\"),  # very dark navy\n",
    "    (   1.65,   2.33, \"Severely wet\",   \"#1871de\"),  # strong blue\n",
    "    (   1.28,   1.65, \"Moderately wet\", \"#14acf4\"),  # medium blue\n",
    "    (   0.84,   1.28, \"Mildly wet\",     \"#00f2fe\"),  # cyan\n",
    "    (  -0.84,   0.84, \"Near-normal\",    \"#9afa93\"),  # light green\n",
    "    (  -1.28,  -0.84, \"Mildly dry\",     \"#fdc403\"),  # yellow\n",
    "    (  -1.65,  -1.28, \"Moderately dry\", \"#f2631d\"),  # orange\n",
    "    (  -2.33,  -1.65, \"Severely dry\",   \"#df2929\"),  # red\n",
    "    (-100,     -2.33, \"Extremely dry\",  \"#8c1b1a\"),  # dark red\n",
    "]\n",
    "\n",
    "CATEGORIES = {\"SPI\": CATEGORIES_SPI, \"SPEI\": CATEGORIES_SPEI,}  # Combined dictionary for easy access\n",
    "\n",
    "# ERA5â€“Drought provides data in former format (SPI6)\n",
    "# But figures should be labelled in the latter (SPI-6)\n",
    "INDEXES_NAMED = {\"SPI6\": \"SPI-6\", \"SPEI6\": \"SPEI-6\",}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The following functions categorise SPI / SPEI values into said categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _digitise_dataset(data: xr.Dataset, bin_edges: list[float], *, persist=True) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Digitise all variables in `data` according to a list of left bin edges, e.g. SPI categories (\"extremely dry\").\n",
    "    In this notebook, do not call this function directly, but use the categorise_dataset wrapper.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform digitisation\n",
    "    data_digitised = xr.apply_ufunc(np.digitize, data,\n",
    "                                    kwargs={\"bins\": bin_edges, \"right\": False}, \n",
    "                                    input_core_dims=[[]],\n",
    "                                    vectorize=True, dask=\"parallelized\",\n",
    "                                    output_dtypes=[np.uint8],  # uint8 is small; not suitable for >256 categories\n",
    "    )\n",
    "\n",
    "    # Persist in memory if desired (default True because uint8s are small)\n",
    "    if persist:\n",
    "        data_digitised = data_digitised.persist()\n",
    "    \n",
    "    return data_digitised\n",
    "\n",
    "def categorise_dataset(data: xr.Dataset, categories: Iterable[Iterable], **kwargs) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Categorise a dataset into bins defined by category thresholds.\n",
    "    Extracts bin edges from `categories` and then digitises `data` accordingly.\n",
    "    Handles NaNs by adding a dummy category (extremely high bin edge).\n",
    "    \"\"\"\n",
    "    # Extract bin edges from categories\n",
    "    # Last element is dropped to extend range to infinity (although values should be clipped anyway)\n",
    "    bin_edges = [category[0] for category in categories[:-1]]\n",
    "\n",
    "    # Add dummy category to catch NaNs\n",
    "    bin_edges = [100000] + bin_edges\n",
    "\n",
    "    # Apply digitisation\n",
    "    data_categorised = _digitise_dataset(data, bin_edges, **kwargs)\n",
    "\n",
    "    return data_categorised\n",
    "\n",
    "# TO DO: Is this only relevant to regional analysis?\n",
    "def get_unique_counts_per_timestamp(da_cat):\n",
    "    \"\"\"Return unique values and counts of drought severity category per timestamp.\"\"\"\n",
    "    unique_vals = []\n",
    "    counts_per_timestamp = []\n",
    "    \n",
    "    for col in da_cat.T:  # iterate over columns (timestamps)\n",
    "        vals, counts = np.unique(col, return_counts=True)\n",
    "        unique_vals.append(vals)\n",
    "        counts_per_timestamp.append(counts)\n",
    "    return unique_vals, counts_per_timestamp\n",
    "\n",
    "def get_filtered_counts_per_timestamp(counts_per_timestamp, unique_vals, threshold = 6):\n",
    "    \"\"\"Return categories of interest and counts of category per column (timestamp).\"\"\"\n",
    "\n",
    "    filtered_counts = []\n",
    "    filtered_cats = []\n",
    "\n",
    "    for c_count, c_cat in zip(counts_per_timestamp, unique_vals):\n",
    "        idx = np.where(c_cat >= threshold)  # indices where category >= threshold\n",
    "        filtered_cats.append(c_cat[idx])\n",
    "        filtered_counts.append(c_count[idx])\n",
    "\n",
    "    return filtered_cats, filtered_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "##### Quality flags\n",
    "The following functions apply the quality flags included in ERA5â€“Drought, such as the probability of zero precipitation and the Shapiroâ€“Wilk normality test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "P0_THRESHOLD = 0.1  # Threshold for masking based on p0 (probability of zero precipitation); from Keune+25\n",
    "\n",
    "# Functions\n",
    "def apply_quality_mask(sig, index_ds):\n",
    "    \"\"\"\n",
    "    Apply a monthly quality mask to a drought index dataset.\n",
    "    Aligns mask and data by month and sets values outside the mask to NaN.\n",
    "    \"\"\"\n",
    "\n",
    "    # 12â€‘month mask -> month dimension\n",
    "    sig_m = sig.assign_coords(\n",
    "        month=(\"time\", sig.time.dt.month.values)\n",
    "    ).swap_dims({\"time\": \"month\"}).drop_vars(\"time\")\n",
    "\n",
    "    # add month to drought dataset\n",
    "    index_ds = index_ds.assign_coords(\n",
    "        month=index_ds.time.dt.month\n",
    "    )\n",
    "\n",
    "    # broadcast mask\n",
    "    mask_full = sig_m.sel(month=index_ds.month)\n",
    "\n",
    "    # apply\n",
    "    return index_ds.where(mask_full == 1)\n",
    "\n",
    "def extract_flags(ds_flag, p_zero_thresh):\n",
    "    sig = (ds_flag['significance'] == 1)\n",
    "    p0  = (ds_flag['pzero'] <= p_zero_thresh)\n",
    "    return sig, p0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "##### Statistics\n",
    "The following functions perform statistics on the ensemble datasets, both calculating the mean and standard deviation in ensemble members, and the drought severity category they fall in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Add number of valid ensemble members\n",
    "# \"reduce_ensemble\"?\n",
    "def ensemble_mean_and_spread(data: xr.Dataset, *, number_dim: str=\"number\") -> tuple[xr.Dataset, xr.Dataset]:\n",
    "    \"\"\" Calculate the mean and spread within an ensemble along the number dimension. \"\"\"\n",
    "    # Calculate mean\n",
    "    mean = data.mean(number_dim)\n",
    "\n",
    "    # Calculate spread\n",
    "    spread = data.std(number_dim)\n",
    "\n",
    "    return mean, spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "##### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "The following cell contains some base helper functions (e.g. displaying in Jupyter Notebook or Jupyter Book style, adding textboxes with consistent formatting, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation: Helper functions, general\n",
    "def _glue_or_show(fig, glue_label=None):\n",
    "    try:\n",
    "        glue(glue_label, fig, display=False)\n",
    "    except TypeError:\n",
    "        plt.show()\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def _add_textbox_to_subplots(text: str, *axs: plt.Axes | ekp.Subplot, right=False) -> None:\n",
    "    \"\"\" Add a text box to each of the specified subplots. \"\"\"\n",
    "    # Get the plt.Axes for each ekp.Subplot\n",
    "    axs = [subplot.ax if isinstance(subplot, ekp.Subplot) else subplot for subplot in axs]\n",
    "\n",
    "    # Set up location\n",
    "    x = 0.95 if right else 0.05\n",
    "    horizontalalignment = \"right\" if right else \"left\"\n",
    "\n",
    "    # Add the text\n",
    "    for ax in axs:\n",
    "        ax.text(x, 0.95, text, transform=ax.transAxes,\n",
    "        horizontalalignment=horizontalalignment, verticalalignment=\"top\",\n",
    "        bbox={\"facecolor\": \"white\", \"edgecolor\": \"black\", \"boxstyle\": \"round\",\n",
    "              \"alpha\": 1})\n",
    "\n",
    "def plot_zero_line(*axs: plt.Axes) -> None:\n",
    "    \"\"\" Plot the y=0 line with consistent styling. \"\"\"\n",
    "    for ax in axs:\n",
    "        ax.axhline(0, color=\"black\", zorder=1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "The following functions display time series of the deterministic reanalysis and ensemble members:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Display SPI / SPEI categories\n",
    "def plot_index_categories(ax: plt.Axes, categories: Iterable[Iterable]) -> None:\n",
    "    \"\"\" Display SPI / SPEI categories (e.g. \"extreme drought\") on an Axes panel. \"\"\"\n",
    "    for low, high, label, colour in categories:\n",
    "        ax.axhspan(low, high, facecolor=colour, edgecolor=None, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for visualisation\n",
    "kwargs_reanalysis = {\"color\": \"yellow\",\n",
    "                     \"linewidth\": 1,\n",
    "                     \"path_effects\": [path_effects.Stroke(linewidth=2, foreground=\"black\", alpha=0.7), path_effects.Normal(), ],\n",
    "                    }\n",
    "kwargs_ensemble_members = {\"color\": \"black\",\n",
    "                           \"alpha\": 1,\n",
    "                           \"linewidth\": 1,\n",
    "                          }\n",
    "\n",
    "# Plot members as individual lines\n",
    "def plot_ensemble_members(data_ensemble: xr.Dataset, var: str, *,\n",
    "                          data_reanalysis: Optional[xr.Dataset]=None,\n",
    "                          time_dimension: str=\"time\", ensemble_dimension: str=\"number\",\n",
    "                          title: Optional[str]=\"\",\n",
    "                          glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\" Display ensemble members (and optionally deterministic reanalysis) time series for one variable `var`. \"\"\"\n",
    "    # Find indicator name and colours from `var`\n",
    "    var_label = INDEXES_NAMED[var]\n",
    "    indicator = var_label.split(\"-\")[0]  # e.g. SPI-6 -> SPI\n",
    "    var_categories = CATEGORIES[indicator]\n",
    "\n",
    "    # Setup: Figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 4), layout=\"constrained\")\n",
    "\n",
    "    # Display individual members\n",
    "    data_ensemble[var].plot.line(ax=ax, x=time_dimension, **kwargs_ensemble_members, add_legend=False)\n",
    "\n",
    "    # Create dummy lines for legend\n",
    "    lines_for_legend = [Line2D([0], [0], **kwargs_ensemble_members), ]\n",
    "    labels_for_legend = [\"Ensemble members\", ]\n",
    "\n",
    "    # Optional: Display reanalysis\n",
    "    if data_reanalysis:\n",
    "        (line_reanalysis,) = data_reanalysis[var].plot.line(ax=ax, x=time_dimension, **kwargs_reanalysis)\n",
    "        lines_for_legend.append(line_reanalysis)\n",
    "        labels_for_legend.append(\"Deterministic reanalysis\")\n",
    "\n",
    "    # Display categories and 0 line\n",
    "    plot_index_categories(ax, var_categories)\n",
    "    plot_zero_line(ax)\n",
    "\n",
    "    # Decorate figure\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim([-8, 8])\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(var_label)\n",
    "    ax.legend(lines_for_legend, labels_for_legend, loc=\"lower right\")\n",
    "\n",
    "    # Show result\n",
    "    _glue_or_show(fig, glue_label)\n",
    "\n",
    "\n",
    "def plot_spread(mean_da: xr.DataArray, spread_da: xr.DataArray, xaxis = \"time\",\n",
    "                title: str = \"SPI-12 Mean with Shaded Spread\"):\n",
    "\n",
    "    da_lo = mean_da - spread_da\n",
    "    da_hi = mean_da + spread_da\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax.fill_between(\n",
    "        mean_da[xaxis].values,\n",
    "        da_lo.values,\n",
    "        da_hi.values,\n",
    "        label=\"Â±1 ST.D\",\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(mean_da.name)\n",
    "    ax.set_ylim([-8, 8])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def plot_bar_with_payout(da, payout_mean, payout_std, title=\"Aggregate Ensemble SPI6\"):\n",
    "    \"\"\"\n",
    "    Plot ensemble SPI time series (black lines) with payout mean Â± std as bars.\n",
    "    \"\"\"\n",
    "    series = payout_mean.to_series()\n",
    "    errors = payout_std.to_series()\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # --- Ensemble members (black lines) ---\n",
    "    for m in da['number'].values:\n",
    "        ax1.plot(\n",
    "            da['year'].values,\n",
    "            da.sel(number=m).values,\n",
    "            color='black',\n",
    "            linewidth=1.2,\n",
    "            alpha=0.9,\n",
    "            zorder=5\n",
    "        )\n",
    "\n",
    "    hline =  ax1.axhline(-5, color=\"red\", linestyle=\"--\", linewidth=1.2, label= \"Trigger\")\n",
    "    ax1.set_title(title)\n",
    "    ax1.set_xlabel(\"Year\")\n",
    "    ax1.set_ylabel(str(da.name) if da.name else \"SPI\")\n",
    "    ax1.set_ylim([-30, 30])\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_zorder(5)\n",
    "    ax1.patch.set_alpha(0)\n",
    "\n",
    "    # --- Payout axis (bars behind) ---\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Payout (million USD)\")\n",
    "    ax2.set_zorder(1)\n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ax2.set_ylim([0, 35])\n",
    "    ax2.grid(False)\n",
    "\n",
    "    x = series.index\n",
    "    y = series.values\n",
    "    yerr = errors.reindex(series.index).values\n",
    "\n",
    "    money_color = \"#2ecc71\"\n",
    "\n",
    "    ax2.bar(\n",
    "        x, y,\n",
    "        yerr=yerr,\n",
    "        color=money_color,\n",
    "        edgecolor=\"black\",\n",
    "        capsize=4,\n",
    "        ecolor=\"black\",\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "    # Legend handles\n",
    "    line_handle = ax1.lines[0]\n",
    "    bar_handle = ax2.bar([0], [0], color=money_color, edgecolor=\"black\", alpha=0.5)[0]\n",
    "\n",
    "    ax1.legend(\n",
    "        [line_handle, bar_handle, hline],\n",
    "        [\"Ensemble SPI members\", \"Insurance payout (mean Â± std)\", \"Trigger\"],\n",
    "        loc=\"upper right\"\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_with_payout(da, payout, title=\"Aggregate Ensemble SPI6\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # --- Ensemble members ---\n",
    "    for m in da['number'].values:\n",
    "        ax1.plot(\n",
    "            da['year'].values,\n",
    "            da.sel(number=m).values,\n",
    "            color='black',\n",
    "            linewidth=1.2,\n",
    "            alpha=0.9,\n",
    "            zorder=5\n",
    "        )\n",
    "\n",
    "    ax1.set_title(title)\n",
    "    ax1.set_xlabel(\"Year\")\n",
    "    ax1.set_ylabel(str(da.name) if da.name else \"SPI\")\n",
    "    ax1.set_ylim([-30, 30])\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Horizontal line (store handle + label)  <-- NEW: keep handle for legend\n",
    "    hline = ax1.axhline(-5, color=\"red\", linestyle=\"--\", linewidth=1.2, label=\"Trigger -5\")\n",
    "\n",
    "    # --- Payout axis ---\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Payout (million USD)\")\n",
    "    ax2.set_ylim([0, 35])\n",
    "    ax2.grid(False)\n",
    "\n",
    "    money_color = \"#2ecc71\"\n",
    "    years = payout['year'].values\n",
    "    box_data = [payout.sel(year=y).dropna(\"number\").values for y in years]\n",
    "\n",
    "    bp = ax2.boxplot(\n",
    "        box_data,\n",
    "        positions=years,\n",
    "        vert=True,\n",
    "        patch_artist=True,\n",
    "        showfliers=True,\n",
    "        boxprops=dict(facecolor=money_color, color=\"black\"),\n",
    "        medianprops=dict(color=\"black\"),\n",
    "        flierprops=dict(marker='o', markersize=4, markerfacecolor='none',\n",
    "                        markeredgecolor=money_color, linestyle='none')\n",
    "    )\n",
    "\n",
    "    ax1.set_xticks(years[::10])\n",
    "    ax1.set_xticklabels(years[::10], ha=\"right\")\n",
    "\n",
    "    # Legend\n",
    "    line_handle = ax1.lines[0]\n",
    "\n",
    "    # Proxy for the box (keep your existing style)\n",
    "    proxy_box = plt.Line2D([0], [0], color= money_color, linewidth=8)\n",
    "\n",
    "    flier_proxy = plt.Line2D(\n",
    "        [0], [0],\n",
    "        marker='o', linestyle='none',\n",
    "        markerfacecolor='none', markeredgecolor=money_color, markersize=6\n",
    "    )\n",
    "\n",
    "    ax1.legend(\n",
    "        [line_handle, proxy_box, flier_proxy, hline],\n",
    "        [\"Ensemble SPI members\", \"Insurance payout (median + IQR)\", \"Outliers\", \"Trigger\"],\n",
    "        loc=\"upper right\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "##### Payout statistics\n",
    "The following cell computes statistics for the payout function in the parametric insurance use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_months(ds, n_months=4, time_axis = \"time\"):\n",
    "    \"\"\"\n",
    "    Aggregates the first N calendar months of each year \n",
    "    by summing over the selected months.\n",
    "    \"\"\"\n",
    "    agg_ds = ds.sel(time = ds[time_axis].dt.month.isin(range(n_months))) # select first N months.\n",
    "    agg_ds = agg_ds.groupby(\"time.year\").sum(\"time\") # Sum over first N months.\n",
    "    \n",
    "    return agg_ds\n",
    "\n",
    "def payout_function(agg_ds, threshold= -5, exit=-30, tick_size=6666667, money_unit=1e6):\n",
    "    \"\"\"\n",
    "    Computes payouts for a parametric drought insurance contract\n",
    "    following trigger, exit and capped losses.\n",
    "    \"\"\"\n",
    "    \n",
    "    less = agg_ds.where(agg_ds <= threshold, threshold) \n",
    "    \n",
    "    diff = abs(less - (threshold))   # positive means loss (-8 - (-5)) = -3\n",
    "\n",
    "    payout = (diff * tick_size) / money_unit\n",
    "\n",
    "    payout = payout.where(payout <= 100)\n",
    "\n",
    "    payout_mean = payout.mean(\"number\")\n",
    "    payout_std  = payout.std(\"number\")\n",
    "\n",
    "    payout_mean = payout_mean.fillna(0)\n",
    "    payout_std = payout_std.fillna(0)\n",
    "\n",
    "    return payout, payout_mean, payout_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-download)=\n",
    "### 2. Download data\n",
    "#### General setup\n",
    "This notebook uses [earthkit-data](https://github.com/ecmwf/earthkit-data) to download files from the CDS.\n",
    "If you intend to run this notebook multiple times, it is highly recommended that you [enable caching](https://earthkit-data.readthedocs.io/en/latest/guide/caching.html) to prevent having to download the same files multiple times.\n",
    "If you prefer not to use earthkit, the following requests can also be used with the [cdsapi module](https://cds.climate.copernicus.eu/how-to-api#linux-use-client-step).\n",
    "In either case (earthkit-data or cdsapi), it is required to set up a CDS account and API key as explained [on the CDS website](https://cds.climate.copernicus.eu/how-to-api).\n",
    "\n",
    "We will be downloading different types of data\n",
    "(drought indicators and quality flags, deterministic reanalysis and ensemble)\n",
    "in this notebook.\n",
    "CDS data requests take the form of dictionaries in Python.\n",
    "When taking multiple requests,\n",
    "it is convenient to define some constants and set up _template_ requests with default parameters.\n",
    "In this section, we define our template containing those parameters that are constant between datasets: the domain in time and space.\n",
    "This way, these are guaranteed to be consistent between downloads and only need to be changed in one place if you wish to modify the notebook for your own use case.\n",
    "\n",
    "In this example, we will be looking at data for one site in Indonesia in 1960â€“2024.\n",
    "We want to download SPI, SPEI, and the associated quality flags\n",
    "for the 6-month accumulation window only.\n",
    "The site, accumulation period and timespan are defined in the following cell,\n",
    "and can be edited when running this notebook yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your preferred site (lat/lon)\n",
    "site = {\"lat\": -7.25, \"lon\": 109.75}\n",
    "site_name = \"Central Java\"\n",
    "\n",
    "# Define your preferred variables (SPI and/or SPEI; both by default)\n",
    "indicators = [\"SPI\", \"SPEI\"]\n",
    "indicators_long = [\"standardised_precipitation_index\", \"standardised_precipitation_evapotranspiration_index\"]  # CDS request format\n",
    "\n",
    "# Define your preferred accumulation period, e.g. `6` for SPI-6\n",
    "# ERA5â€“Drought provides the following options: 1, 3, 6, 12, 24, 36, 48\n",
    "accumulation_period = 6  # Months\n",
    "\n",
    "# Define your preferred analysis and reference periods\n",
    "years = (1960, 2024)  # Years for the analysis (inclusive)\n",
    "\n",
    "# Derived variables for convenience\n",
    "# Example site\n",
    "label_site = f\"{site_name} ({site['lat']:.2f} Â°N, {site['lon']:.2f} Â°E)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "The CDS request template is then defined using the values defined above.\n",
    "Additional information to download specific data variables will be mixed into this template in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDS catalogue entry\n",
    "ID_ERA5_DROUGHT = \"derived-drought-historical-monthly\"\n",
    "\n",
    "# Add margins around central location to make downloading and pre-processing easier\n",
    "request_site = request_data_for_one_site(**site)  \n",
    "\n",
    "# Main template\n",
    "request_era5drought_template = {\n",
    "    \"version\": \"1_0\",\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"accumulation_period\": [f\"{accumulation_period}\", ],\n",
    "    \"year\": [f\"{year}\" for year in range(years[0], years[1]+1)],\n",
    "    \"month\": [f\"{month:02}\" for month in MONTHS],\n",
    "} | request_site\n",
    "\n",
    "# Templates for reanalysis, ensemble\n",
    "request_reanalysis = request_era5drought_template | {\"product_type\": [\"reanalysis\"],}\n",
    "request_ensemble   = request_era5drought_template | {\"product_type\": [\"ensemble_members\"],}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### Download SPI and SPEI\n",
    "First,\n",
    "the SPI-6 and SPEI-6 time series\n",
    "in the deterministic reanalysis and ensemble\n",
    "are downloaded from the CDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Define request for variables\n",
    "# (SPI-6 and SPEI-6 in this notebook)\n",
    "request_indicators = {\"variable\": indicators_long}\n",
    "\n",
    "# Define requests for reanalysis and ensemble based on templates defined earlier\n",
    "request_indicators_reanalysis = request_reanalysis | request_indicators\n",
    "request_indicators_ensemble   = request_ensemble   | request_indicators\n",
    "\n",
    "# Download data and load into xarray\n",
    "data_indicators_reanalysis = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_indicators_reanalysis)  # Download as field list\n",
    "data_indicators_reanalysis = data_indicators_reanalysis.to_xarray(compat=\"equals\").load()  # Convert to xarray dataset, without dask\n",
    "\n",
    "data_indicators_ensemble   = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_indicators_ensemble)  # Download as field list\n",
    "data_indicators_ensemble   = data_indicators_ensemble.to_xarray(compat=\"equals\").load()  # Convert to xarray dataset, without dask\n",
    "\n",
    "# Extract desired site only\n",
    "data_indicators_reanalysis = data_indicators_reanalysis.sel(**site)\n",
    "data_indicators_ensemble   = data_indicators_ensemble.sel(**site)\n",
    "\n",
    "# Display in notebook\n",
    "data_indicators_reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Unlike ERA5, ERA5â€“Drought does not come with a `number` dimension representing the ensemble members.\n",
    "Instead, they are accessible via the `time` dimension, which has 10 entries (representing the 10 members) at each point in time.\n",
    "For convience, we re-organise the dataset to include a `number` dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number dimension\n",
    "data_indicators_ensemble = add_number_dimension(data_indicators_ensemble)\n",
    "\n",
    "# Display in notebook\n",
    "data_indicators_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### Download quality flags\n",
    "ERA5â€“Drought includes quality flags that can be used to mask low-quality data.\n",
    "The first is the probability of zero precipitation (_p{sub}`0`_),\n",
    "which counts the number of years in the reference period (1991â€“2020) in which there was 0 precipitation in a given calendar month (e.g. January).\n",
    "This flag is only applicable to SPI,\n",
    "where the authors recommend masking any data with _p{sub}`0`_ > 0.1 [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "The second is the normality _Î±_,\n",
    "derived using the Shapiroâ€“Wilk test [[Shapiro+65](https://doi.org/10.1093/biomet/52.3-4.591)].\n",
    "This _Î±_ quantifies how well the computed SPI or SPEI values\n",
    "in the reference period\n",
    "(1991â€“2020)\n",
    "are described by a standard normal distribution.\n",
    "The mask in ERAâ€“Drought uses a threshold of 0.05, meaning points where _Î±_ < 0.05 are rejected.\n",
    "\n",
    "The three quality flags (_p{sub}`0`_ for SPI, _Î±_ for SPI, and _Î±_ for SPEI) are downloaded from the CDS for the reanalysis and ensemble.\n",
    "Note that ERA5â€“Drought provides the quality flags with timestamps for 2020\n",
    "(2020-01-01, 2020-02-01, etc.)\n",
    "to fit into the datetime format, which requires a year and day.\n",
    "However, the flags are applicable to the corresponding calendar month\n",
    "(January, February, etc.)\n",
    "across the entire timespan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Define request for p0\n",
    "request_p0 = {\"variable\": [\"probability_of_zero_precipitation_spi\"], }\n",
    "request_p0_reanalysis = request_reanalysis | request_p0  # Note: request_reanalysis specifies years but these are ignored\n",
    "request_p0_ensemble   = request_ensemble   | request_p0\n",
    "\n",
    "# Download data and load into xarray\n",
    "data_p0_reanalysis = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_p0_reanalysis)  # Download as field list\n",
    "data_p0_reanalysis = data_p0_reanalysis.to_xarray(compat=\"equals\").load()  # Convert to xarray dataset, without dask\n",
    "\n",
    "data_p0_ensemble   = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_p0_ensemble)  # Download as field list\n",
    "data_p0_ensemble   = data_p0_ensemble.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "data_p0_ensemble   = add_number_dimension(data_p0_ensemble).load()  # Add number dimension, load without dask\n",
    "\n",
    "# Extract desired site only\n",
    "data_p0_reanalysis = data_p0_reanalysis.sel(**site)\n",
    "data_p0_ensemble   = data_p0_ensemble.sel(**site)\n",
    "\n",
    "# Generate mask: Allow data where p0 < 0.1\n",
    "mask_p0_reanalysis = (data_p0_reanalysis < P0_THRESHOLD)\n",
    "mask_p0_ensemble   = (data_p0_ensemble   < P0_THRESHOLD)\n",
    "\n",
    "# Display in notebook\n",
    "mask_p0_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Define request for normality\n",
    "request_normality = {\"variable\": [\"test_for_normality_spi\"],  }\n",
    "request_normality_reanalysis = request_reanalysis | request_normality  # Note: request_reanalysis specifies years but these are ignored\n",
    "request_normality_ensemble   = request_ensemble   | request_normality\n",
    "\n",
    "# Download data and load into xarray\n",
    "mask_normality_reanalysis = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_normality_reanalysis)  # Download as field list\n",
    "mask_normality_reanalysis = mask_normality_reanalysis.to_xarray(compat=\"equals\").load()  # Convert to xarray dataset, without dask\n",
    "\n",
    "mask_normality_ensemble   = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_normality_ensemble)  # Download as field list\n",
    "mask_normality_ensemble   = mask_normality_ensemble.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "mask_normality_ensemble   = add_number_dimension(mask_normality_ensemble).load()  # Add number dimension, load without dask\n",
    "\n",
    "# Extract desired site only\n",
    "mask_normality_reanalysis = mask_normality_reanalysis.sel(**site)\n",
    "mask_normality_ensemble   = mask_normality_ensemble.sel(**site)\n",
    "\n",
    "# Convert to boolean mask\n",
    "mask_normality_reanalysis = mask_normality_reanalysis.astype(bool)\n",
    "mask_normality_ensemble   = mask_normality_ensemble.astype(bool)\n",
    "\n",
    "# Display in notebook\n",
    "mask_normality_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Define request for normality\n",
    "request_normality = {\"variable\": [\"test_for_normality_spei\"],  }\n",
    "request_normality_reanalysis = request_reanalysis | request_normality  # Note: request_reanalysis specifies years but these are ignored\n",
    "request_normality_ensemble   = request_ensemble   | request_normality\n",
    "\n",
    "# Download data and load into xarray\n",
    "mask_normality_reanalysis = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_normality_reanalysis)  # Download as field list\n",
    "mask_normality_reanalysis = mask_normality_reanalysis.to_xarray(compat=\"equals\").load()  # Convert to xarray dataset, without dask\n",
    "\n",
    "mask_normality_ensemble   = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_normality_ensemble)  # Download as field list\n",
    "mask_normality_ensemble   = mask_normality_ensemble.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "mask_normality_ensemble   = add_number_dimension(mask_normality_ensemble).load()  # Add number dimension, load without dask\n",
    "\n",
    "# Extract desired site only\n",
    "mask_normality_reanalysis = mask_normality_reanalysis.sel(**site)\n",
    "mask_normality_ensemble   = mask_normality_ensemble.sel(**site)\n",
    "\n",
    "# Convert to boolean mask\n",
    "mask_normality_reanalysis = mask_normality_reanalysis.astype(bool)\n",
    "mask_normality_ensemble   = mask_normality_ensemble.astype(bool)\n",
    "\n",
    "# Display in notebook\n",
    "mask_normality_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Note that for the given location\n",
    "(Central Java),\n",
    "most of the data are not masked.\n",
    "The SPI normality mask is triggered for several months for some members\n",
    "(e.g. October for member 0),\n",
    "the other masks are never triggered.\n",
    "This will change if you run this notebook for a different site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "(section-timeseries)=\n",
    "### 3. Time series analysis\n",
    "#### SPI and SPEI time series\n",
    "As a first step,\n",
    "we examine the time series of SPI and SPEI\n",
    "to get an intuition for\n",
    "the climatology of this site\n",
    "and\n",
    "the spread of the ensemble.\n",
    "First, this is done without applying quality flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to plot SPI and SPEI\n",
    "for indicator in indicators:\n",
    "    # Set up label for Jupyter-book; can be ignored when running your own analysis\n",
    "    glue_label = f\"indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-{indicator.lower()}-noflags\"\n",
    "\n",
    "    # Plot time series\n",
    "    plot_ensemble_members(data_indicators_ensemble, f\"{indicator}{accumulation_period}\",\n",
    "                          data_reanalysis=data_indicators_reanalysis,\n",
    "                          title=f\"ERA5â€“Drought {indicator}-{accumulation_period} at {label_site}\",\n",
    "                          glue_label=glue_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} SPI-6\n",
    ":sync: spi\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spi-noflags\n",
    ":name: \"indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spi-noflags\"\n",
    "\n",
    "SPI-6 time series in one site,\n",
    "showing the deterministic reanalysis (yellow) and the 10 ensemble members (black, overlaid with transparency).\n",
    "Colours in the background correspond to SPI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "Quality flags are not applied.\n",
    "```\n",
    ":::\n",
    ":::{tab-item} SPEI-6\n",
    ":sync: spei\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spei-noflags\n",
    ":name: \"indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spei-noflags\"\n",
    "\n",
    "SPEI-6 time series in one site,\n",
    "showing the deterministic reanalysis (yellow) and the 10 ensemble members (black, overlaid with transparency).\n",
    "Colours in the background correspond to SPEI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "Quality flags are not applied.\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "The time series for\n",
    "SPI\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spi-noflags>`)\n",
    "and SPEI\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spei-noflags>`)\n",
    "both show good overall agreement between the deterministic reanalysis and the ensemble members.\n",
    "The spread in the ensemble varies over time.\n",
    "However, the time series for SPI shows several spikes in the reanalysis and some ensemble members,\n",
    "indicating that low-quality data should be filtered.\n",
    "To this end, we apply the _p{sub}`0`_ and _Î±_ quality flags and examine the resulting time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to plot SPI and SPEI\n",
    "for indicator in indicators:\n",
    "    # Set up label for Jupyter-book; can be ignored when running your own analysis\n",
    "    glue_label = f\"indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-{indicator.lower()}\"\n",
    "\n",
    "    # Plot time series\n",
    "    plot_ensemble_members(data_indicators_ensemble, f\"{indicator}{accumulation_period}\",\n",
    "                          data_reanalysis=data_indicators_reanalysis,\n",
    "                          title=f\"ERA5â€“Drought {indicator}-{accumulation_period} at {label_site}\",\n",
    "                          glue_label=glue_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} SPI-6\n",
    ":sync: spi\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spi\n",
    ":name: \"indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spi\"\n",
    "\n",
    "SPI-6 time series in one site,\n",
    "showing the deterministic reanalysis (yellow) and the 10 ensemble members (black, overlaid with transparency).\n",
    "Colours in the background correspond to SPI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "Quality flags are not applied.\n",
    "```\n",
    ":::\n",
    ":::{tab-item} SPEI-6\n",
    ":sync: spei\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spei\n",
    ":name: \"indicator_derived-drought-historical-monthly_uncertainty_q01_fig-timeseries-spei\"\n",
    "\n",
    "SPEI-6 time series in one site,\n",
    "showing the deterministic reanalysis (yellow) and the 10 ensemble members (black, overlaid with transparency).\n",
    "Colours in the background correspond to SPEI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "Quality flags are not applied.\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5drought_ensemble_spi_mean_12, era5drought_ensemble_spi_spread_12 = ensemble_mean_and_spread(spi12_masked)\n",
    "era5drought_ensemble_spi_mean_1, era5drought_ensemble_spi_spread_1 = ensemble_mean_and_spread(spi1_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig6, p06 = extract_flags(indo_ds_spi_flag_ens_6, P_ZERO_THRESH)\n",
    "\n",
    "spi6 = indo_ds_ens_6[\"SPI6\"]\n",
    "\n",
    "spi6_sig = apply_quality_mask(sig6, spi6)\n",
    "indo_spi6_masked = apply_quality_mask(p06, spi6_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_da = spi12_masked.sel(**example_site)  # select the DataArray for SPI12.\n",
    "plot_ens_index_timeseries(spi_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Next we categorise each ensemble member in the SPI time series for the example site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_cat = categorise_dataset(spi_da, CATEGORIES_SPI) # categorise each ensemble member."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "This obtains a drought classification time series for all 10 ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals, counts_per_timestamp = get_unique_counts_per_timestamp(da_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Next we filter the counts so we only look at dry event (defined as moderately dry or higher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cats, filtered_counts = get_filtered_counts_per_timestamp(counts_per_timestamp, unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "The plot below shows the number of ensemble members that fall into each category per timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_spei12 = xr.where(spei_flag_ens_12['significance'] == 1, 1, 0)  # set spi12 flag xarrays\n",
    "sig_spei1 = xr.where(spei_flag_ens_1['significance'] == 1, 1, 0)  # TODO: Don't need to use xr.where\n",
    "\n",
    "spei12, spei1 = spi_ens_12[\"SPEI12\"], spi_ens_1[\"SPEI1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "spei12_masked = apply_quality_mask(sig_spei12, spei12) \n",
    "spei1_masked = apply_quality_mask(sig_spei1, spei1) # apply significance masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_site = spei12_masked.sel(**example_site)  # select the DataArray\n",
    "\n",
    "plot_ens_index_timeseries(spei_site, title = 'SPEI12 â€” time series for each ensemble member') # TODO, put reanalysis in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "The mean & spread for the SPEI time series in the example site is then computed and plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5drought_ensemble_spei_mean_12, era5drought_ensemble_spei_spread_12 = ensemble_mean_and_spread(spei12_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_da_mean = era5drought_ensemble_spei_mean_12.sel(**example_site)\n",
    "spei_da_spread = era5drought_ensemble_spei_spread_12.sel(**example_site)\n",
    "\n",
    "fig, ax = plot_spread(spei_da_mean, spei_da_spread, title = 'SPEI-12 Mean with Shaded Spread\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_da_cat = categorise_dataset(spei_site, CATEGORIES_SPEI) # categorise each ensemble member.\n",
    "spei_unique_vals, spei_counts_per_timestamp = get_unique_counts_per_timestamp(spei_da_cat)\n",
    "spei_filtered_cats, spei_filtered_counts = get_filtered_counts_per_timestamp(counts_per_timestamp, unique_vals, threshold = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    7: \"#B4A18E\",   # Moderate\n",
    "    8: \"#847363\",   # Severe\n",
    "    9: \"#57381A\",   # Extreme\n",
    "}\n",
    "\n",
    "plot_stacked_spi_ensemble(spei_filtered_cats, spei_filtered_counts, CATEGORIES_SPEI, color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "(section-insurance)=\n",
    "### 4. Parametric insurance\n",
    "Based on the drought indices and the decision to use the time span of the drought indices that best explains volatility in rice production, a parametric insurance product can be developed. A parametric insurance contract that is based on weather indices (such as SPI for example) is fully defined through the sum insured, the trigger (also called strike), the limit and the modality of the pay-out function [[World Bank Group+18](https://doi.org/10.1596/29784)].\n",
    "\n",
    "Triggers, limits, and the modality of the pay-out function are integral parts of the \"Indemnity Function\", where the parametric insurance contract protects against insufficient and/or excessive realisations of the underlying weather variable (e.g., rainfall deficit quantified through SPI).\n",
    "\n",
    "The Indemnity Function, $I$ that is based on the SPI is defined as: \n",
    "\n",
    "$$\n",
    "I = f(SPI \\mid x, Tr, Ex) = x \\times f(x) =\n",
    "\\begin{cases}\n",
    "0, & \\text{if } SPI > Tr, \\\\[6pt]\n",
    "\\dfrac{Tr - SPI}{Tr - Ex}, & \\text{if } Ex < SPI \\le Tr, \\\\[10pt]\n",
    "1, & \\text{if } SPI \\le Ex.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $x$ is the sum insured, $Tr$ is the Trigger and $Ex$ is the Exit below which level pay-outs stop. Based on the sum insured, a tick size may be determined that consists of a monetary pay-out for each increment of the SPI index. \n",
    "\n",
    "Parametric insurance products have previously been developed by the World Bank for \"wet season rice\" and 4-months cumulative SPIs (January-April) for the Central Java region in Indonesia. In that study, the insured value of a ton of rice was set to USD 100, with the total theoretical sum insured set to USD 520,162,600. The trigger for a parametric insurance payout to start was taken to be -5, with an exit of an SPI value of -20 justified from historical rainfall data and climate projections. Indemnity would occur under the parametric insurance product for a total of 15 SPI values. For the study, a tick value of USD 6,666,667 was determined from the maximum production shortfall of 1 million tons, with the payout limit defined as USD 100,000,000.\n",
    "\n",
    "The ERA5â€‘Drought product, which provides an estimate of uncertainty based on the 10â€‘member ensemble at a fine resolution, can be directly integrated into the design and evaluation of parametric insurance schemes. Incorporating this ensemble spread offers an explicit quantification of uncertainty around the underlying drought indicator, such as SPI, and therefore around potential payouts. \n",
    "\n",
    "Below, we assess using the ERA5-Drought reanalysis and ensemble product to provide an estimate of the uncertainty in parametric insurance contract payouts. This enables insurers to better assess risk, refine calculations, and understand the robustness of the parametric insurance contract. It allows parametric insurance to be extended to regions where in-situ observations are sparse, and strengthens the feasibility of deploying scalable insurance products underpinned by weather data worldwide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "#### 2.6 Calculating time-series payout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "The mean and spread of the SPI is then calculated for the ensemble site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_site_spi_mean_6, indo_site_spi_spread_6 = ensemble_mean_and_spread(indo_spi6_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "And the first 4 months per calendar year are summed over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "indo_first4_single_site = aggregate_months(indo_spi6_masked)\n",
    "indo_first4_single_site = indo_first4_single_site.sel(year = slice(1960, 2024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "The calendar year payout with ensemble member SPI is then plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "payout, payout_mean, payout_std = payout_function(indo_first4_single_site)\n",
    "plot_bar_with_payout(indo_first4_single_site, payout_mean, payout_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box_with_payout(indo_first4_single_site, payout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## â„¹ï¸ If you want to know more\n",
    "\n",
    "### Key resources\n",
    "The CDS catalogue entries for the data used were:\n",
    "* Monthly drought indices from 1940 to present derived from ERA5 reanalysis: [derived-drought-historical-monthly](https://doi.org/10.24381/9bea5e16)\n",
    "\n",
    "Code libraries used:\n",
    "* [earthkit](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-data](https://github.com/ecmwf/earthkit-data)\n",
    "  * [earthkit-plots](https://github.com/ecmwf/earthkit-plots)\n",
    "\n",
    "### References\n",
    "\n",
    "[[ECIU+25](https://eciu.net/analysis/reports/2025/estimated-financial-losses-faced-by-uk-farmers-due-dry-weather-impacts-on-key-arable-crops)] Energy & Climate Intelligence Unit, â€˜Estimated financial losses faced by UK farmers due dry weather impacts on key arable cropsâ€™, Energy & Climate Intelligence Unit, London, United Kingdom, Dec. 2025.\n",
    "\n",
    "[[IPCC+23](https://doi.org/10.59327/IPCC/AR6-9789291691647)] IPCC, â€˜Climate Change 2023: Synthesis Report. Contribution of Working Groups I, II and III to the Sixth Assessment Report of the Intergovernmental Panel on Climate Changeâ€™, Intergovernmental Panel on Climate Change (IPCC), Geneva, Switzerland, Jul. 2023. doi: 10.59327/IPCC/AR6-9789291691647.\n",
    "\n",
    "[[UNICEF+24](https://reliefweb.int/node/4111326)] UNICEF, â€˜Latin America and Caribbean Region Flash Update No. 2 (Climate-related crisis in the Amazon Region)â€™, UNICEF, Nov. 2024.\n",
    "\n",
    "[[Franch-Pardo+25](https://doi.org/10.48088/ejg.i.fra.16.2.286.297)] I. Franch-Pardo, P. A. F. Puig, and A. CerdÃ , â€˜Geospatial Technologies in Crisis Response: Analyzing the 2024 Floods in Valencia, Spainâ€™, European Journal of Geography, vol. 16, no. 2, pp. 286â€“297, Aug. 2025, doi: 10.48088/ejg.i.fra.16.2.286.297.\n",
    "\n",
    "[[Lin+20](https://doi.org/10.1111/rmir.12146)] X. Lin and W. J. Kwon, â€˜Application of parametric insurance in principle-compliant and innovative waysâ€™, Risk Management and Insurance Review, vol. 23, no. 2, pp. 121â€“150, May 2020, doi: 10.1111/rmir.12146.\n",
    "\n",
    "[[Prokopchuk+20](https://doi.org/10.22004/ag.econ.320076)] O. Prokopchuk, I. Prokopchuk, G. Mentel, and Y. Bilan, â€˜Parametric Insurance as Innovative Development Factor of the Agricultural Sector of Economyâ€™, AGRIS on-line Papers in Economics and Informatics, vol. 12, no. 3, pp. 69â€“86, Sep. 2020, doi: 10.22004/ag.econ.320076.\n",
    "\n",
    "[[World Bank Group+18](https://doi.org/10.1596/29784)] World Bank Group, â€˜Developing Parametric Insurance for Weather Related Risks for Indonesiaâ€™, World Bank, Washington, D.C., USA, Jan. 2018. doi: 10.1596/29784.\n",
    "\n",
    "[[McKee+93](https://climate.colostate.edu/pdfs/relationshipofdroughtfrequency.pdf)] T. B. McKee, N. J. Doesken, and J. Kleist, â€˜The relationship of drought frequency and duration to time scalesâ€™, in Eighth Conference on Applied Climatology, Anaheim, California, USA, Jan. 1993.\n",
    "\n",
    "[[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] J. Keune, F. Di Giuseppe, C. Barnard, E. Damasio da Costa, and F. Wetterhall, â€˜ERA5â€“Drought: Global drought indices based on ECMWF reanalysisâ€™, Scientific Data, vol. 12, p. 616, Apr. 2025, doi: 10.1038/s41597-025-04896-y.\n",
    "\n",
    "[[Vicente-Serrano+10](https://doi.org/10.1175/2009JCLI2909.1)] S. M. Vicente-Serrano, S. BeguerÃ­a, and J. I. LÃ³pez-Moreno, â€˜A Multiscalar Drought Index Sensitive to Global Warming: The Standardized Precipitation Evapotranspiration Indexâ€™, Journal of Climate, vol. 23, no. 7, pp. 1696â€“1718, Apr. 2010, doi: 10.1175/2009JCLI2909.1.\n",
    "\n",
    "[[Soci+24](https://doi.org/10.1002/qj.4803)] C. Soci et al., â€˜The ERA5 global reanalysis from 1940 to 2022â€™, Quarterly Journal of the Royal Meteorological Society, vol. 150, no. 764, pp. 4014â€“4048, Jul. 2024, doi: 10.1002/qj.4803.\n",
    "\n",
    "[[Hersbach+20](https://doi.org/10.1002/qj.3803)] H. Hersbach et al., â€˜The ERA5 global reanalysisâ€™, Quarterly Journal of the Royal Meteorological Society, vol. 146, no. 730, pp. 1999â€“2049, May 2020, doi: 10.1002/qj.3803.\n",
    "\n",
    "[[Evenflow+24](https://climate.copernicus.eu/sites/default/files/2024-12/Value-generated-by-ERA5-full-report.pdf)] Evenflow, â€˜The value generated by ERA5â€™, Copernicus Climate Change Service (C3S), Bonn, Germany, Dec. 2024. [Online]. Available: https://climate.copernicus.eu/sites/default/files/2024-12/Value-generated-by-ERA5-full-report.pdf\n",
    "\n",
    "[[Isaksen+10](https://doi.org/10.21957/obke4k60)] L. Isaksen et al., â€˜Ensemble of data assimilations at ECMWFâ€™, European Centre for Medium-Range Weather Forecasts, Reading, UK, 636, Dec. 2010. doi: 10.21957/obke4k60.\n",
    "\n",
    "[[JCGM+08](https://doi.org/10.59161/JCGM101-2008)] JCGM, â€˜Evaluation of measurement data â€” Supplement 1 to the â€œGuide to the expression of uncertainty in measurementâ€ â€” Propagation of distributions using a Monte Carlo methodâ€™, Joint Committee for Guides in Metrology, Sevres, Paris, France, 101:2008, 2008. doi: 10.59161/JCGM101-2008.\n",
    "\n",
    "[[Shapiro+65](https://doi.org/10.1093/biomet/52.3-4.591)] S. S. Shapiro and M. B. Wilk, â€˜An analysis of variance test for normality (complete samples)â€™, Biometrika, vol. 52, no. 3â€“4, pp. 591â€“611, Dec. 1965, doi: 10.1093/biomet/52.3-4.591."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
