{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Reproducibility of drought indicators in the ERA5â€“Drought dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Production date: 2026-02-xx\n",
    "\n",
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "\n",
    "Dataset version: 1.0.\n",
    "\n",
    "Produced by: Enis Gerxhalija, Olivier Burggraaff (National Physical Laboratory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ðŸŒ Use case: Retrieving drought indicators from the ERA5â€“Drought dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## â“ Quality assessment question\n",
    "* **Are the drought indicators in the ERA5â€“Drought dataset consistent with and reproducible from ERA5 data?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Drought and extreme precipitation have far-reaching environmental, societal, and economic impacts.\n",
    "In the United Kingdom, the record-breaking hot and dry spring and summer of 2025 caused harvest losses worth more than Â£800 million [[ECIU+25](https://eciu.net/analysis/reports/2025/estimated-financial-losses-faced-by-uk-farmers-due-dry-weather-impacts-on-key-arable-crops)].\n",
    "An 18-month drought in Brazil in 2023â€“24,\n",
    "the most severe since monitoring began in 1954,\n",
    "led to 720 health centres in affected areas becoming non-operational [[UNICEF+24](https://www.unicef.org/media/165191/file/LACR-Flash-Update-11-November-2024.pdf)].\n",
    "Finally, extreme rainfall killed hundreds of people and caused billions of â‚¬ of damages in Spain in 2024 [[Franch-Pardo+25](https://doi.org/10.48088/ejg.i.fra.16.2.286.297)].\n",
    "Climate change is thought to be the primary driver behind the increase in drought and extreme precipitation events since the 1950s [[IPCC+23](https://doi.org/10.59327/IPCC/AR6-9789291691647)],\n",
    "and this trend is expected to continue into the future.\n",
    "\n",
    "Given these impacts,\n",
    "monitoring drought and extreme precipitation is vital.\n",
    "Several quantitative proxies have been developed to aid in this monitoring,\n",
    "generally based on\n",
    "(a combination of)\n",
    "total precipitation, soil moisture, evapotranspiration, and surface (air) temperature.\n",
    "Two widely-employed indices are the \n",
    "_Standardised Precipitation Index (SPI)_ [[McKee+93](https://climate.colostate.edu/pdfs/relationshipofdroughtfrequency.pdf)]\n",
    "and\n",
    "_Standardised Precipitation-Evapotranspiration Index (SPEI)_ [[Vicente-Serrano+10](https://doi.org/10.1175/2009JCLI2909.1)].\n",
    "Both operate on the same principle,\n",
    "namely quantifying the amount of precipitation\n",
    "over a given time frame at a given location\n",
    "relative to its historical climatology.\n",
    "For example,\n",
    "an SPI value of +1 corresponds to a precipitation that is 1 standard deviation above the mean,\n",
    "for that site and time frame.\n",
    "This probabilistic approach lends itself to statements on the occurrence rate of extreme events [[McKee+93](https://climate.colostate.edu/pdfs/relationshipofdroughtfrequency.pdf)].\n",
    "SPEI expands on SPI by including not just gains from precipitation, but also losses due to evapo(transpi)ration.\n",
    "SPI and SPEI can be evaluated over different _accumulation periods_ to probe phenomena at different time scales [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y), [EDO+25](https://drought.emergency.copernicus.eu/data/factsheets/factsheet_spi.pdf)]:\n",
    "* 1, 3 months: soil moisture, flow in small creeks.\n",
    "* 6, 12 months: reservoir storage, stream flow.\n",
    "* 24, 36, 48 months: groundwater recharge, reduced reservoir.\n",
    "\n",
    "Of course,\n",
    "proxies like SPI and SPEI depend on reliable input data in the form of historical meteorological time series.\n",
    "Weather stations can provide these data with high accuracy and precision for specific sites,\n",
    "but their coverage is sparse and their data are not always interoperable.\n",
    "Reanalyses,\n",
    "which integrate observations and forecast modelling,\n",
    "can provide similar data consistently with long-term global coverage.\n",
    "For example, ECMWF's fifth-generation reanalysis _ERA5_ provides meteorological data on a global ~31 km grid\n",
    "going back to 1940 [[Soci+24](https://doi.org/10.1002/qj.4803), [Hersbach+20](https://doi.org/10.1002/qj.3803)].\n",
    "\n",
    "The Copernicus Climate Change Service (C3S)\n",
    "now provides pre-calculated SPI and SPEI indices derived from ERA5\n",
    "in the ERA5â€“Drought dataset [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)],\n",
    "[available from the Climate Data Store](https://doi.org/10.24381/9bea5e16).\n",
    "This derived dataset can be a valuable resource for applications in many sectors,\n",
    "since it can be used out of the box,\n",
    "freeing users from the need to find and process the underpinning meteorological data themselves.\n",
    "ERA5â€“Drought provides SPI and SPEI for 7 different accumulation periods,\n",
    "interpolated to a 0.25Â° Ã— 0.25Â° grid.\n",
    "It includes ERA5's deterministic reanalysis as well as 10 propagated members of the ERA5-EDA ensemble.\n",
    "The latter can be used to quantify the uncertainty in SPI or SPEI resulting from uncertainty in the input data.\n",
    "Moreover, ERA5â€“Drought provides multiple quality flags that can be used to filter data that do not meet the requirements for SPI or SPEI to be applicable.\n",
    "\n",
    "This quality assessment tests the consistency of ERA5â€“Drought with the underpinning ERA5 data in terms of its reproducibility.\n",
    "By manually reproducing SPI, SPEI, and the associated quality indicators from ERA5 data and comparing the results,\n",
    "we assess whether ERA5â€“Drought can indeed be used as a more convenient alternative to ERA5 for monitoring drought and extreme precipitation.\n",
    "Furthermore,\n",
    "any discrepancies found in the comparison shed light on caveats in the use of ERA5â€“Drought specifically and drought indicators broadly,\n",
    "such as the underlying assumptions.\n",
    "This notebook provides code for reproducing SPI and SPEI from ERA5 data and can be a jumping-off point for further analysis by the reader."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ“¢ Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Conclusion 1\n",
    "* Conclusion 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ðŸ“‹ Methodology\n",
    "\n",
    "This quality assessment tests the reproducibility of drought indices in the ERA5â€“Drought\n",
    "([_Monthly drought indices from 1940 to present derived from ERA5 reanalysis_](https://doi.org/10.24381/9bea5e16))\n",
    "dataset\n",
    "from their origins in ERA5.\n",
    "\n",
    "This notebook provides and runs through Python code for reproducing\n",
    "the SPI and SPEI indicators\n",
    "as well as\n",
    "the associated quality flags\n",
    "(probability of zero precipitation _p{sub}`0`_ and Shapiroâ€“Wilk normality _Î±_)\n",
    "from ERA5.\n",
    "These reproduced values are then compared to the pre-made data in ERA5â€“Drought in several case studies,\n",
    "namely\n",
    "a full time-series comparison in one location\n",
    "and\n",
    "a geospatial comparison at one point in time.\n",
    "The notebook is set up so that the test sites and dates are easily customised,\n",
    "so you can download this notebook and run it on your preferred domain.\n",
    "\n",
    "The analysis and results are organised in the following steps, which are detailed in the sections below:\n",
    "\n",
    "**[](section-code_setup)**\n",
    " * Import all required libraries.\n",
    " * Define helper functions.\n",
    "\n",
    "**[](section-general_setup)**\n",
    " * Define scope of analysis (time, location).\n",
    " * Set up CDS downloads for ERA5 and ERA5â€“Drought.\n",
    " * Download land-sea mask.\n",
    "\n",
    "**[](section-spi)**\n",
    " * Download ERA5 precipitation data.\n",
    " * Compute SPI over different accumulation periods.\n",
    " * Download ERA5â€“Drought SPI and quality flags.\n",
    " * Compare ERA5â€“Drought and reproduced SPI (time series, geospatial).\n",
    " * Compare ERA5â€“Drought and reproduced quality flags.\n",
    "\n",
    "**[](section-spei)**\n",
    " * Download ERA5 precipitation and potential evaporation data.\n",
    " * Compute SPEI over different accumulation periods.\n",
    " * Download ERA5â€“Drought SPEI and quality flags.\n",
    " * Compare ERA5â€“Drought and reproduced SPEI (time series, geospatial).\n",
    " * Compare ERA5â€“Drought and reproduced quality flags.\n",
    "\n",
    "**[](section-ensemble)**\n",
    " * Download ERA5 precipitation data.\n",
    " * Compute SPI for different ERA5 ensemble members.\n",
    " * Download ERA5â€“Drought SPI ensemble.\n",
    " * Compare ERA5â€“Drought and reproduced SPI ensembles.\n",
    "\n",
    "**[](section-conclusion)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-code_setup)=\n",
    "### 1. Code setup\n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data)) and visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data. Because earthkit is in active development, some functionality may change after this notebook is published. If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Import required libraries\n",
    "In this section, we import all the relevant packages needed for running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Input / Output\n",
    "from pathlib import Path\n",
    "import earthkit.data as ekd\n",
    "\n",
    "# General data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "from itertools import batched\n",
    "\n",
    "# Analysis\n",
    "from dask.array import nanmedian, ravel\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Visualisation\n",
    "import earthkit.plots as ekp\n",
    "from earthkit.plots.styles import Style\n",
    "from cartopy import crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "from tqdm import tqdm  # Progress bars\n",
    "\n",
    "# Visualisation in Jupyter book -- automatically ignored otherwise\n",
    "try:\n",
    "    from myst_nb import glue\n",
    "except ImportError:\n",
    "    glue = None\n",
    "\n",
    "# Type hints\n",
    "from typing import Any, Callable, Iterable, Optional\n",
    "from scipy.stats import rv_continuous as Distribution\n",
    "from pandas.io.formats.style import Styler as pdStyler\n",
    "from earthkit.plots.geo.domains import Domain\n",
    "AnyDomain = (Domain | str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "This section defines some functions and variables used in the following analysis, allowing code cells in later sections to be shorter and ensuring consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "##### Data downloading & (pre-)processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The following functions handle downloading data in specific circumstances, e.g. a geographical or temporal subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographical\n",
    "def request_data_for_one_site(*, lat, lon, half_width=0.25):\n",
    "    \"\"\" Return a CDS request for a bounding box around a point (lon, lat). \"\"\"\n",
    "    north, south = lat + half_width, lat - half_width\n",
    "    east , west  = lon + half_width, lon - half_width\n",
    "    box = [north, west, south, east]\n",
    "    box = [round(x, 2) for x in box]  # Round all coordinates to 2 digits\n",
    "    request_box = {\"area\": box}\n",
    "    return request_box\n",
    "\n",
    "# Handling CDS size limits\n",
    "def batch_requests(main_request: dict, *, batch_key: str=\"year\", n: int=20) -> list[dict]:\n",
    "    \"\"\" Take a big request (e.g. ERA5â€“Drought for all years) and separate it into smaller ones (size `n`). \"\"\"\n",
    "    full_range = main_request[batch_key]  # e.g. [1940, 1941, ..., 2024]\n",
    "    batched_range = batched(full_range, n)  # e.g. [1940, ..., 1959], [1960, ..., 1979], ...\n",
    "    subrequests = [main_request | {batch_key: batch} for batch in batched_range]  # create corresponding CDS requests\n",
    "    return subrequests\n",
    "\n",
    "# Handling multiple accumulation period download for ensemble data.\n",
    "def ens_drought_request(ekd_request):\n",
    "    \"\"\" Take multiple accumulation period request for ensemble data and combine into one dataset. \"\"\"\n",
    "    file_paths = [fld.path for fld in ekd_request._indexes] # Extract file paths from the Earthkit FieldList\n",
    "    datasets = [xr.open_dataset(path) for path in file_paths] # Open each file as xarray\n",
    "    processed = [add_number_dimension(ds) for ds in datasets] #  Add the number dimension to each dataset\n",
    "    final = xr.combine_by_coords(processed, join = \"outer\", combine_attrs=\"drop\") # Stack all datasets together\n",
    "    final = final.chunk({\"time\": -1}) # Rechunk to single time dimension\n",
    "    return final "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The following functions ensure consistency in dimensions, which have inconsistent names (e.g. `valid_time` vs. `time`) and definitions (e.g. longitude 0 to 360 or â€“180 to 180) between ERA5 and ERA5â€“Drought:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_era5_dimensions(data: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Rename dimensions\n",
    "    from ERA5 (valid_time, latitude, longitude)\n",
    "    to ERA5â€“Drought (time, lat, lon)\n",
    "    format.\n",
    "    \"\"\"\n",
    "    data = data.rename({\"valid_time\": \"time\",\n",
    "                        \"latitude\": \"lat\",\n",
    "                        \"longitude\": \"lon\",\n",
    "                       })\n",
    "    return data\n",
    "\n",
    "def longitude_360_to_180(data: xr.Dataset, longitude_dimension=\"lon\") -> xr.Dataset:\n",
    "    \"\"\" Convert longitude from 0..360 to -180..180 format. \"\"\"\n",
    "    longitude_new = ((data[longitude_dimension] - 180) % 360) - 180\n",
    "    data = data.assign_coords({longitude_dimension: longitude_new})\n",
    "    data = data.sortby(longitude_dimension)#.squeeze()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The following functions handle unit conversions, e.g. m to mm precipitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit conversion\n",
    "def convert_unit(dataset: xr.Dataset, key: str, conversion: Callable, new_unit: str) -> None:\n",
    "    \"\"\" Convert the units of dataset[key] to new_unit using a conversion function (e.g. lambda x: x*1000 for m to mm), in-place. \"\"\"\n",
    "    # Metadata handling\n",
    "    metadata_old = dataset[key].attrs\n",
    "    metadata_new = metadata_old | {\"units\": new_unit}\n",
    "\n",
    "    # Apply changes\n",
    "    dataset[key] = conversion(dataset[key]).assign_attrs(**metadata_new)\n",
    "\n",
    "    return dataset  # Redundant because modified in-place\n",
    "\n",
    "convert_m2mm = partial(convert_unit, conversion=(lambda x: x*1000), new_unit=\"mm\")  # meter -> millimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The following function handles the overall pre-processing of ERA5 data: renaming dimensions, converting units, and adjusting longitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_era5(data: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Pre-process ERA5 data (precipitation and/or evapotranspiration) into the right format for analysis. \"\"\"\n",
    "    # Dimensions\n",
    "    data = rename_era5_dimensions(data)\n",
    "    data = longitude_360_to_180(data, \"lon\")  # Convert longitude from 0..360 to â€“180..180\n",
    "\n",
    "    # Units\n",
    "    for var in data.data_vars:  # Assume all data_vars need to be converted to mm\n",
    "        data = convert_m2mm(data, var)  # Convert from m to mm\n",
    "\n",
    "    # Re-chunk for speed gain in fitting\n",
    "    data = data.chunk({\"time\": -1, \"lat\": 103, \"lon\": 360,})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The following function calculates the water balance `wb` from the total precipitation and potential evaporation ([](section-spei)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_waterbalance(data: xr.Dataset, *,\n",
    "                           precipitation_variable: str=\"tp\", evaporation_variable: str=\"pev\",\n",
    "                           waterbalance_variable: str=\"wb\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate the water balance from precipitation and evaporation.\n",
    "    Assumes the ECMWF sign convention where downward flux is positive and upward flux is negative,\n",
    "    i.e. WB = TP + PEV.\n",
    "    \"\"\"\n",
    "    # Calculate water balance\n",
    "    waterbalance = data[precipitation_variable] + data[evaporation_variable]\n",
    "\n",
    "    # Apply variable name, metadata, and convert to dataset\n",
    "    waterbalance = waterbalance.rename(waterbalance_variable)\n",
    "    waterbalance = waterbalance.assign_attrs({\"units\": data[precipitation_variable].units,\n",
    "                                              \"long_name\": \"Water balance\",\n",
    "                                             })\n",
    "    waterbalance = waterbalance.to_dataset()\n",
    "    \n",
    "    return waterbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "The following functions aid in processing quality flag data from ERA5â€“Drought into a standard format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_era5drought_qualityflag(data: dict[Any, ekd.FieldList], variable_out: Optional[str]=None, *,\n",
    "                                       month_dimension: str=\"month\", time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\" \n",
    "    Turn a dict of earthkit FieldLists with ERA5â€“Drought quality flags, organised by accumulation period, into one big xr.Dataset.\n",
    "    Rename the variables according to the dict keys; optionally using `variable_out` (e.g. SPEI -> SPEI1, SPEI3, etc).\n",
    "    Convert a 12-month time dimension (2020-01-01, 2020-02-01, ...) into a month dimension (1, 2, ...).\n",
    "    \"\"\"\n",
    "    # Convert field lists to xarray Datasets\n",
    "    data = {key: ds.to_xarray(compat=\"equals\")\n",
    "            for key, ds in data.items()}\n",
    "\n",
    "    # Rename variables to include keys (e.g. accumulation periods)\n",
    "    first_fieldlist = next(iter(data.values()))\n",
    "    data_var = next(iter(first_fieldlist.data_vars))\n",
    "    if not variable_out:  # If not manually specified, append keys to existing variable name\n",
    "        variable_out = data_var\n",
    "    \n",
    "    data = [ds.rename_vars({data_var: f\"{variable_out}{key}\"})\n",
    "            for key, ds in data.items()]\n",
    "\n",
    "    # Merge into one\n",
    "    data = xr.merge(data, compat=\"equals\")\n",
    "\n",
    "    # Change time dimension to months\n",
    "    data = data.assign_coords({month_dimension: data[time_dimension].dt.month})\n",
    "    data = data.swap_dims({time_dimension: month_dimension})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The following functions restructure the ensemble members in the ERA5â€“Drought dataset along a new dimension, as in ERA5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number_dimension(data: xr.Dataset, *, n_members: int=10,\n",
    "                         time_dimension: str=\"time\", ensemble_dimension: str=\"number\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Convert a dataset\n",
    "    from ERA5â€“Drought format (10-duplicate `time` dimension)\n",
    "    to ERA5 format (`number` dimension for ensemble members)\n",
    "    \"\"\"\n",
    "    # Find unique times and use these to generate datasets for successive members\n",
    "    member_numbers = np.arange(n_members)\n",
    "    _, index = np.unique(data[time_dimension], return_index=True)\n",
    "    data = [data.isel({time_dimension: index + i}) for i in member_numbers]\n",
    "\n",
    "    # Combine into one dataset\n",
    "    data = xr.concat(data, dim=ensemble_dimension).assign_coords(number=member_numbers)\n",
    "\n",
    "    # Rechunk for memory efficiency\n",
    "    data = data.chunk({ensemble_dimension: n_members, time_dimension: 48, \"lat\": 360, \"lon\": 103,})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "##### Accumulation periods\n",
    "The following cells contain constants and functions used in accumulating variables (e.g. precipitation) over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants such as the accumulation periods to use\n",
    "ACCUMULATION_PERIODS = [1, 3, 6, 12, 24, 36, 48]  # Months\n",
    "MONTHS = range(1, 13)  # January to December (inclusive)\n",
    "MONTHS_NAMED = {\n",
    "     1:  \"January\", 2:  \"February\", 3:  \"March\",\n",
    "     4:  \"April\",   5:  \"May\",      6:  \"June\",\n",
    "     7:  \"July\",    8:  \"August\",   9:  \"September\",\n",
    "    10: \"October\", 11: \"November\", 12:  \"December\",\n",
    "}\n",
    "\n",
    "# Perform accumulation\n",
    "def accumulate(data: xr.Dataset, var: str, *,\n",
    "               accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS, time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Accumulate the given variable `var` (e.g. total precipitation) over different accumulation periods.\n",
    "    \"\"\"\n",
    "    # Find the number of days in each month\n",
    "    time_index = pd.to_datetime(data[time_dimension])  # Convert time dimension to datetime format\n",
    "    days_in_month = xr.DataArray(time_index.days_in_month, coords={time_dimension: data[time_dimension]})  # Aligned with `data` coordinates\n",
    "\n",
    "    # Monthly mean `var` â†’ Monthly total `var`\n",
    "    monthly_total = data[var] * days_in_month\n",
    "\n",
    "    ## Accumulate over periods (rolling windows)\n",
    "    result = data.copy()\n",
    "    for period in accumulation_periods:\n",
    "        rolling_sum = monthly_total.rolling({time_dimension: period}, center=False).sum()  # Rolling sum\n",
    "        result[f\"{var}{period}\"] = rolling_sum  # Assign variable in same format as ERA5â€“Drought (e.g. SPI6)\n",
    "\n",
    "    # Reorganise\n",
    "    result = result.drop_vars([var])  # Drop original var\n",
    "    result = result.chunk(data.chunksizes)  # Rechunk like input data\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "The following functions calculate the probability\n",
    "(regular and accounting for the centre of mass)\n",
    "of months with zero (accumulated) precipitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_months_with_zero_precipitation(data: xr.Dataset, *,\n",
    "                                             round_to: int=2, threshold: float=0.,\n",
    "                                             time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Find the number of months with zero precipitation (and total months) in a given dataset.\n",
    "    Rounds to `round_to` decimals (default 2, e.g. 0.01 mm).\n",
    "    Zero precipitation means <= `threshold` (0. by default).\n",
    "    Applied per calendar month and to all variables (e.g. accumulation periods).\n",
    "    \"\"\"\n",
    "    # Round data, to 2 decimals by default\n",
    "    data = data.round(round_to)\n",
    "\n",
    "    # Find months below threshold\n",
    "    is_zero = (data <= threshold)\n",
    "\n",
    "    # Group by calendar month and find total number\n",
    "    data_by_calendar_month = is_zero.groupby(is_zero[time_dimension].dt.month)\n",
    "    n_zero  = data_by_calendar_month.sum(dim=time_dimension).astype(np.uint8)\n",
    "    n_total = data_by_calendar_month.count(dim=time_dimension).astype(np.uint8)\n",
    "\n",
    "    return n_total, n_zero\n",
    "\n",
    "def probability_of_zero_precipitation(data: xr.Dataset, **kwargs) -> xr.Dataset:\n",
    "    \"\"\" Calculate the simple probability of zero precipitation in the given dataset, per calendar month. \"\"\"\n",
    "    # Find number of months (total / zero precipitation)\n",
    "    n_total, n_zero = number_of_months_with_zero_precipitation(data, **kwargs)\n",
    "\n",
    "    # Calculate simple probability\n",
    "    p_zero = n_zero / (n_total + 1)\n",
    "\n",
    "    return p_zero\n",
    "   \n",
    "def probability_of_zero_precipitation_weighted(data: xr.Dataset, **kwargs) -> xr.Dataset:\n",
    "    \"\"\" Calculate the weighted probability of zero precipitation in the given dataset, per calendar month. \"\"\"\n",
    "    # Find number of months (total / zero precipitation)\n",
    "    n_total, n_zero = number_of_months_with_zero_precipitation(data, **kwargs)    \n",
    "\n",
    "    # Calculate weighted probability\n",
    "    p_zero = xr.where(\n",
    "        n_zero > 0,                          # Condition: More than 0 months with zero precipitation\n",
    "        (n_zero + 1) / (2 * (n_total + 1)),  # If condition met: weighted probability\n",
    "        0                                    # If condition not met: just 0\n",
    "    )\n",
    "\n",
    "    return p_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Calculating SPI and SPEI\n",
    "The following functions fit the appropriate distributions\n",
    "(gamma, generalised logistic)\n",
    "and calculate corresponding CDF and SPI / SPEI values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General fitting function\n",
    "def fit_distributions(reference_data: xr.Dataset, distribution: Distribution, *,\n",
    "                      time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Fit distributions (e.g. gamma) for each month and accumulation period using xarray parallelisation.\n",
    "    Data are assumed to have been sliced to the reference period.\n",
    "    \"\"\"\n",
    "    # Define fitting function for the given distribution\n",
    "    def fit(y):\n",
    "        y = y[np.isfinite(y)]\n",
    "        try:\n",
    "            params = distribution.fit(y)\n",
    "        except:  # If fitting fails, return NaN\n",
    "            # Should only catch a specific Exception type\n",
    "            params = [np.nan]*(distribution.numargs+2)\n",
    "        finally:  # Always convert result (values or NaN) to desired format\n",
    "            params = np.stack(params, axis=-1)  # Extend with axis for stats (alpha, loc, scale, ...)\n",
    "        return params\n",
    "\n",
    "    # Split dataset by month\n",
    "    reference_data_by_month = reference_data.groupby(reference_data[time_dimension].dt.month)\n",
    "\n",
    "    # Apply fitting function by month\n",
    "    params = xr.apply_ufunc(fit, reference_data_by_month,\n",
    "                            input_core_dims=[[time_dimension]], output_core_dims=[[\"stat\"]],\n",
    "                            vectorize=True, dask=\"parallelized\",\n",
    "                            dask_gufunc_kwargs={\"output_sizes\": {\"stat\": distribution.numargs+2}},  # e.g. 3 for gamma (alpha, loc, scale)\n",
    "                            output_dtypes=[np.float64],\n",
    "                           )\n",
    "    params = params.chunk({\"month\": -1})\n",
    "\n",
    "    return params\n",
    "\n",
    "# Fitting functions for SPI, SPEI distributions specifically\n",
    "fit_monthly_spi  = partial(fit_distributions, distribution=stats.gamma)\n",
    "fit_monthly_spei = partial(fit_distributions, distribution=stats.genlogistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "The following functions apply the fitted distributions to calculate CDF values for observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Clip the CDF to avoid infinities\n",
    "def clip_cdf(cdf: xr.Dataset, threshold: float=1e-16) -> xr.Dataset:\n",
    "    \"\"\" Clip CDF values to `threshold` on both sides. \"\"\"\n",
    "    cdf_clipped = cdf.clip(threshold, 1 - threshold)\n",
    "    return cdf_clipped\n",
    "\n",
    "# Main function: Compute CDF values for observed data\n",
    "def compute_cdf(data: xr.Dataset, parameters: xr.Dataset, distribution: Distribution, *,\n",
    "                month_dimension: str=\"month\", time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    For observed `data`, compute the corresponding cumulative distribution function (CDF)\n",
    "    values for the given `distribution` and `parameters`.\n",
    "\n",
    "    Assumes that `data` and `parameters` have compatible:\n",
    "        Coordinates (except time)\n",
    "        Variables (e.g. corresponding to accumulation periods)\n",
    "    \"\"\"\n",
    "    # Create a month dimension for broadcasting with the one in parameters\n",
    "    data_month = data[time_dimension].dt.month.rename(month_dimension)\n",
    "\n",
    "    # Extract parameters\n",
    "    nr_parameters = parameters.sizes[\"stat\"]  # 3 for gamma / genlogistic\n",
    "    parameters_extracted = [parameters.sel(stat=j).sel({month_dimension: data_month}) for j in range(nr_parameters)]\n",
    "\n",
    "    # Calculate CDF values by month\n",
    "    cdf = xr.apply_ufunc(distribution.cdf, data, *parameters_extracted,\n",
    "                         input_core_dims=[[], [], [], []], output_core_dims=[[]],\n",
    "                         vectorize=True, dask=\"parallelized\",\n",
    "                         output_dtypes=[np.float64],\n",
    "                         keep_attrs=True\n",
    "                        )\n",
    "    cdf = clip_cdf(cdf)  # Clip extreme values to avoid infinities\n",
    "    cdf = cdf.chunk(data.chunksizes) # Rechunk like input data\n",
    "\n",
    "    return cdf\n",
    "\n",
    "# Compute SPI, SPEI with preset distributions\n",
    "compute_cdf_spi  = partial(compute_cdf, distribution=stats.gamma)\n",
    "compute_cdf_spei = partial(compute_cdf, distribution=stats.genlogistic)\n",
    "\n",
    "def adjust_cdf_for_zero_precipitation(cdf: xr.Dataset, data: xr.Dataset, *,\n",
    "                                      time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Adjust CDF for months with zero precipitation, following Stagge+15 (doi:10.1002/joc.4267) method.\n",
    "    `cdf` can be for any time range, `data` should be for the reference period only.\n",
    "    \"\"\" \n",
    "    # Calculate probability of zero precipitation\n",
    "    p_zero = probability_of_zero_precipitation_weighted(data)\n",
    "    p_zero = p_zero.chunk({\"month\": -1})  # Rechunk for efficiency\n",
    "\n",
    "    # Adjust CDF by calendar month\n",
    "    def adjust_cdf_by_calendar_month(cdf_one_month: xr.Dataset) -> xr.Dataset:\n",
    "        this_month = cdf_one_month[time_dimension][0].month.values # Cannot use GroupBy label inside .map() unfortunately\n",
    "        p_zero_this_month = p_zero.sel({\"month\": this_month})\n",
    "        cdf_adjusted = p_zero_this_month + (1 - p_zero_this_month) * cdf_one_month\n",
    "        return cdf_adjusted\n",
    "\n",
    "    cdf_by_calendar_month = cdf.groupby(cdf[time_dimension].dt.month)\n",
    "    cdf_adjusted = cdf_by_calendar_month.map(adjust_cdf_by_calendar_month)  \n",
    "    # Alternative approach: Broadcast p_zero against cdf instead of using GroupBy (not implemented here)\n",
    "\n",
    "    # Reorganise for efficiency\n",
    "    cdf_adjusted = cdf_adjusted.chunk(cdf.chunksizes)\n",
    "\n",
    "    return cdf_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The following functions calculate the SPI/SPEI index based on CDF values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function: Convert CDF values to indexes\n",
    "def cdf_to_index(cdf: xr.Dataset, *, var: Optional[str]=None, index_name: Optional[str]=None) -> xr.Dataset:\n",
    "    \"\"\" Transform CDF values to a standard normal distribution. \"\"\"\n",
    "    cdf = clip_cdf(cdf)  # Clip extreme values to avoid infinities\n",
    "\n",
    "    # Convert CDF to index\n",
    "    index_values = xr.apply_ufunc(stats.norm.ppf, cdf, 0.0, 1.0,  \n",
    "                                  input_core_dims=[[], [], []], output_core_dims=[[]],\n",
    "                                  vectorize=True, dask=\"parallelized\",\n",
    "                                  output_dtypes=[np.float64],\n",
    "                                  keep_attrs=True,\n",
    "                                 )\n",
    "\n",
    "    # Adjust variable names to ERA5â€“Drought format (e.g. SPI6) if desired\n",
    "    if var and index_name:\n",
    "        rename_variables = {datavar: datavar.replace(var, index_name) for datavar in cdf.data_vars if var in datavar}\n",
    "        index_values = index_values.rename_vars(rename_variables)\n",
    "\n",
    "    return index_values\n",
    "\n",
    "# Compute SPI, SPEI with preset names\n",
    "cdf_to_spi  = partial(cdf_to_index, var=\"tp\", index_name=\"SPI\")\n",
    "cdf_to_spei = partial(cdf_to_index, var=\"wb\", index_name=\"SPEI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "For convenience, we also provide the following functions that wrap the entire process from data to SPI/SPEI into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full SPI pipeline\n",
    "def calculate_spi_from_era5(data: xr.Dataset, *, reference_window: dict[str, slice],\n",
    "                            do_preprocessing=False, evaluation_window: Optional[dict[str, slice]]=None,\n",
    "                            precipitation_variable: str=\"tp\",\n",
    "                            accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS,\n",
    "                           ) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate SPI from ERA5 precipitation data, including all steps.\n",
    "    Input should be ERA5 data in xarray format, either\n",
    "        freshly downloaded (`do_preprocessing=True`)\n",
    "        or\n",
    "        pre-processed (`do_preprocessing=False`).\n",
    "    Some parameters can be adjusted,\n",
    "        e.g. the name of the precipitation variable (\"tp\" by default).\n",
    "        This should make the function easier to transfer to other datasets.\n",
    "    \"\"\"\n",
    "    # Optional: pre-process to desired format\n",
    "    if do_preprocessing:\n",
    "        data = preprocess_era5(data)\n",
    "\n",
    "    # Accumulate total precipitation\n",
    "    data = accumulate(data, precipitation_variable, accumulation_periods=accumulation_periods)\n",
    "\n",
    "    # Select data in reference window\n",
    "    data_reference = data.sel(**reference_window)\n",
    "    \n",
    "    # Fit gamma distribution\n",
    "    spi_parameters = fit_monthly_spi(data_reference)\n",
    "\n",
    "    # Optional: Only calculate index in evaluation window\n",
    "    if evaluation_window:\n",
    "        data = data.sel(**evaluation_window)\n",
    "\n",
    "    # Compute CDF time series\n",
    "    cdf = compute_cdf_spi(data, spi_parameters)\n",
    "\n",
    "    # Adjust CDF\n",
    "    cdf_adjusted = adjust_cdf_for_zero_precipitation(cdf, data_reference)\n",
    "\n",
    "    # Calculate SPI from adjusted CDF\n",
    "    spi = cdf_to_spi(cdf_adjusted)\n",
    "    spi = spi.chunk(data.chunksizes)\n",
    "\n",
    "    return spi\n",
    "\n",
    "# Full SPEI pipeline\n",
    "def calculate_spei_from_era5(data: xr.Dataset, *, reference_window: dict[str, slice],\n",
    "                             do_preprocessing=False, evaluation_window: Optional[dict[str, slice]]=None,\n",
    "                             precipitation_variable: str=\"tp\", evaporation_variable: str=\"pev\",\n",
    "                             accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS,\n",
    "                            ) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate SPEI from ERA5 precipitation and potential evaporation data, including all steps.\n",
    "    Input should be ERA5 data in xarray format, either\n",
    "        freshly downloaded (`do_preprocessing=True`)\n",
    "        or\n",
    "        pre-processed (`do_preprocessing=False`).\n",
    "    Some parameters can be adjusted,\n",
    "        e.g. the name of the precipitation variable (\"tp\" by default).\n",
    "        This should make the function easier to transfer to other datasets.\n",
    "    \"\"\"\n",
    "    # Optional: pre-process to desired format\n",
    "    if do_preprocessing:\n",
    "        data = preprocess_era5(data)\n",
    "\n",
    "    # Calculate water balance\n",
    "    data = calculate_waterbalance(data)\n",
    "\n",
    "    # Accumulate water balance\n",
    "    data = accumulate(data, \"wb\")\n",
    "\n",
    "    # Select data in reference window\n",
    "    data_reference = data.sel(**reference_window)\n",
    "\n",
    "    # Fit generalised logistic distribution\n",
    "    spei_parameters = fit_monthly_spei(data_reference)\n",
    "\n",
    "    # Optional: Only calculate index in evaluation window\n",
    "    if evaluation_window:\n",
    "        data = data.sel(**evaluation_window)\n",
    "\n",
    "    # Compute CDF time series\n",
    "    cdf = compute_cdf_spei(data, spei_parameters)\n",
    "\n",
    "    # Calculate SPI from CDF\n",
    "    spei = cdf_to_spei(cdf)\n",
    "    spei = spei.chunk(data.chunksizes)\n",
    "\n",
    "    return spei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "##### Categorising SPI and SPEI\n",
    "The following cell defines categories for SPI and SPEI values, e.g. \"severe drought\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category format: [lower limit, upper limit, label, colour]\n",
    "# Colours are picked from Fig. 4 in Keune+25 and labelled for convenience\n",
    "# Limits are left-inclusive: [lower, upper)\n",
    "# Extreme values of 100 / -100 should be treated as infinities but play nicer with some code than np.inf\n",
    "\n",
    "CATEGORIES_SPI = [  # Approximates the GDO scheme\n",
    "    (   2.00, 100,     \"Extremely wet\",            \"#7a007b\"),  # deepest purple \n",
    "    (   1.50,   2.00,  \"Severely wet\",             \"#af51c3\"),  # dark purple\n",
    "    (   1.00,   1.50,  \"Moderately wet\",           \"#eaccf8\"),  # medium purple\n",
    "    (   0.00,   1.00,  \"Nearâ€‘normal / mildly wet\", \"#ffffff\"),  # white\n",
    "    (  -1.00,   0.00,  \"Nearâ€‘normal / mildly dry\", \"#ffffff\"),  # white\n",
    "    (  -1.50,  -1.00,  \"Moderately dry\",           \"#fffc03\"),  # yellow\n",
    "    (  -2.00,  -1.50,  \"Severely dry\",             \"#feaa00\"),  # orange\n",
    "    (-100,     -2.00,  \"Extremely dry\",            \"#ff0100\"),  # red\n",
    "]\n",
    "\n",
    "CATEGORIES_SPEI = [\n",
    "    (   2.33, 100,    \"Extremely wet\",  \"#01148b\"),  # very dark navy\n",
    "    (   1.65,   2.33, \"Severely wet\",   \"#1871de\"),  # strong blue\n",
    "    (   1.28,   1.65, \"Moderately wet\", \"#14acf4\"),  # medium blue\n",
    "    (   0.84,   1.28, \"Mildly wet\",     \"#00f2fe\"),  # cyan\n",
    "    (  -0.84,   0.84, \"Near-normal\",    \"#9afa93\"),  # light green\n",
    "    (  -1.28,  -0.84, \"Mildly dry\",     \"#fdc403\"),  # yellow\n",
    "    (  -1.65,  -1.28, \"Moderately dry\", \"#f2631d\"),  # orange\n",
    "    (  -2.33,  -1.65, \"Severely dry\",   \"#df2929\"),  # red\n",
    "    (-100,     -2.33, \"Extremely dry\",  \"#8c1b1a\"),  # dark red\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "The following functions categorise SPI / SPEI values into said categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _digitise_dataset(data: xr.Dataset, bin_edges: list[float], *, persist=True) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Digitise all variables in `data` according to a list of left bin edges, e.g. SPI categories (\"extremely dry\").\n",
    "    In this notebook, do not call this function directly, but use the categorise_dataset wrapper.\n",
    "    \"\"\"\n",
    "    # Perform digitisation\n",
    "    data_digitised = xr.apply_ufunc(np.digitize, data,\n",
    "                                    kwargs={\"bins\": bin_edges, \"right\": False}, \n",
    "                                    input_core_dims=[[]],\n",
    "                                    vectorize=True, dask=\"parallelized\",\n",
    "                                    output_dtypes=[np.uint8],  # uint8 is small; not suitable for >256 categories\n",
    "    )\n",
    "\n",
    "    # Persist in memory if desired (default True because uint8s are small)\n",
    "    if persist:\n",
    "        data_digitised = data_digitised.persist()\n",
    "\n",
    "    return data_digitised\n",
    "\n",
    "def categorise_dataset(data: xr.Dataset, categories: Iterable[Iterable], **kwargs) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Categorise a dataset into bins defined by category thresholds.\n",
    "    Extracts bin edges from `categories` and then digitises `data` accordingly.\n",
    "    Handles NaNs by adding a dummy category (extremely high bin edge).\n",
    "    \"\"\"\n",
    "    # Extract bin edges from categories\n",
    "    # Last element is dropped to extend range to infinity (although values should be clipped anyway)\n",
    "    bin_edges = [category[0] for category in categories[:-1]]\n",
    "\n",
    "    # Add dummy category to catch NaNs\n",
    "    bin_edges = [100000] + bin_edges\n",
    "\n",
    "    # Apply digitisation\n",
    "    data_categorised = _digitise_dataset(data, bin_edges, **kwargs)\n",
    "\n",
    "    return data_categorised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "##### Quality flags\n",
    "The following functions create and apply quality flag tests, such as the probability of zero precipitation and the Shapiroâ€“Wilk normality test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapiro_wilk_normality(data: xr.Dataset, *,\n",
    "                           time_dimension: str=\"time\", month_dimension: str=\"month\") -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate the Shapiroâ€“Wilk normality p-value for every variable in `data`\n",
    "        along the `time_dimension`, grouped by month.\n",
    "    Make sure to provide data for the desired period (generally the reference window) only.\n",
    "    \"\"\"\n",
    "    # Group by month\n",
    "    data_by_month = data.groupby(data[time_dimension].dt.month)\n",
    "\n",
    "    # Perform test\n",
    "    _ , pval = xr.apply_ufunc(stats.shapiro, data_by_month,\n",
    "                              input_core_dims=[[time_dimension]], output_core_dims=[[],[]],\n",
    "                              vectorize=True, dask=\"parallelized\",\n",
    "                              output_dtypes=[np.float64, np.float64],\n",
    "                              keep_attrs=True,\n",
    "                             )\n",
    "    return pval\n",
    "\n",
    "def apply_sw_quality_mask(era5_quality: xr.Dataset, index_ds: xr.Dataset, indicator: str):\n",
    "    \"\"\"\n",
    "    Apply significance-based quality masks to drought indicator datasets.\n",
    "    \"\"\"\n",
    "    index_ds = safe_rename(index_ds)\n",
    "    for period in ACCUMULATION_PERIODS:\n",
    "        sig = era5_quality[f\"significance_{period}\"]\n",
    "        sig = sig.assign_coords(time=sig.time.dt.month)\n",
    "        mask = sig.sel(time=index_ds[f\"{indicator}{period}\"].time.dt.month)\n",
    "        index_ds[f\"{indicator}{period}\"] = index_ds[f\"{indicator}{period}\"].where(mask.values == 1)\n",
    "    return index_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "##### Statistics\n",
    "The following functions calculate and display the difference (by month) between datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: Calculate statistics\n",
    "def align_data_variables(data1: xr.Dataset, data2: xr.Dataset, var: Optional[str]=\"\") -> tuple[xr.Dataset]:\n",
    "    \"\"\"\n",
    "    Only look at variables that are in both datasets, following the order in `data2`.\n",
    "    Optional: variables have to include `var`, e.g. \"SPI\".\n",
    "    \"\"\"\n",
    "    matching_variables = [data_var for data_var in data2.data_vars\n",
    "                          if data_var in data1.data_vars and var in data_var]\n",
    "    data1, data2 = [data[matching_variables] for data in (data1, data2)]\n",
    "    return data1, data2\n",
    "\n",
    "def median_by_month(data: xr.Dataset, *, time_dimension: str=\"time\") -> xr.Dataset:\n",
    "    \"\"\" Calculate the median by month, flattening all other dimensions (time, lat, lon, etc.) \"\"\"\n",
    "    data_by_month = data.groupby(data[time_dimension].dt.month)\n",
    "    median = data_by_month.quantile(0.5, dim=..., skipna=True)  # .quantile function has better dask support than .median\n",
    "    median = median.drop_vars(\"quantile\")  # Drop unneeded coordinate\n",
    "    return median\n",
    "\n",
    "def fraction_by_month(data: xr.Dataset, *, time_dimension: str=\"time\", as_percentage=False) -> xr.Dataset:\n",
    "    \"\"\" Given a dataset of bools, return the fraction per calendar month that are True. \"\"\"\n",
    "    data_by_month = data.groupby(data[time_dimension].dt.month)\n",
    "    fraction = data_by_month.sum(dim=...) / data_by_month.count(dim=...)  # dim=... reduces over all dimensions (e.g. lat, lon)]\n",
    "    fraction = fraction.drop_vars(var for var in fraction.coords if var != \"month\")  # Remove unneeded coordinates (e.g. lat, lon for 1D dataset)\n",
    "    if as_percentage:\n",
    "        fraction *= 100\n",
    "    return fraction\n",
    "\n",
    "# Main function: Calculate statistics\n",
    "def comparison_monthly_statistics(data1: xr.Dataset, data2: xr.Dataset, *,\n",
    "                                  threshold: float=0.10,\n",
    "                                  time_dimension: str=\"time\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given two datasets, calculate a number of statistics for each variable and return the result in a table.\n",
    "    \"\"\"\n",
    "    # Align data variables\n",
    "    data1, data2 = align_data_variables(data1, data2)\n",
    "\n",
    "    # Calculate difference\n",
    "    difference = data2 - data1\n",
    "    difference_absolute = xr.ufuncs.abs(difference)\n",
    "\n",
    "    # Calculate monthly medians\n",
    "    md  = median_by_month(difference,          time_dimension=time_dimension).to_pandas()\n",
    "    mad = median_by_month(difference_absolute, time_dimension=time_dimension).to_pandas()\n",
    "\n",
    "    # Calculate fraction over threshold\n",
    "    difference_over_threshold = (difference_absolute >= threshold)\n",
    "    fraction_over_threshold = fraction_by_month(difference_over_threshold, time_dimension=time_dimension, as_percentage=True).to_pandas()\n",
    "    \n",
    "    # Combine into one DataFrame\n",
    "    stats = pd.concat({\"MÎ”\": md,\n",
    "                       \"M|Î”|\": mad,\n",
    "                      f\"|Î”| â‰¥ {threshold:.2f}\": fraction_over_threshold}, axis=1)\n",
    "    stats = stats.swaplevel(0, 1, axis=1)             # Accumulation period on top, statistic below\n",
    "    stats = stats[data2.data_vars]                    # Same order as inputs\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Styling for statistics\n",
    "def _add_matching_vertical_separators(styler: pdStyler, *,\n",
    "                                      colour=\"#bbbbbb\", width=\"1px\") -> pdStyler:\n",
    "    \"\"\"\n",
    "    Add vertical separators corresponding to the top level columns,\n",
    "        e.g. SPI1 â€“ SPI3 etc. but not Î” â€“ |Î”| in comparison_monthly_statistics outputs.\n",
    "\n",
    "    Note: This function is largely AI-generated, with manual edits.\n",
    "      - Adds a left border to the first subcolumn of each top-level group\n",
    "        in the BODY (data cells),\n",
    "      - Adds the same border to the HEADER cells for both level 0 and level 1\n",
    "        at the same positions (using .col{i} classes).\n",
    "    \"\"\"\n",
    "    # Get data, check applicability\n",
    "    df = styler.data\n",
    "    if not isinstance(df.columns, pd.MultiIndex) or df.columns.nlevels < 2:\n",
    "        raise ValueError(\"Expected MultiIndex columns with â‰¥2 levels.\")\n",
    "\n",
    "    # Group boundaries (indices of first subcolumn of each new top-level label)\n",
    "    lvl0 = df.columns.get_level_values(0).to_numpy()\n",
    "    breaks = np.flatnonzero(lvl0[1:] != lvl0[:-1]) + 1\n",
    "    breaks = np.r_[0, breaks]  # Include first element\n",
    "\n",
    "    # Define common styles\n",
    "    border_left = f\"{width} solid {colour}\"\n",
    "\n",
    "    # 1) BODY: draw the vertical rule down through the data\n",
    "    for i in breaks:\n",
    "        styler = styler.set_properties(\n",
    "            subset=pd.IndexSlice[:, df.columns[i]],\n",
    "            **{\"border-left\": border_left}\n",
    "        )\n",
    "\n",
    "    # 2) HEADER: mirror the exact same left border on header cells\n",
    "    # Each header cell at position i has classes: th.col_heading.level{0|1}.col{i}\n",
    "    header_rules = []\n",
    "    for i in breaks:\n",
    "        header_rules.extend([\n",
    "            {\"selector\": f\"th.col_heading.level0.col{i}\",\n",
    "             \"props\": [(\"border-left\", border_left)]}\n",
    "            ,\n",
    "            {\"selector\": f\"th.col_heading.level1.col{i}\",\n",
    "             \"props\": [(\"border-left\", border_left)]}\n",
    "        ])\n",
    "\n",
    "    # Optional: normalize other header borders so only our verticals stand out\n",
    "    header_rules.extend([\n",
    "        {\"selector\": \"th.col_heading\", \"props\": [(\"border-bottom\", \"0\")]},\n",
    "        # keep overall layout tight and consistent\n",
    "        {\"selector\": \"table\",\n",
    "         \"props\": [(\"border-collapse\", \"separate\"), (\"border-spacing\", \"0\")]}\n",
    "    ])\n",
    "\n",
    "    styler = styler.set_table_styles((styler.table_styles or []) + header_rules)\n",
    "\n",
    "    return styler\n",
    "\n",
    "# Main function: Display statistics\n",
    "def display_monthly_statistics(comparison_stats: pd.DataFrame, *,\n",
    "                               label1: str=\"ERA5â€“Drought\", label2: str=\"Reproduced\", title_suffix: Optional[str]=\"\") -> pdStyler:\n",
    "    \"\"\"\n",
    "    Display the statistics calculated in comparison_monthly_statistics with more style.\n",
    "    Note: does NOT do the actual calculations, unlike in other notebooks.\n",
    "    \"\"\"\n",
    "    # Use words for month names; cannot be done in styler\n",
    "    comparison_stats = comparison_stats.rename(MONTHS_NAMED).rename_axis(None, axis=0)\n",
    "\n",
    "    # Apply styles:\n",
    "    # Number of digits\n",
    "    # Caption\n",
    "    # No sticky index â€“ does not play nice with jupyter-book\n",
    "    # Apply vertical lines to separate columns\n",
    "    formatted = comparison_stats.style \\\n",
    "                                .format(precision=4)  \\\n",
    "                                .set_caption(f\"{label2} â€“ {label1}{title_suffix}\")  \\\n",
    "                                .pipe(_add_matching_vertical_separators)\n",
    "    \n",
    "    # Center headers ; AI-generated\n",
    "    formatted = formatted.set_table_styles(\n",
    "        (formatted.table_styles or []) + [\n",
    "            {'selector': 'th.col_heading',\n",
    "             'props': [('text-align', 'center'),\n",
    "                       ('vertical-align', 'bottom'),\n",
    "                      ],\n",
    "             },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "The following functions compare quality flags quantitatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flagged_months(data: xr.Dataset, *, invert=True) -> xr.Dataset:\n",
    "    \"\"\" For a dataset with quality flags for 12 months, return a new dataset with the number of months failing that flag. \"\"\"\n",
    "    sum_by_month = data.sum(dim=\"month\").astype(np.uint8)  # Number of months *passing* the flag\n",
    "    if invert:  # Make False for e.g. mismatched months\n",
    "        sum_by_month = 12 - sum_by_month                   # Number of months *failing* the flag\n",
    "    return sum_by_month\n",
    "\n",
    "\n",
    "def _matching_fraction(data1: xr.Dataset, data2: xr.Dataset, *,\n",
    "                       precision: int=3) -> pd.Series:\n",
    "    # Round to precision if floating-point numbers\n",
    "    if \"float\" in data1.dtypes.values():\n",
    "        data1, data2 = [data.round(precision) for data in (data1, data2)]\n",
    "\n",
    "    # Compare and determine matching fraction\n",
    "    equal = (data1 == data2)\n",
    "    equal_fraction = equal.sum() / equal.count()\n",
    "    equal_fraction = equal_fraction * 100  # %\n",
    "\n",
    "    # Tabulate\n",
    "    equal_fraction = equal_fraction.compute()  # Perform calculations â€“ this step may take a few minutes\n",
    "    equal_fraction = equal_fraction.to_pandas()  # -> pd.Series\n",
    "\n",
    "    return equal_fraction\n",
    "\n",
    "\n",
    "def compare_quality_flags(flags: dict[str, Iterable[xr.Dataset]],  # e.g. p0 (probabilities), p0 < 0.33 (mask)\n",
    "                          label1: str=\"ERA5â€“Drought\", label2: str=\"Reproduced\", title_suffix: Optional[str]=\"\") -> pdStyler:\n",
    "    # Set up progress bar\n",
    "    flags = tqdm(flags.items(), desc=\"Finding matching flags\", leave=False, unit=\"pair\")\n",
    "\n",
    "    # Perform comparisons\n",
    "    equal_fraction = {\"Matching \"+key: _matching_fraction(*data) for key, data in flags}  # str: pd.Series\n",
    "    \n",
    "    # Tabulate\n",
    "    equal_fraction = pd.DataFrame(equal_fraction).T  # Flags as rows, variables as columns\n",
    "\n",
    "    # Stylise\n",
    "    equal_fraction = equal_fraction.style \\\n",
    "                                   .format(precision=2)  \\\n",
    "                                   .set_caption(f\"{label1} vs. {label2}\\nQuality flag matches{title_suffix}\")\n",
    "\n",
    "    return equal_fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "##### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "The following cell defines [earthkit-plots styles](https://earthkit-plots.readthedocs.io/en/latest/_api/plots/styles/index.html) for the variables in the datasets.\n",
    "These styles define the colour maps and colour bar ranges for each quantity. Earthkit-plots styles are explained further in the [corresponding documentation](https://earthkit-plots.readthedocs.io/en/latest/examples/examples/examples.html#Styles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Translate tabulated categories to Style\n",
    "def categories_to_earthkit_style(var_categories: Iterable[Iterable]) -> Style:  # e.g. CATEGORIES_SPI\n",
    "    \"\"\" From a list of categories, create an earthkit.plots Style. \"\"\"\n",
    "    cmap = ListedColormap([category[3] for category in var_categories[::-1]])  # Colours in reverse (ascending) order\n",
    "    norm =   BoundaryNorm([category[0] for category in var_categories[-2::-1]], cmap.N, extend=\"both\")\n",
    "    style = {\"cmap\": cmap, \"norm\": norm, \"extend\": \"both\"}\n",
    "    return style\n",
    "\n",
    "# Styles for SPI, SPEI based on Keune+25 colours\n",
    "_style_spi  = categories_to_earthkit_style(CATEGORIES_SPI)\n",
    "_style_spei = categories_to_earthkit_style(CATEGORIES_SPEI)\n",
    "_style_spi_diff  = {\"cmap\": plt.cm.RdBu.resampled(11), \"vmin\": -1, \"vmax\": 1, \"extend\": \"both\"}\n",
    "_style_spei_diff = _style_spi_diff\n",
    "\n",
    "# Styles for quality flags\n",
    "_style_probability = {\"cmap\": plt.cm.magma.resampled(30), \"vmin\": 0, \"vmax\": 1}\n",
    "_style_probability_diff = {\"cmap\": plt.cm.RdBu.resampled(15), \"vmin\": -1, \"vmax\": 1}\n",
    "_style_flag_summed = {\"cmap\": ListedColormap([\"#000000\", \"#ffffcd\", \"#f4eabb\", \"#ebd4ac\", \"#e2bc99\", \"#d5a888\", \"#c8947a\",\n",
    "                                                         \"#bf7e6b\", \"#b4685d\", \"#a7544e\", \"#9b3d3f\", \"#8d2733\", \"#800029\",]),\n",
    "                      \"norm\": BoundaryNorm(np.arange(-0.5, 13, 1), 13),\n",
    "                      \"ticks\": np.arange(0, 13, 1),\n",
    "                     }\n",
    "\n",
    "# Individual styles\n",
    "# Set up like this so they can still be edited individually\n",
    "styles = {\n",
    "    # Indexes\n",
    "    \"SPI\":  Style(**_style_spi),  \"SPI_diff\":  Style(**_style_spi_diff),\n",
    "    \"SPEI\": Style(**_style_spei), \"SPEI_diff\": Style(**_style_spei_diff),\n",
    "\n",
    "    # Quality flags\n",
    "    \"probability\": Style(**_style_probability), \"probability_diff\": Style(**_style_probability_diff),\n",
    "    \"flag_summed\": Style(**_style_flag_summed),\n",
    "}\n",
    "\n",
    "# Apply general settings\n",
    "for style in styles.values():\n",
    "    style.normalize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "The following cell contains some base helper functions (e.g. displaying in Jupyter Notebook or Jupyter Book style, adding textboxes with consistent formatting, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation: Helper functions, general\n",
    "def _glue_or_show(fig, glue_label=None):\n",
    "    try:\n",
    "        glue(glue_label, fig, display=False)\n",
    "    except TypeError:\n",
    "        plt.show()\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def _add_textbox_to_subplots(text: str, *axs: plt.Axes | ekp.Subplot, right=False) -> None:\n",
    "    \"\"\" Add a text box to each of the specified subplots. \"\"\"\n",
    "    # Get the plt.Axes for each ekp.Subplot\n",
    "    axs = [subplot.ax if isinstance(subplot, ekp.Subplot) else subplot for subplot in axs]\n",
    "\n",
    "    # Set up location\n",
    "    x = 0.95 if right else 0.05\n",
    "    horizontalalignment = \"right\" if right else \"left\"\n",
    "\n",
    "    # Add the text\n",
    "    for ax in axs:\n",
    "        ax.text(x, 0.95, text, transform=ax.transAxes,\n",
    "        horizontalalignment=horizontalalignment, verticalalignment=\"top\",\n",
    "        bbox={\"facecolor\": \"white\", \"edgecolor\": \"black\", \"boxstyle\": \"round\",\n",
    "              \"alpha\": 1})\n",
    "\n",
    "def plot_zero_line(*axs: plt.Axes) -> None:\n",
    "    \"\"\" Plot the y=0 line with consistent styling. \"\"\"\n",
    "    for ax in axs:\n",
    "        ax.axhline(0, color=\"black\", zorder=1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "The following functions are also base helper functions, but specific to geospatial plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default geospatial domain\n",
    "# To do: Use Robinson CRS but maintain aspect ratio\n",
    "DOMAIN_GLOBAL = ekp.geo.domains.Domain.from_string(\"global\")\n",
    "# DOMAIN_GLOBAL = ekp.geo.domains.Domain.from_string(\"global\", crs=ccrs.Robinson())\n",
    "\n",
    "# Visualisation: Helper functions for geospatial plots\n",
    "def _spatial_plot_append_subplots(fig: ekp.Figure, *data: xr.Dataset, domain: Optional[AnyDomain]=None, **kwargs) -> list[ekp.Subplot]:\n",
    "    \"\"\" Plot any number of datasets into new subplots in an existing earthkit figure. \"\"\"\n",
    "    # Create subplots\n",
    "    subplots = [fig.add_map(domain=domain) for d in data]\n",
    "\n",
    "    # Plot\n",
    "    for subplot, d in zip(subplots, data):\n",
    "        subplot.grid_cells(d, **kwargs)\n",
    "\n",
    "    return subplots\n",
    "\n",
    "def decorate_fig(fig: ekp.Figure, *, title: Optional[str]=\"\") -> None:\n",
    "    \"\"\" Decorate an earthkit figure with land, coastlines, etc. \"\"\"\n",
    "    # Add progress bar because individual steps can be very slow for large plots\n",
    "    with tqdm(total=5, desc=\"Decorating\", leave=False) as progressbar:\n",
    "        fig.land()\n",
    "        progressbar.update()\n",
    "        fig.coastlines()\n",
    "        progressbar.update()\n",
    "        fig.borders()\n",
    "        progressbar.update()\n",
    "        fig.gridlines(linestyle=plt.rcParams[\"grid.linestyle\"])\n",
    "        progressbar.update()\n",
    "        fig.title(title)\n",
    "        progressbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "The following functions handle visualisation of accumulated variables such as total precipitation and water balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function: Plot any accumulated variable\n",
    "def plot_accumulated_variable(data: xr.Dataset, site: dict[str, slice], var: str, *,\n",
    "                              accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS,\n",
    "                              start_at_zero=False, var_label: Optional[str]=None,\n",
    "                              glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\" Plot accumulated time series for variable `var` in multiple accumulation periods, in one `site`. \"\"\"\n",
    "    # Select data in site\n",
    "    data_site = data.sel(**site)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), constrained_layout=True)\n",
    "    \n",
    "    # Plot data for each accumulation period\n",
    "    for period in accumulation_periods:\n",
    "        period_var = f\"{var}{period}\"\n",
    "        data_site[period_var].plot(ax=ax, label=f\"{period:2d} months\")\n",
    "    \n",
    "    # Decorate figure\n",
    "    ax.set_title(f\"{var_label} at ({site['lat']} Â°N, {site['lon']} Â°E) accumulated over different periods\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(f\"Accumulated {var_label}\")\n",
    "    ax.legend(title=\"Accumulation\\nperiod\", reverse=True, loc=\"best\")\n",
    "    if start_at_zero:  # Start y-axis at 0, e.g. for total precipitation\n",
    "        ax.set_ylim(ymin=0)\n",
    "    else:              # If values can be + or -, show the 0-line clearly\n",
    "        plot_zero_line(ax)      \n",
    "\n",
    "    # Show result\n",
    "    _glue_or_show(fig, glue_label)\n",
    "\n",
    "\n",
    "# Plot tp, wb with preset names\n",
    "plot_accumulated_precipitation = partial(plot_accumulated_variable, var=\"tp\", start_at_zero=True,  var_label=\"Total precipitation [mm]\")\n",
    "plot_accumulated_waterbalance  = partial(plot_accumulated_variable, var=\"wb\", start_at_zero=False, var_label=\"Water balance [mm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "The following functions produce time series comparisons between datasets, such as reproduced vs. ERA5â€“Drought SPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Display SPI / SPEI categories\n",
    "def plot_index_categories(ax: plt.Axes, categories: Iterable[Iterable]) -> None:\n",
    "    \"\"\" Display SPI / SPEI categories (e.g. \"extreme drought\") on an Axes panel. \"\"\"\n",
    "    for low, high, label, colour in categories:\n",
    "        ax.axhspan(low, high, facecolor=colour, edgecolor=None, alpha=0.25)\n",
    "\n",
    "\n",
    "# Main function: Plot time series of absolute values (left) and differences (right)\n",
    "def plot_time_series_comparison(data1: xr.Dataset, data2: xr.Dataset, var: str, *,\n",
    "                                accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS,\n",
    "                                var_categories: Optional[Iterable[Iterable]]=None,  # e.g. CATEGORIES_SPI\n",
    "                                label1: str=\"ERA5â€“Drought\", label2: str=\"Reproduced\", title_suffix: Optional[str]=\"\",\n",
    "                                glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot time series of one variable (e.g. SPI) in two datasets.\n",
    "    Left column: Overlapping time series.\n",
    "    Right column: Differences (data2 â€“ data1).\n",
    "\n",
    "    One row for each accumulation period.\n",
    "    `var` and `accumulation_periods` are provided manually, rather than inferred,\n",
    "        to allow plotting of individual time series.\n",
    "    \"\"\"\n",
    "    # Calculate difference\n",
    "    difference = data2 - data1\n",
    "    difference_label = f\"{label2} â€“ {label1}\"\n",
    "\n",
    "    # Setup: Figure\n",
    "    ncols = 2\n",
    "    nrows = len(accumulation_periods)  # Note: not checking if accumulation periods are actually present in data1, data2\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=\"col\", squeeze=False,\n",
    "                            layout=\"constrained\", gridspec_kw={\"wspace\": 0.07}, figsize=(10, 2.7*nrows))\n",
    "\n",
    "    # Setup: Styles for line plots\n",
    "    timeseries_kwargs = [{\"color\": \"tab:blue\", \"linestyle\": \"-\", \"label\": label1},\n",
    "                         {\"color\": \"tab:orange\", \"linestyle\": \"dotted\", \"label\": label2},\n",
    "                        ]\n",
    "\n",
    "    # Plot data\n",
    "    for ax_row, period in zip(axs, accumulation_periods):\n",
    "        var_period = f\"{var}{period}\"\n",
    "\n",
    "        # Plot absolute time series\n",
    "        for data, style in zip([data1, data2], timeseries_kwargs):\n",
    "            data[var_period].plot(ax=ax_row[0], **style, zorder=2)\n",
    "\n",
    "        # Display categories and 0 line\n",
    "        plot_index_categories(ax_row[0], var_categories)\n",
    "        plot_zero_line(*ax_row)\n",
    "\n",
    "        # Plot difference\n",
    "        difference[var_period].plot(ax=ax_row[1], color=\"#004488\", zorder=2)\n",
    "        md  = nanmedian(ravel(              difference[var_period]),  axis=0).compute()\n",
    "        mad = nanmedian(ravel(xr.ufuncs.abs(difference[var_period])), axis=0).compute()\n",
    "        _add_textbox_to_subplots(f\"Median Î”: {md:+.4f}\\nMedian |Î”|: {mad:.4f}\", ax_row[1], right=True)\n",
    "        \n",
    "\n",
    "    # Decorate figure\n",
    "    for ax in axs.ravel():\n",
    "        ax.set_title(None)\n",
    "    axs[0, 0].set_title(f\"{var} values\")\n",
    "    axs[0, 1].set_title(f\"Difference ({difference_label})\")\n",
    "\n",
    "    axs[0, 0].set_ylim(-8, 8)\n",
    "    axs[0, 1].set_ylim(-1, 1)\n",
    "\n",
    "    for ax in axs[:, 0]:\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "    for ax in axs[:-1].ravel():\n",
    "        ax.set_xlabel(None)\n",
    "    for ax in axs[-1]:\n",
    "        ax.set_xlabel(\"Time\")\n",
    "    for ax_row, period in zip(axs, accumulation_periods):\n",
    "        ax_row[0].set_ylabel(f\"{var}-{period}\")\n",
    "        ax_row[1].set_ylabel(f\"{var}-{period} difference\")\n",
    "\n",
    "    fig.suptitle(f\"{label1} vs. {label2}\\nTime series for {var}{title_suffix}\")\n",
    "    fig.align_ylabels()\n",
    "\n",
    "    # Show result\n",
    "    _glue_or_show(fig, glue_label)\n",
    "\n",
    "\n",
    "# Plot SPI, SPEI with preset names\n",
    "plot_time_series_comparison_spi  = partial(plot_time_series_comparison, var=\"SPI\",  var_categories=CATEGORIES_SPI)\n",
    "plot_time_series_comparison_spei = partial(plot_time_series_comparison, var=\"SPEI\", var_categories=CATEGORIES_SPEI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "The following functions produce confusion matrices for the SPI / SPEI categories, e.g. how many \"extremely dry\" points in the reproduced dataset are also classified as \"extremely dry\" in ERA5â€“Drought:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function: Plot confusion matrices with counts (text) and fractions (colour)\n",
    "def plot_confusion_matrices(data1: xr.Dataset, data2: xr.Dataset, var: str, var_categories: Iterable[Iterable], *,  # e.g. CATEGORIES_SPI\n",
    "                            label1: str=\"ERA5â€“Drought\", label2: str=\"Reproduced\", title_suffix: Optional[str]=\"\",\n",
    "                            glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot confusion matrices of categories for one variable (e.g. SPI \"extremely dry\") in two datasets.\n",
    "    One panel for each data_variable that occurs in both datasets and matches the variable `var`,\n",
    "        e.g. different accumulation periods.\n",
    "    \"\"\"\n",
    "    # Align datasets\n",
    "    data1, data2 = align_data_variables(data1, data2, var=var)  # Ensure only matching variables\n",
    "    data1, data2 = xr.align(data1, data2)  # Ensure only matching points\n",
    "    # data1 = data1.transpose(*[dim for dim in data2.dims])  # Ensure same order of dimensions\n",
    "    data1, data2 = [data.stack(point=data2.dims) for data in (data1, data2)]  # Make 1D list\n",
    "\n",
    "    # Apply categorisation\n",
    "    categories1, categories2 = [categorise_dataset(data, var_categories) for data in (data1, data2)]\n",
    "\n",
    "    # Create figure\n",
    "    n_categories = len(var_categories)\n",
    "    category_index = np.arange(n_categories)\n",
    "    n_datavars = len(data2.data_vars)\n",
    "    ncols = 2\n",
    "    nrows = (n_datavars // ncols) + 1\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5*ncols, 4*nrows),\n",
    "                            gridspec_kw={\"hspace\": 0.01, \"wspace\": 0.01}, layout=\"constrained\")\n",
    "\n",
    "    # Loop over data variables\n",
    "    for ax, data_var in zip(axs.ravel(), data2.data_vars):\n",
    "        # Create confusion matrix from categorisation values\n",
    "        matrix_absolute = confusion_matrix(categories1[data_var], categories2[data_var], labels=category_index+1)\n",
    "        matrix_relative = confusion_matrix(categories1[data_var], categories2[data_var], labels=category_index+1, normalize=\"true\")  # Normalised by rows (data1)\n",
    "        # For operational code, you would add an assert here to check that the sum of elements in matrix_absolute\n",
    "        # corresponds to the number of not-NaN elements of the input data\n",
    "\n",
    "        # Plot fractions for color background\n",
    "        image = ax.imshow(matrix_relative, cmap=plt.cm.Blues.resampled(10), vmin=0.0, vmax=1.0)\n",
    "\n",
    "        # Annotate with absolute counts\n",
    "        for i in category_index:\n",
    "            for j in category_index:\n",
    "                counts_abs, counts_rel = matrix_absolute[i, j], matrix_relative[i, j]\n",
    "                ax.text(j, i, f\"{counts_abs:.0f}\", ha=\"center\", va=\"center\",  # Add text\n",
    "                        color=\"white\" if counts_rel > 0.5 else \"black\",       # Colour based on background\n",
    "                        fontsize=9, clip_on=True)                             # Text settings\n",
    "\n",
    "        # Label based on data variable, adding a hyphen\n",
    "        data_var_hyphenated = data_var.replace(var, var+\"-\")\n",
    "        ax.set_title(data_var_hyphenated)\n",
    "\n",
    "    # Add category labels\n",
    "    category_labels = [category[2] for category in var_categories]\n",
    "    for ax in axs.ravel():\n",
    "        ax.set_xticks(category_index, labels=category_labels, rotation=30, ha=\"right\", fontsize=9)\n",
    "        ax.set_yticks(category_index, labels=category_labels, fontsize=9)\n",
    "        ax.grid(False)\n",
    "        ax.xaxis.set_inverted(True)\n",
    "\n",
    "    # Add a single shared colorbar showing row-wise fraction\n",
    "    cbar = fig.colorbar(image, ax=axs, location=\"right\", fraction=0.05, pad=0.05)# shrink=0.6)\n",
    "    cbar.set_label(f\"Fraction of {label1} data (rows)\")\n",
    "\n",
    "    # Hide extra panels if odd number of variables\n",
    "    for ax in axs.ravel()[n_datavars:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # Decorate figure\n",
    "    fig.suptitle(f\"{label1} vs. {label2}\\nConfusion matrices for {var}{title_suffix}\")\n",
    "    fig.supxlabel(label2, fontweight=\"bold\", fontsize=16)\n",
    "    fig.supylabel(label1, fontweight=\"bold\", fontsize=16)\n",
    "\n",
    "    # Show result\n",
    "    _glue_or_show(fig, glue_label)\n",
    "\n",
    "\n",
    "# Plot SPI, SPEI with preset names\n",
    "plot_confusion_matrices_spi  = partial(plot_confusion_matrices, var=\"SPI\",  var_categories=CATEGORIES_SPI)\n",
    "plot_confusion_matrices_spei = partial(plot_confusion_matrices, var=\"SPEI\", var_categories=CATEGORIES_SPEI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "The following functions display geospatial comparisons between index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function: Plot maps of absolute values (left, middle) and differences (right)\n",
    "def plot_geospatial_comparison(data1: xr.Dataset, data2: xr.Dataset, var: str, time: str, *,\n",
    "                               label1: str=\"ERA5â€“Drought\", label2: str=\"Reproduced\", title_suffix: Optional[str]=\"\",\n",
    "                               domain: AnyDomain=DOMAIN_GLOBAL,\n",
    "                               time_dimension: str=\"time\",\n",
    "                               glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot geospatial views of categories for one variable (e.g. SPI \"extremely dry\") in two datasets.\n",
    "    One panel for each data_variable that occurs in both datasets and matches the variable `var`,\n",
    "        e.g. different accumulation periods.\n",
    "    \"\"\"\n",
    "    # Select data for one timestamp\n",
    "    data1, data2 = [data.sel({time_dimension: time})\n",
    "                    for data in (data1, data2)]\n",
    "\n",
    "    # Only look at variables that are in both datasets\n",
    "    # Note: Not checking for matching coordinates / xr.align\n",
    "    data1, data2 = align_data_variables(data1, data2, var=var)\n",
    "\n",
    "    # Calculate difference\n",
    "    difference = data2 - data1\n",
    "    difference_label = f\"{label2} â€“ {label1}\"\n",
    "\n",
    "    # Setup: Figure\n",
    "    nrows = len(data2.data_vars)\n",
    "    ncols = 3  # data1, data2, diff\n",
    "    fig = ekp.Figure(rows=nrows, columns=ncols, size=(4*ncols, 3.7*nrows))\n",
    "\n",
    "    # Loop over variables (e.g. accumulation periods)\n",
    "    for data_var in data2.data_vars:\n",
    "        # Plot index\n",
    "        for data in (data1, data2):\n",
    "            subplot = fig.add_map(domain=domain)\n",
    "            subplot.grid_cells(data, z=data_var, style=styles[var])\n",
    "\n",
    "        # Plot difference\n",
    "        subplot_diff = fig.add_map(domain=domain)\n",
    "        subplot_diff.grid_cells(difference, z=data_var, style=styles[var+\"_diff\"])\n",
    "\n",
    "    # Label dataset at the top\n",
    "    for subplot, label in zip(fig.subplots[:ncols], [label1, label2, difference_label]):\n",
    "        subplot.title(label)\n",
    "\n",
    "    # Label indicator in the corner\n",
    "    for subplots, data_var in zip(batched(fig.subplots, ncols), data2.data_vars):\n",
    "        _add_textbox_to_subplots(data_var, *subplots)\n",
    "\n",
    "    # Legend at the bottom\n",
    "    for subplot in fig.subplots[-ncols:]:\n",
    "        subplot.legend(label=var)\n",
    "\n",
    "    # Decorate figure\n",
    "    time_for_title = time[:7] # Could be changed to proper datetime format, e.g. %B %Y\n",
    "    title = f\"{label1} vs. {label2}\\nGeospatial comparison for {var} ({domain.name}, {time_for_title}){title_suffix}\"\n",
    "    decorate_fig(fig, title=title)\n",
    "\n",
    "    # Show result\n",
    "    _glue_or_show(fig.fig, glue_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "The following functions display geospatial comparisons between quality flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function: Plot maps of absolute values (left, middle) and differences (right)\n",
    "def plot_geospatial_comparison_quality_flags(var: str, example_month: int, *,\n",
    "                                             probabilities: Optional[dict[str, Iterable[xr.Dataset]]]={},  # e.g. p0\n",
    "                                             masks:         Optional[dict[str, Iterable[xr.Dataset]]]={},  # e.g. p0 < 0.33 or alpha > 0.05\n",
    "                                             label1: str=\"ERA5â€“Drought\", label2: str=\"Reproduced\", title_suffix: Optional[str]=\"\",\n",
    "                                             flag_label: Optional[str]=None,\n",
    "                                             domain: AnyDomain=DOMAIN_GLOBAL, shared_mask: Optional[xr.DataArray]=True,\n",
    "                                             month_dimension: str=\"month\",\n",
    "                                             glue_label: Optional[str]=None) -> None:\n",
    "    \"\"\"\n",
    "    Plot geospatial views of pre-calculated quality flags in two datasets.\n",
    "    probabilities are datasets with quality flag probabilities.\n",
    "        These are ingested as a dict with str keys (the label for that mask) and an Iterable of xr.Datasets.\n",
    "        These are displayed for variable `var` (e.g. tp3, SPEI3) in `example_month` (e.g. 12).\n",
    "    masks created from the quality flags can be included, e.g. where p0 <= 0.33.\n",
    "        These are ingested as a dict with str keys (the label for that mask) and an Iterable of xr.Datasets.\n",
    "        Following Keune+25 Fig 3, masks are displayed as their sum over all 12 months (left, middle)\n",
    "        as well as the number of mismatched months (right).\n",
    "    An additional `shared_mask`, e.g. a land-sea mask, can be applied to all panels.\n",
    "    \"\"\"\n",
    "    # Setup: Labels\n",
    "    difference_label = f\"{label2} â€“ {label1}\"\n",
    "\n",
    "    # Setup: Types of data to plot\n",
    "    n_probabilities, n_masks = len(probabilities), len(masks)\n",
    "    assert n_probabilities or n_masks, \"No data provided to plot_geospatial_comparison_quality_flags.\"\n",
    "\n",
    "    # Setup: Figure\n",
    "    nrows = n_probabilities + n_masks  # 1 each per probability (generally 0 or 1) + 1 each per mask\n",
    "    ncols = 3  # data1, data2, diff\n",
    "    figsize = (4*ncols, 1.5+3*nrows) if domain.name == \"Global\" else (4*ncols, 1.5+3.7*nrows)  # Adjust aspect ratio for global plots\n",
    "    fig = ekp.Figure(rows=nrows, columns=ncols, size=figsize)\n",
    "\n",
    "    # Plot probabilities (if any)\n",
    "    for key, list_of_datasets in probabilities.items():\n",
    "        # Select data for one month\n",
    "        list_of_datasets = [prob.sel({month_dimension: example_month}) for prob in list_of_datasets]\n",
    "\n",
    "        # Calculate difference\n",
    "        probability_difference = xr.ufuncs.subtract(*list_of_datasets[::-1])  # data2 - data1\n",
    "\n",
    "        # Create and fill panels\n",
    "        subplots = [fig.add_map(domain=domain) for j in range(ncols)]\n",
    "\n",
    "        for subplot, prob in zip(subplots, list_of_datasets):\n",
    "            subplot.grid_cells(prob.where(shared_mask), z=var, style=styles[\"probability\"])\n",
    "        subplots[-1].grid_cells(probability_difference.where(shared_mask), z=var, style=styles[\"probability_diff\"])\n",
    "\n",
    "        # Add colour bars\n",
    "        subplots[0].legend(label=key, location=\"left\")\n",
    "        subplots[-1].legend(label=\"Difference\", location=\"right\")\n",
    "\n",
    "    # Plot masks (if any)\n",
    "    for key, list_of_datasets in masks.items():\n",
    "        # Create and fill panels\n",
    "        subplots = [fig.add_map(domain=domain) for j in range(ncols)]\n",
    "\n",
    "        for subplot, mask in zip(subplots, list_of_datasets):\n",
    "            # Add up per month and invert (to get number of *flagged* rather than *allowed* points)\n",
    "            flagged_months = count_flagged_months(mask)\n",
    "\n",
    "            # Plot\n",
    "            subplot.grid_cells(flagged_months.where(shared_mask), z=var, style=styles[\"flag_summed\"])\n",
    "\n",
    "        # Find and plot mismatched months\n",
    "        mask1, mask2 = list_of_datasets\n",
    "        masks_not_matching = (mask1 != mask2)\n",
    "        months_not_matching = count_flagged_months(masks_not_matching, invert=False)\n",
    "        subplots[-1].grid_cells(months_not_matching.where(shared_mask), z=var, style=styles[\"flag_summed\"])\n",
    "\n",
    "        # Add colour bars\n",
    "        subplots[0].legend(label=\"Flagged months\", location=\"left\")\n",
    "        subplots[-1].legend(label=\"Mismatched months\", location=\"right\")\n",
    "\n",
    "        # Label masks in the corner\n",
    "        _add_textbox_to_subplots(key, *subplots)\n",
    "\n",
    "    # Label dataset at the top\n",
    "    for subplot, label in zip(fig.subplots[:ncols], [label1, label2, difference_label]):\n",
    "        subplot.title(label)\n",
    "\n",
    "    # Decorate figure\n",
    "    month_for_title = MONTHS_NAMED[example_month]\n",
    "    title = f\"{label1} vs. {label2}\\nGeospatial comparison of {flag_label}\\n({domain.name}, {month_for_title}, {var}){title_suffix}\"\n",
    "    decorate_fig(fig, title=title)\n",
    "\n",
    "    # Show result\n",
    "    _glue_or_show(fig.fig, glue_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "(section-general_setup)=\n",
    "### 2. General setup\n",
    "This section provides some of the setup for the further analysis,\n",
    "including\n",
    "the timespan and sites to investigate\n",
    "as well as\n",
    "the CDS data downloads.\n",
    "This ensures that the following sections\n",
    "(SPI, SPEI, etc.)\n",
    "can be run independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### 2.1 Analysis setup\n",
    "In this assessment,\n",
    "we will calculate SPI and SPEI for the years 1940â€“2024.\n",
    "For the reference period,\n",
    "we will use the World Meteorological Organization (WMO) current standard 30-year reference period of 1991â€“2020,\n",
    "which is also used in ERA5â€“Drought.\n",
    "Both of these date ranges can be adjusted in the cell below when running the analysis yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your preferred analysis and reference periods\n",
    "years           = (1940, 2024)  # Years for the analysis (inclusive)\n",
    "years_reference = (1991, 2020)  # Years for the reference period (inclusive)\n",
    "\n",
    "# Derived variables for convenience:\n",
    "reference_window = {\"time\": slice(f\"{years_reference[0]}-01-01\", f\"{years_reference[1]}-12-01\"),}  #  Slice (1991-01-01, 2020-12-01)\n",
    "entire_window    = {\"time\": slice(f\"{years[0]}-01-01\",           f\"{years[1]}-12-01\"),}            #  Slice (1940-01-01, 2024-12-01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "Some parts of the analysis will be performed globally, others in specific sites for computational reasons.\n",
    "This notebook uses Addis Ababa in Ethiopia (9.00 Â°N, 38.75 Â°E) and the Horn of Africa region around it as an example;\n",
    "a different site can be chosen when running the notebook yourself by editing the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your preferred site for the time series analysis\n",
    "example_site = {\"lat\": 9.00, \"lon\": 38.75}  # Compatible with ERA5â€“Drought and pre-processed ERA5 data\n",
    "\n",
    "# Define the size and name of the surrounding region\n",
    "example_region_size = 12  # Degrees to either side of the example side\n",
    "example_region_size = 2  # TESTING ONLY\n",
    "label_region = \"Horn of Africa\"\n",
    "\n",
    "# Define the year for the example region analysis\n",
    "snapshot_year = 2024\n",
    "\n",
    "# Derived variables for convenience\n",
    "# Example site\n",
    "label_site = f\"({example_site['lat']:.2f} Â°N, {example_site['lon']:.2f} Â°E)\"\n",
    "request_site = request_data_for_one_site(lat=example_site[\"lat\"], lon=example_site[\"lon\"])\n",
    "\n",
    "# Example region\n",
    "example_region = {\"lat\": slice(example_site[\"lat\"] + example_region_size, example_site[\"lat\"] - example_region_size),  # Decreasing order\n",
    "                  \"lon\": slice(example_site[\"lon\"] - example_region_size, example_site[\"lon\"] + example_region_size),} # Increasing order\n",
    "request_region = request_data_for_one_site(lat=example_site[\"lat\"], lon=example_site[\"lon\"], half_width=example_region_size)\n",
    "domain_region = ekp.geo.domains.Domain(\n",
    "    bbox=[example_region[\"lon\"].start, example_region[\"lon\"].stop, example_region[\"lat\"].start, example_region[\"lat\"].stop],\n",
    "    name=label_region,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "#### 2.2 CDS download setup\n",
    "Having defined our target years, we can now define our CDS request.\n",
    "First, we define templates with some default parameters\n",
    "(e.g. years, data format)\n",
    "that will also be used later in the notebook.\n",
    "Additional information for specific downloads\n",
    "(e.g. variable, data stream)\n",
    "is mixed into this template where relevant.\n",
    "\n",
    "This notebook uses [earthkit-data](https://github.com/ecmwf/earthkit-data) to download files from the CDS.\n",
    "If you intend to run this notebook multiple times, it is highly recommended that you [enable caching](https://earthkit-data.readthedocs.io/en/latest/guide/caching.html) to prevent having to download the same files multiple times.\n",
    "If you prefer not to use earthkit, the following requests can also be used with the [cdsapi module](https://cds.climate.copernicus.eu/how-to-api#linux-use-client-step).\n",
    "In either case (earthkit-data or cdsapi), it is required to set up a CDS account and API key as explained [on the CDS website](https://cds.climate.copernicus.eu/how-to-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "##### ERA5\n",
    "We start by setting up a template for requests from the [_Complete ERA5 global atmospheric reanalysis_](https://doi.org/10.24381/cds.143582cf) dataset, from which we will obtain precipitation and (for SPEI) potential evapotranspiration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_ERA5 = \"reanalysis-era5-complete\"\n",
    "\n",
    "request_era5_template = {\n",
    "    \"class\": \"ea\",            # Default for ERA5\n",
    "    # Dates: ERA5 takes these in the format 19400101/19400201/.../20241101/20241201\n",
    "    # The following lines generate a string in said format for the chosen year range\n",
    "    \"date\": \"/\".join(f\"{year}{month:02}01\"                    # yyyymm01 format\n",
    "                     for year in range(years[0], years[1]+1)  # All years in specified range, inclusive\n",
    "                     for month in MONTHS),                    # All calendar months\n",
    "    \"expver\": \"1\",            # ERA5 consolidated data\n",
    "    \"levtype\": \"sfc\",         # Surface\n",
    "    \"grid\": \"0.25/0.25\",      # Grid: 0.25Â° by 0.25Â° (interpolated from native)\n",
    "    \"type\": \"fc\",             # Forecast\n",
    "    \"data_format\": \"netcdf\",  # NetCDF data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "##### ERA5â€“Drought\n",
    "We also set up a template for requests from ERA5â€“Drought ([_Monthly drought indices from 1940 to present derived from ERA5 reanalysis_](https://doi.org/10.24381/9bea5e16)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_ERA5_DROUGHT = \"derived-drought-historical-monthly\"\n",
    "\n",
    "# General request template\n",
    "request_era5drought_template = {\n",
    "    \"version\": \"1_0\",                                # Current version\n",
    "    \"dataset_type\": \"consolidated_dataset\",          # Only use consolidated data, i.e. not ERA5T-derived\n",
    "    \"month\": [f\"{month:02d}\" for month in MONTHS],   # All calendar months\n",
    "}\n",
    "\n",
    "# Request for SPI or SPEI data\n",
    "request_era5drought_index = {\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"accumulation_period\": [str(p) for p in ACCUMULATION_PERIODS],\n",
    "    \"year\": [f\"{year}\" for year in range(years[0], years[1]+1)],    \n",
    "} | request_era5drought_template\n",
    "\n",
    "# Request for quality flags\n",
    "request_era5drought_flag = {\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "} | request_era5drought_template\n",
    "\n",
    "# Request for SPI/SPEI ensemble data\n",
    "request_ens_era5drought_index = {\n",
    "    \"product_type\": [\"ensemble_members\"],\n",
    "    \"accumulation_period\": [str(p) for p in ACCUMULATION_PERIODS],\n",
    "     \"year\": [f\"{year}\" for year in range(years[0], years[1]+1)],    \n",
    "} | request_era5drought_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "#### 2.3 Download land-sea mask\n",
    "ERA5â€“Drought uses a land-sea mask to only provide values over land.\n",
    "Here, we download the [ERA5 land-sea mask](https://confluence.ecmwf.int/display/FUG/Section+2.1.3.1+Land-Sea+Mask) from the [_ERA5 hourly data on single levels from 1940 to present_](https://doi.org/10.24381/cds.adbb2d47) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_ERA5_LANDSEAMASK = \"reanalysis-era5-single-levels\"\n",
    "\n",
    "request_landsea_mask = {\n",
    "    \"product_type\": \"reanalysis\",\n",
    "    \"variable\": \"land_sea_mask\",\n",
    "    \"date\": \"2000-01-01\",  # Does nothing but is required in CDS form\n",
    "    \"time\": \"00:00\",       # Does nothing but is required in CDS form\n",
    "    \"format\": \"netcdf\",\n",
    "    \"download_format\": \"zip\",\n",
    "}\n",
    "\n",
    "# Download mask\n",
    "LAND = ekd.from_source(\"cds\", ID_ERA5_LANDSEAMASK, request_landsea_mask)\n",
    "LAND = LAND.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "\n",
    "# Convert longitude from 0..360 to â€“180..180\n",
    "LAND = rename_era5_dimensions(LAND)\n",
    "LAND = longitude_360_to_180(LAND, \"lon\")\n",
    "\n",
    "# Drop time dimension\n",
    "LAND = LAND.squeeze(\"time\")\n",
    "\n",
    "# Convert to boolean mask: Land if > 0.5 (following ERA5 convention)\n",
    "LAND = (LAND[\"lsm\"] > 0.5) # Land considered to be full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-spi)=\n",
    "### 3. SPI comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.1 Download monthly precipitation data from ERA5\n",
    "First, the monthly-mean total precipitation data from the ERA5 reanalysis is downloaded.\n",
    "Generally, one would use the [_ERA5 monthly averaged data on single levels from 1940 to present_](https://doi.org/10.24381/cds.f17050d7) dataset for this, which provides pre-calculated monthly means at 0.25Â° by 0.25Â° resolution.\n",
    "For this assessment,\n",
    "to be as close to the ERA5â€“Drought data processing pipeline as possible\n",
    "and\n",
    "to make use of some of MARS's functionalities (see [](section-ensemble)),\n",
    "we instead use the [_Complete ERA5 global atmospheric reanalysis_](https://doi.org/10.24381/cds.143582cf) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "We want to download \n",
    "total precipitation data (variable `228.128`)\n",
    "from the\n",
    "`moda` stream (monthly-mean reanalysis data),\n",
    "so we mix this information into the request template set up [previously](section-general_setup)\n",
    "and submit the request to the CDS.\n",
    "More information about the format for these requests is available in the [MARS ERA5 catalogue](https://apps.ecmwf.int/data-catalogues/era5/?class=ea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_precipitation_moda = {\n",
    "    \"param\": \"228.128\",  # Variable: Total precipitation\n",
    "    \"stream\": \"moda\",    # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data and load into xarray\n",
    "data_era5_precipitation_cds = ekd.from_source(\"cds\", ID_ERA5, request_era5_precipitation_moda)  # Download as field list\n",
    "data_era5_precipitation_cds = data_era5_precipitation_cds.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "\n",
    "# Pre-process to desired format\n",
    "# Note the change in variable name\n",
    "data_era5_precipitation_preprocessed = preprocess_era5(data_era5_precipitation_cds)\n",
    "\n",
    "# Display in notebook\n",
    "data_era5_precipitation_preprocessed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.2 Calculate total precipitation over accumulation periods\n",
    "As explained above,\n",
    "SPI and SPEI are commonly evaluated over different accumulation periods.\n",
    "ERA5â€“Drought provides both indices for periods of 1, 3, 6, 12, 24, 36, and 48 months.\n",
    "Here, we perform this accumulation by calculating the total precipitation over the previous _p_ months\n",
    "at every coordinate and timestamp in the ERA5 data,\n",
    "for each accumulation period _p_.\n",
    "The implementation used here\n",
    "(which can be found in [](section-code_setup))\n",
    "accounts for the variable number of days in each month,\n",
    "including leap years.\n",
    "\n",
    "The resulting accumulated time series for the example site defined in [](section-general_setup),\n",
    "Addis Ababa in Ethiopia in our example,\n",
    "are displayed in Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-tp-accumulated>`.\n",
    "This example clearly shows how shorter accumulation periods probe short-term effects such as seasonality,\n",
    "which are smoothed out in longer periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Accumulate total precipitation\n",
    "data_era5_precipitation = accumulate(data_era5_precipitation_preprocessed, \"tp\")\n",
    "\n",
    "# Display result\n",
    "data_era5_precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accumulated precipitation at example site\n",
    "plot_accumulated_precipitation(data_era5_precipitation, example_site,\n",
    "                               glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-tp-accumulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-tp-accumulated\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-tp-accumulated\"\n",
    "\n",
    "Total precipitation from ERA5 accumulated over different periods, for the example site of Addis Ababa, Ethiopia.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.3 Fit gamma distribution by calendar month\n",
    "At the core of SPI is the assumption that (monthly) total precipitation values follow a gamma distribution.\n",
    "Here, this distribution is fitted to data within the reference period (1991â€“2020 by default, see above).\n",
    "A separate distribution is fitted for each calendar month,\n",
    "i.e.\n",
    "we fit one distribution for all 30 Januaries in the reference period,\n",
    "another for all 30 Februaries,\n",
    "and so on.\n",
    "This separation allows the resulting index to account for seasonal differences.\n",
    "This is then repeated for each accumulation period.\n",
    "\n",
    "Here, we use\n",
    "[scipy.stats.gamma](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html)\n",
    "to fit the gamma distribution.\n",
    "This returns three parameters for each calendar month and accumulation period, namely\n",
    "shape (_Î±_), location (_Î¼_), and scale (_Î²_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Select data in reference window\n",
    "data_era5_precipitation_reference = data_era5_precipitation.sel(**reference_window)\n",
    "\n",
    "# Fit gamma distribution\n",
    "spi_parameters = fit_monthly_spi(data_era5_precipitation_reference)\n",
    "\n",
    "# Display result\n",
    "spi_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "The observed (accumulated) total precipitation values along the entire time series\n",
    "(1940â€“2024 in our example)\n",
    "are then compared to the fitted parameters.\n",
    "This is quantified in terms of where the observed values fall on the cumulative distribution function (CDF):\n",
    "\n",
    "$$\n",
    "P(X \\leq x) = F_X(x ; \\alpha, \\mu, \\beta) = \\int_{-\\infty}^{x}f(y ; \\alpha, \\mu, \\beta) \\, \\text{d}y\n",
    "$$\n",
    "\n",
    "Where\n",
    "_P(X â‰¤ x)_ is the probability for a randomly drawn total precipitation _X_ to be equal to or less than the observed value _x_;\n",
    "_F{sub}`X`_ is the CDF for a gamma distribution with shape _Î±_, location _Âµ_, and scale _Î²_;\n",
    "and\n",
    "the CDF is equal to the integral of the corresponding probability density function up to _x_.\n",
    "\n",
    "As before, there is a distribution for each calendar month, for each accumulation period.\n",
    "\n",
    "Note that actually evaluating the CDF\n",
    "â€“ as opposed to [queueing it up in dask](https://docs.xarray.dev/en/stable/user-guide/dask.html), as done here â€“\n",
    "can be slow, especially for a large dataset like global ERA5 precipitation.\n",
    "As such, if you are interested in a subset of the data,\n",
    "such as a specific site or period in time,\n",
    "it may be best to subset your data _before_ calculating the CDF rather than afterwards.\n",
    "An example of this is provided below in the comparison with ERA5â€“Drought SPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CDF time series\n",
    "cdf = compute_cdf_spi(data_era5_precipitation, spi_parameters)\n",
    "\n",
    "# Display result\n",
    "cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.4 Adjust for months with zero precipitation\n",
    "Sometimes, zero (or near-zero) monthly precipitation is observed,\n",
    "particularly in dry areas like deserts.\n",
    "Maintaining the desired statistics,\n",
    "such as the mean SPI in the reference period being 0,\n",
    "requires adjusting the CDF to account for these zero-precipitation months.\n",
    "\n",
    "ERA5â€“Drought follows the [[Stagge+15](https://doi.org/10.1002/joc.4267)] method to adjust the CDF.\n",
    "First, the probability of zero precipitation is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\bar{p_0} = \\frac{n_0 + 1}{2 (n + 1)}\n",
    "$$\n",
    "\n",
    "where\n",
    "_n{sub}`0`_ is the number of months with zero precipitation in the reference period,\n",
    "and\n",
    "_n_ is the total number of months in the reference period (here 30 for 1991â€“2020).\n",
    "While some datasets define \"zero precipitation\" using a slightly higher threshold\n",
    "(e.g. less than 0.1 mm)\n",
    "to account for measurement uncertainty,\n",
    "ERA5â€“Drought uses a threshold of exactly 0 mm total precipitation in the underpinning ERA5 data.\n",
    "\n",
    "Having calculated the probability of zero precipitation, the CDF is adjusted as follows:\n",
    "\n",
    "$$\n",
    "F'_X(x ; \\alpha, \\mu, \\beta) =\n",
    "\\begin{cases}\n",
    "\\bar{p_0} + (1 - \\bar{p_0}) \\, F_X(x; \\alpha, \\mu, \\beta), & x > 0, \\\\\n",
    "\\frac{n_0 + 1}{2(n+1)}, & x = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "As before, this adjustment is carried out individually for each calendar month and accumulation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Adjust CDF\n",
    "cdf_adjusted = adjust_cdf_for_zero_precipitation(cdf, data_era5_precipitation_reference)\n",
    "\n",
    "# Display result\n",
    "cdf_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.5 Compute SPI\n",
    "Finally,\n",
    "SPI values\n",
    "for each data point (latitude, longitude, time)\n",
    "are calculated from the adjusted CDF values _F'{sub}`X`_ by transforming to a standard normal distribution.\n",
    "The function [scipy.stats.norm.ppf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) is used to calculate the inverse CDF _Î¦{sup}`-1`_ of the normal distribution:\n",
    "\n",
    "$$\n",
    "\\text{SPI}(x) = \\Phi^{-1}\\left(F'_X(x ; \\alpha, \\mu, \\beta)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPI from adjusted CDF\n",
    "spi_reproduced = cdf_to_spi(cdf_adjusted)\n",
    "\n",
    "# Display result\n",
    "spi_reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "#### 3.6 SPI comparison: Time series in example site\n",
    "Having reproduced the SPI index from ERA5 precipitation data following the ERA5â€“Drought methodology,\n",
    "we can now compare the results to determine the reproducibility of ERA5â€“Drought.\n",
    "We first compare the datasets over time at the example site defined in [](section-general_setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "The previous sections set up the SPI reproduction pipeline for the entire ERA5 precipitation dataset (global, 1940â€“2024).\n",
    "Because actually executing said calculation takes a long time,\n",
    "as noted in the CDF subsection,\n",
    "here we sub-select the downloaded ERA5 precipitation data and calculate SPI for the example site only.\n",
    "For convenience, the full SPI pipeline is wrapped into a single `calculate_spi_from_era5` function,\n",
    "as defined in [](section-code_setup).\n",
    "\n",
    "Note that while the two may seem equivalent,\n",
    "downloading the ERA5 precipitation data for the example site only and then running the SPI pipeline,\n",
    "rather than downloading the entire dataset and subselecting for the example site,\n",
    "produces different results.\n",
    "This is likely caused by the inner workings of the MARS regridding function.\n",
    "For consistency with ERA5â€“Drought, it is necessary to download the global ERA5 dataset and subselect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Select only desired site\n",
    "data_era5_precipitation_site = data_era5_precipitation_preprocessed.sel(**example_site)\n",
    "\n",
    "# Calculate SPI\n",
    "spi_reproduced_site = calculate_spi_from_era5(data_era5_precipitation_site, reference_window=reference_window)\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spi_reproduced_site = spi_reproduced_site.persist()\n",
    "\n",
    "# Display result\n",
    "spi_reproduced_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "Next, we download the corresponding data from ERA5â€“Drought.\n",
    "Because of size limits on the CDS,\n",
    "the time series must be downloaded in parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Main request, based on template and example site\n",
    "request_era5drought_spi = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "} | request_era5drought_index | request_site\n",
    "\n",
    "# Split into batches of up to 20 years each\n",
    "subrequests_era5drought_spi = batch_requests(request_era5drought_spi, n=20)\n",
    "\n",
    "# Download data and load into xarray\n",
    "spi_era5drought_site = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, *subrequests_era5drought_spi)\n",
    "spi_era5drought_site = spi_era5drought_site.to_xarray(compat=\"equals\", join=\"outer\")\n",
    "spi_era5drought_site = spi_era5drought_site.chunk({\"time\": -1})  # Full time series in one chunk\n",
    "\n",
    "# Select only desired site (remove margins)\n",
    "spi_era5drought_site = spi_era5drought_site.sel(**example_site)\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spi_era5drought_site = spi_era5drought_site.persist()\n",
    "\n",
    "# Display result\n",
    "spi_era5drought_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "First, we examine the per-point difference in SPI between ERA5â€“Drought and the reproduction.\n",
    "This comparison is performed separately for each calendar month and each accumulation period\n",
    "to reflect the fitting process.\n",
    "We calculate the median difference _Î”_ and median absolute difference _|Î”|_,\n",
    "as well as the percentage of match-ups where _|Î”| â‰¥ 0.10_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPI median differences\n",
    "spi_difference_site = comparison_monthly_statistics(spi_era5drought_site, spi_reproduced_site)\n",
    "\n",
    "# Display with style\n",
    "display_monthly_statistics(spi_difference_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "It is clear from the table above that there is good agreement between the reproduced SPI values and those retrieved from ERA5â€“Drought.\n",
    "The median difference and median absolute difference are 0 for the vast majority of monthâ€“accumulation period pairs,\n",
    "and always â‰¤ 0.004.\n",
    "Similarly,\n",
    "the number of match-ups where the absolute difference is over our threshold of 0.10 is very small\n",
    "(â‰¤2.4%, corresponding to 1 or 2 match-ups for the 1940â€“2024 time span)\n",
    "or none at all.\n",
    "Differences between months and between accumulation periods are due to the fitting process being applied independently to each.\n",
    "There are no apparent patterns across the different accumulation periods,\n",
    "such as a particular month always being problematic,\n",
    "although these may be expected in other sites.\n",
    "\n",
    "Comparing the SPI time series\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries>`)\n",
    "shows that large differences occur only in isolated spikes,\n",
    "generally at extreme values of SPI (below â€“3 or above +3) where extreme deviations (e.g. from â€“5 to â€“8) are not meaningful [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "As such, these spikes do not cause a difference in SPI classifications\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion>`).\n",
    "The cause of these spikes is not clear,\n",
    "since the underpinning data are the same and the similarity along the rest of the time series suggests that the fitted distributions are also (near-)equal.\n",
    "\n",
    "In some cases,\n",
    "such as SPI-36 and SPI-48 in Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries>`,\n",
    "small regular differences are observed.\n",
    "These tend to be periodic per year,\n",
    "indicating that they correspond to individual calendar months.\n",
    "For example, the table above shows that SPI-48 is equal between the two datasets in all months except June and August.\n",
    "These differences are the result of small differences in the obtained fit parameters,\n",
    "which are likely caused by small differences in the fitting procedure and initial conditions.\n",
    "This is commonly seen in regression-based indicators and does not indicate a meaningful discrepancy in the reproducibility of ERA5â€“Drought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series comparison (absolute values and differences)\n",
    "plot_time_series_comparison_spi(spi_era5drought_site, spi_reproduced_site, title_suffix=f\" at {label_site}\",\n",
    "                                glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix comparison\n",
    "# e.g. are all \"extremely dry\" data in ERA5â€“Drought also \"extremely dry\" in the reproduction?\n",
    "plot_confusion_matrices_spi(spi_era5drought_site, spi_reproduced_site, title_suffix=f\" at {label_site}\",\n",
    "                            glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries\"\n",
    "\n",
    "SPI time series downloaded from ERA5â€“Drought and reproduced from ERA5 precipitation data (left) and the difference between the two (right), for the example site of Addis Ababa, Ethiopia.\n",
    "Colours in the left-hand column correspond to SPI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Confusion matrix\n",
    ":sync: confusion\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion\"\n",
    "\n",
    "Confusion matrices for SPI categories from ERA5â€“Drought vs. reproduced from ERA5, for the example site of Addis Ababa, Ethiopia, in 1940â€“2024.\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "#### 3.7 SPI comparison: Regional snapshot\n",
    "Next, we investigate spatial patterns in SPI and the difference therein across a wider region around the example site.\n",
    "This region is defined in [](section-general_setup).\n",
    "In this example, we look at part of the Horn of Africa using a box of 12Â° in all directions around Addis Ababa, Ethiopia.\n",
    "To reduce computing requirements, the comparison is performed for one year only,\n",
    "here 2024, again defined in [](section-general_setup).\n",
    "\n",
    "As in the time series comparison,\n",
    "we subselect the desired data from ERA5 and calculate the corresponding SPI\n",
    "and\n",
    "download SPI from ERA5â€“Drought for the desired region and time span:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Select only desired site\n",
    "data_era5_precipitation_region = data_era5_precipitation_preprocessed.sel(**example_region)\n",
    "\n",
    "# Window in which to evaluate SPI\n",
    "evaluation_window = {\"time\": slice(f\"{snapshot_year}-01-01\", f\"{snapshot_year}-12-01\")}  #  Slice (2024-01-01, 2024-12-01)\n",
    "\n",
    "# Calculate SPI\n",
    "spi_reproduced_region = calculate_spi_from_era5(data_era5_precipitation_region, reference_window=reference_window,\n",
    "                                                evaluation_window=evaluation_window)\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spi_reproduced_region = spi_reproduced_region.persist()\n",
    "\n",
    "# Display result\n",
    "spi_reproduced_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Main request, based on template and example region\n",
    "request_era5drought_spi = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "} | request_era5drought_index | request_region\n",
    "\n",
    "# Select only desired year\n",
    "request_era5drought_spi = request_era5drought_spi | {\"year\": [f\"{snapshot_year}\"],}\n",
    "\n",
    "# Download data and load into xarray\n",
    "spi_era5drought_region = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_era5drought_spi)\n",
    "spi_era5drought_region = spi_era5drought_region.to_xarray(compat=\"equals\", join=\"outer\")\n",
    "spi_era5drought_region = spi_era5drought_region.chunk({\"time\": -1})  # Full time series in one chunk\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spi_era5drought_region = spi_era5drought_region.persist()\n",
    "\n",
    "# Display result\n",
    "spi_era5drought_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "As before,\n",
    "we examine the per-point difference in SPI between ERA5â€“Drought and the reproduction for each calendar month and each accumulation period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPI median differences\n",
    "spi_difference_region = comparison_monthly_statistics(spi_era5drought_region, spi_reproduced_region)\n",
    "\n",
    "# Display with style\n",
    "display_monthly_statistics(spi_difference_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "As before, the differences between ERA5â€“Drought and reproduced SPI are small to zero in most cases.\n",
    "Notably, differences of more than 0.10 appear in a larger number of match-ups than before, specifically for SPI-1.\n",
    "The distribution of these discrepancies across the example region\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-geospatial>`)\n",
    "suggests that they again occur primarily where values of SPI are extremely high or low.\n",
    "This is corroborated by the confusion matrices\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion-region>`),\n",
    "although these show that a small number of pixels are classified differently in ERA5â€“Drought vs. the reproduced dataset.\n",
    "Mismatches occur almost exclusively between adjacent categories\n",
    "(e.g. \"moderately wet\" and \"severely wet\"),\n",
    "although there are individual outliers.\n",
    "\n",
    "Crucially,\n",
    "the discrepancies fall mostly in months in the local dry season [[Gebrechorkos+19](https://doi.org/10.1038/s41598-019-47933-8)].\n",
    "Hence,\n",
    "the precipitation time series\n",
    "â€“ particularly for the 1-month accumulation period â€“\n",
    "likely contains more months with zero or near-zero precipitation,\n",
    "making it more difficult to obtain a consistent fit.\n",
    "The authors of ERA5â€“Drought recommend flagging data in calendar months for which at least 3 months in the reference window had zero precipitation (_p{sub}`0`_ â‰¥ 0.10) [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)];\n",
    "this is explored in the next subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot geospatial comparison: SPI in one region\n",
    "plot_geospatial_comparison(spi_era5drought_region, spi_reproduced_region, var=\"SPI\", time=f\"{snapshot_year}-12-01\",\n",
    "                           domain=domain_region,\n",
    "                           glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-geospatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix comparison\n",
    "# e.g. are all \"extremely dry\" data in ERA5â€“Drought also \"extremely dry\" in the reproduction?\n",
    "plot_confusion_matrices_spi(spi_era5drought_region, spi_reproduced_region, title_suffix=f\" in {label_region}\",\n",
    "                            glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion-region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Geospatial\n",
    ":sync: geospatial\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-geospatial\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-geospatial\"\n",
    "\n",
    "SPI downloaded from ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference between the two (right), for the region around the example site of Addis Ababa, Ethiopia.\n",
    "Only one month (December 2024) is displayed.\n",
    "Colours correspond to SPI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Confusion matrix\n",
    ":sync: confusion\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion-region\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-confusion-region\"\n",
    "\n",
    "Confusion matrices for SPI categories from ERA5â€“Drought vs. reproduced from ERA5, across the region around the example site of Addis Ababa, Ethiopia.\n",
    "Combines data for all months within one year (2024).\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "#### 3.8 Quality flags: Probability of zero precipitation\n",
    "One of the quality flags included in ERA5â€“Drought is the probability of zero precipitation _p{sub}`0`_.\n",
    "This represents,\n",
    "for each calendar month and accumulation period,\n",
    "the fraction of months within the reference period (1991â€“2020) where precipitation was zero.\n",
    "While the ERA5â€“Drought implementation of SPI accounts for months with zero precipitation by shifting the CDF,\n",
    "as demonstrated above,\n",
    "those months do skew the fitted distribution and reduce the reliability of the index.\n",
    "In ERA5â€“Drought,\n",
    "the gamma distribution is not even fitted if at least 10 out of 30 months in the reference window have 0 precipitation,\n",
    "and the authors recommend that users filter out locations with a lower threshold, such as _p{sub}`0`_ > 0.1 [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "\n",
    "\n",
    "Unlike in the zero-precipitation correction that is part of the SPI calculation,\n",
    "this quality flag uses an unweighted probability, with _n{sub}`0`_ the number of months with zero precipitation and _n_ the total number of months in the reference window (30):\n",
    "\n",
    "$$\n",
    "p_0 = \\frac{n_0}{n + 1}\n",
    "$$\n",
    "\n",
    "In this subsection, we reproduce the _p{sub}`0`_ quality flag and its derived masks,\n",
    "and compare their values to those provided in ERA5â€“Drought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Accumulate total precipitation\n",
    "data_era5_precipitation = accumulate(data_era5_precipitation_preprocessed, \"tp\")\n",
    "\n",
    "# Select data in reference window\n",
    "data_era5_precipitation_reference = data_era5_precipitation.sel(**reference_window)\n",
    "\n",
    "# Calculate the probability of zero precipitation\n",
    "p_zero_reproduced = probability_of_zero_precipitation(data_era5_precipitation_reference)\n",
    "\n",
    "# Display result\n",
    "p_zero_reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The CDS provides ERA5â€“Drought's _p{sub}`0`_ flag for each accumulation period,\n",
    "but does not distinguish between them in the variable name.\n",
    "This means that _p{sub}`0`_ must be downloaded separately for each accumulation period, renamed, and merged together,\n",
    "rather than downloading it for all in one request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup: Request for each accumulation period\n",
    "request_p_zero = {\n",
    "    \"variable\": [\"probability_of_zero_precipitation_spi\"],\n",
    "} | request_era5drought_flag\n",
    "\n",
    "requests_per_accumulation_period = {period: {\"accumulation_period\": [str(period)],}\n",
    "                                    for period in ACCUMULATION_PERIODS}\n",
    "\n",
    "subrequests_era5drought_p_zero = {period: (req | request_p_zero)\n",
    "                                  for period, req in requests_per_accumulation_period.items()}\n",
    "\n",
    "# Download data in individual requests\n",
    "p_zero_era5drought = {period: ekd.from_source(\"cds\", ID_ERA5_DROUGHT, subreq)  # Download as field lists\n",
    "                      for period, subreq in subrequests_era5drought_p_zero.items()}\n",
    "\n",
    "# Pre-process: Convert to xarray, handle variable names, month dimension\n",
    "p_zero_era5drought = preprocess_era5drought_qualityflag(p_zero_era5drought, \"tp\")\n",
    "\n",
    "# Display in notebook\n",
    "p_zero_era5drought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "For both datasets, we create masks corresponding to\n",
    "the threshold for not fitting a gamma distribution (_p{sub}`0`_ > 0.33)\n",
    "and\n",
    "the recommended threshold for filtering data (_p{sub}`0`_ > 0.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Create masks from p_zero\n",
    "# True: below threshold, allowed\n",
    "# False: above threshold, flagged\n",
    "p_zero_reproduced_033  = (p_zero_reproduced  <= 0.33)\n",
    "p_zero_era5drought_033 = (p_zero_era5drought <= 0.33)\n",
    "\n",
    "p_zero_reproduced_010  = (p_zero_reproduced  <= 0.10)\n",
    "p_zero_era5drought_010 = (p_zero_era5drought <= 0.10)\n",
    "\n",
    "# Display result\n",
    "p_zero_era5drought_033"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "First,\n",
    "we quantitatively compare how often the values of _p{sub}`0`_ and the derived masks in ERA5â€“Drought and the reproduction match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package probability and masks into dictionary for table function; note use unicode symbols / HTML\n",
    "p_zero_flags = {r\"p<sub>0</sub> [%]\":        [p_zero_era5drought,     p_zero_reproduced],\n",
    "                r\"p<sub>0</sub> > 0.33 [%]\": [p_zero_era5drought_033, p_zero_reproduced_033],\n",
    "                r\"p<sub>0</sub> > 0.10 [%]\": [p_zero_era5drought_010, p_zero_reproduced_010],\n",
    "               }\n",
    "\n",
    "# Compare probabilities per variable\n",
    "compare_quality_flags(p_zero_flags, title_suffix=\" (global)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "It is immediately evident from the table above that there is excellent agreement,\n",
    "â‰¥99% in all cases and 100% in most.\n",
    "Since _p{sub}`0`_ is derived directly from the accumulated ERA5 total precipitation,\n",
    "without any intermediate fitting steps,\n",
    "the few discrepancies that do occur are likely caused by small differences in the data processing between ERA5â€“Drought and this notebook.\n",
    "Potential examples include\n",
    "the cut-off for zero precipitation (exactly 0 mm, 0.01 mm, or something else);\n",
    "if the cut-off is not exactly zero, whether it is applied to the total or average precipitation in the accumulation period;\n",
    "whether leap years are accounted for;\n",
    "and computational factors like floating-point accuracy.\n",
    "Given the level of agreement, it is safe to conclude that the _p{sub}`0`_ quality flag is reproducible.\n",
    "\n",
    "The global distribution of _p{sub}`0`_ in the 3-month accumulation period\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-global>`)\n",
    "shows that differences occur in isolated pixels,\n",
    "e.g. in Argentina, Ukraine, and Russia,\n",
    "rather than clusters.\n",
    "Many pixels in the example region\n",
    "(Horn of Africa)\n",
    "are flagged in one or more months\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-region>`)\n",
    "as discussed in the SPI comparison above,\n",
    "although the flagged pixels do not match one-to-one with the pixels that showed differences in SPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package probability and masks into dictionary for plotting function; note use of LaTeX instead of unicode/HTML symbols\n",
    "probabilities = {r\"$p_0$ (probability of zero precipitation)\": [p_zero_era5drought, p_zero_reproduced],\n",
    "                }\n",
    "masks = {r\"$p_0 > 0.33$\": [p_zero_era5drought_033, p_zero_reproduced_033],\n",
    "         r\"$p_0 > 0.10$\": [p_zero_era5drought_010, p_zero_reproduced_010],\n",
    "         }\n",
    "\n",
    "# Display quality flags â€“ this step may take a few minutes\n",
    "# Regional for tp1, for regional SPI comparison\n",
    "plot_geospatial_comparison_quality_flags(\"tp1\", example_month=12, probabilities=probabilities, masks=masks,\n",
    "                                         shared_mask=LAND, domain=domain_region, flag_label=r\"$p_0$\",\n",
    "                                         glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-region\")\n",
    "\n",
    "# Global for tp3 (comparable to SPEI3 Shapiroâ€“Wilk plot in Keune+25 Fig 3.\n",
    "plot_geospatial_comparison_quality_flags(\"tp3\", example_month=12, probabilities=probabilities, masks=masks,\n",
    "                                         shared_mask=LAND, flag_label=r\"$p_0$\",\n",
    "                                         glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Global, 3-month\n",
    ":sync: global\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-global\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-global\"\n",
    "\n",
    "Global probability of zero precipitation in the 3-month accumulation period and associated masks in ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference or mismatch between the two (right).\n",
    "Probability is displayed for one calendar month (December) across the reference window (1991â€“2020).\n",
    "Masks are displayed as the number of calendar months that get flagged and the oceans are masked,\n",
    "following [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] Fig. 3.\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Example region, 1-month\n",
    ":sync: geospatial\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-region\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-p0-region\"\n",
    "\n",
    "Probability of zero precipitation in the 1-month accumulation period and associated masks in ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference or mismatch between the two (right).\n",
    "Probability is displayed for one calendar month (December) across the reference window (1991â€“2020).\n",
    "Masks are displayed as the number of calendar months that get flagged and the oceans are masked,\n",
    "following [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] Fig. 3.\n",
    "This figure displays only the example region (Horn of Africa), for comparison with\n",
    "Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-geospatial>`.\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "#### 3.9 Quality flags: Shapiroâ€“Wilk normality test\n",
    "Another quality flag included in ERA5â€“Drought is the normality _Î±_,\n",
    "derived using the Shapiroâ€“Wilk test for normality [[Shapiro+65](https://doi.org/10.1093/biomet/52.3-4.591)].\n",
    "This _Î±_ quantifies how well the computed index values\n",
    "(SPI or SPEI)\n",
    "in the reference period\n",
    "(1991â€“2020)\n",
    "are described by a standard normal distribution.\n",
    "As such, _Î±_ is provided for each combination of calendar month and accumulation window,\n",
    "for each pixel.\n",
    "The authors of ERAâ€“Drought use a threshold of 0.05, meaning points where _Î±_ < 0.05 are rejected.\n",
    "\n",
    "In this subsection,\n",
    "we reproduce the _Î±_ quality flag and its derived mask,\n",
    "and compare their values to those provided in ERA5â€“Drought.\n",
    "Because this involves computing SPI,\n",
    "which is computationally expensive,\n",
    "the evaluation is performed over the example region\n",
    "(Horn of Africa)\n",
    "rather than globally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "First, we reproduce SPI across the desired region in the reference window and compute the corresponding Shapiroâ€“Wilk normalities and mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only desired site\n",
    "data_era5_precipitation_region = data_era5_precipitation_preprocessed.sel(**example_region)\n",
    "\n",
    "# Calculate SPI\n",
    "spi_reproduced_region = calculate_spi_from_era5(data_era5_precipitation_region, reference_window=reference_window,\n",
    "                                                evaluation_window=reference_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Apply Shapiroâ€“Wilk normality test\n",
    "normality_reproduced = shapiro_wilk_normality(spi_reproduced_region)\n",
    "\n",
    "# Create mask from normality p-values\n",
    "# True: above threshold, allowed\n",
    "# False: below threshold, flagged\n",
    "normality_reproduced_mask = (normality_reproduced >= 0.05)\n",
    "\n",
    "# Display result\n",
    "normality_reproduced_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The CDS provides ERA5â€“Drought's _Î±_ flag for each accumulation period,\n",
    "but does not distinguish between them in the variable name.\n",
    "This means that _Î±_ must be downloaded separately for each accumulation period, renamed, and merged together,\n",
    "rather than downloading it for all in one request.\n",
    "\n",
    "Note that unlike for the probability of zero precipitation,\n",
    "ERA5â€“Drought does not provide the value of _Î±_, only the corresponding boolean mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup: Request for each accumulation period\n",
    "request_normality = {\n",
    "    \"variable\": [\"test_for_normality_spi\"],\n",
    "} | request_region | request_era5drought_flag\n",
    "\n",
    "requests_per_accumulation_period = {period: {\"accumulation_period\": [str(period)],}\n",
    "                                    for period in ACCUMULATION_PERIODS}\n",
    "\n",
    "subrequests_era5drought_normality = {period: (req | request_normality)\n",
    "                                       for period, req in requests_per_accumulation_period.items()}\n",
    "\n",
    "# Download data in individual requests\n",
    "normality_era5drought_mask = {period: ekd.from_source(\"cds\", ID_ERA5_DROUGHT, subreq)  # Download as field lists\n",
    "                              for period, subreq in subrequests_era5drought_normality.items()}\n",
    "\n",
    "# Pre-process: Convert to xarray, handle variable names, month dimension\n",
    "normality_era5drought_mask = preprocess_era5drought_qualityflag(normality_era5drought_mask, \"SPI\")\n",
    "normality_era5drought_mask = normality_era5drought_mask.astype(bool)  # Convert to boolean array (values are only 0. or 1.)\n",
    "\n",
    "# Display in notebook\n",
    "normality_era5drought_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "First,\n",
    "we quantitatively compare how often the values of the normality mask desired from _Î±_ in ERA5â€“Drought and the reproduction match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package probability and masks into dictionary for table function; note use unicode symbols / HTML\n",
    "normality_flags = {\"Î± < 0.05 [%]\": [normality_reproduced_mask, normality_era5drought_mask],\n",
    "                  }\n",
    "\n",
    "# Compare probabilities per variable\n",
    "compare_quality_flags(normality_flags, title_suffix=f\" ({domain_region.name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "The table above shows perfect agreement for accumulation periods of 6 months and longer,\n",
    "and near-perfect agreement for SPI-3 normality\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi3>`).\n",
    "For SPI-1, there are more mismatches\n",
    "(**Final number**%).\n",
    "This mirrors the pattern from the SPI comparison above,\n",
    "where SPI-1 showed larger discrepancies than the longer accumulation periods,\n",
    "likely due to low- and zero-precipitation months making it more difficult to consistently find a good fit for the gamma distribution.\n",
    "Differences in the fitted distribution can logically lead to differences in the normality of said distribution.\n",
    "A geospatial comparison of SPI-1 normality\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi1>`)\n",
    "shows that at least one calendar month is flagged for most pixels,\n",
    "and differences are distributed across the area.\n",
    "Both of these patterns match the earlier suggestion that it is more difficult to fit a gamma distribution in drier months,\n",
    "in which case SPI values are less trustworthy\n",
    "â€“ meaning the normality flag is working as intended.\n",
    "\n",
    "In conclusion,\n",
    "the differences in the normality mask (_Î±_ < 0.05) seen above are likely caused by the differences in fitted distributions seen before,\n",
    "and thus do not affect the assessment of reproducibility.\n",
    "The mask provided with ERA5â€“Drought can be used confidently to mask corresponding SPI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package masks into dictionary for plotting function; note use of LaTeX instead of unicode/HTML symbols\n",
    "masks = {r\"$\\alpha < 0.05$\": [normality_era5drought_mask, normality_reproduced_mask],\n",
    "        }\n",
    "\n",
    "# Display quality flags â€“ this step may take a few minutes\n",
    "# SPI-1: Compare to table\n",
    "plot_geospatial_comparison_quality_flags(\"SPI1\", example_month=12, masks=masks,\n",
    "                                         shared_mask=LAND, domain=domain_region,\n",
    "                                         glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi1\")\n",
    "\n",
    "# SPI-3: Compare to Keune+25 Fig 3.\n",
    "plot_geospatial_comparison_quality_flags(\"SPI3\", example_month=12, masks=masks,\n",
    "                                         shared_mask=LAND, domain=domain_region,\n",
    "                                         glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} SPI-1\n",
    ":sync: geospatial\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi1\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi1\"\n",
    "\n",
    "Shapiroâ€“Wilk normality Î± for SPI-1 and associated masks in ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference or mismatch between the two (right).\n",
    "The _Î±_ < 0.05 mask is displayed as the number of calendar months that get flagged and the oceans are masked,\n",
    "following [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] Fig. 3.\n",
    "This figure displays only the example region (Horn of Africa).\n",
    "```\n",
    ":::\n",
    ":::{tab-item} SPI-3\n",
    ":sync: spi3\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi3\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-normality-region-spi3\"\n",
    "\n",
    "Shapiroâ€“Wilk normality Î± for SPI-3 and associated masks in ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference or mismatch between the two (right).\n",
    "The _Î±_ < 0.05 mask is displayed as the number of calendar months that get flagged and the oceans are masked,\n",
    "following [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] Fig. 3.\n",
    "This figure displays only the example region (Horn of Africa).\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-spei)=\n",
    "### 4. SPEI comparison\n",
    "The process of calculating SPEI is very similar to that for SPI, with three major differences:\n",
    "* SPEI is based on the water balance (precipitation and potential evaporation or evapotranspiration), rather than just precipitation.\n",
    "* SPEI is based on a log-logistic distribution, rather than a gamma distribution.\n",
    "* SPEI does not need to be adjusted for months with zero precipitation.\n",
    "\n",
    "As such, this section is structured similarly to [](section-spi) and can be run entirely independently, but some of the more detailed explanations from said section are left out for brevity this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "#### 4.1 Download monthly precipitation and potential evaporation data from ERA5\n",
    "First, the monthly-mean total precipitation (variable `228.128`) and evaporation (variable `251.228`) are downloaded from [_Complete ERA5 global atmospheric reanalysis_ (reanalysis-era5-complete)](https://doi.org/10.24381/cds.143582cf).\n",
    "More information about the format for these requests is available in the [MARS ERA5 catalogue](https://apps.ecmwf.int/data-catalogues/era5/?class=ea).\n",
    "\n",
    "When reproducing this notebook yourself, if you have previously run through [](section-spi) and have [caching](https://earthkit-data.readthedocs.io/en/latest/guide/caching.html) enabled in earthkit-data, the previously downloaded precipitation data will be re-used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_precipitation_moda = {\n",
    "    \"param\": \"228.128\",  # Variable: Total precipitation\n",
    "    \"stream\": \"moda\",    # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template\n",
    "\n",
    "request_era5_pev_moda = {\n",
    "    \"param\": \"251.228\",  # Variable: Potential evaporation\n",
    "    \"stream\": \"moda\",    # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and load into xarray\n",
    "data_era5_waterbalance_cds = ekd.from_source(\"cds\", ID_ERA5, request_era5_precipitation_moda, request_era5_pev_moda)  # Download as field list\n",
    "data_era5_waterbalance_cds = data_era5_waterbalance_cds.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "\n",
    "# Pre-process to desired format\n",
    "# Note the change in variable name\n",
    "data_era5_waterbalance_preprocessed = preprocess_era5(data_era5_waterbalance_cds)\n",
    "\n",
    "# Display in notebook\n",
    "data_era5_waterbalance_preprocessed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "142",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate water balance over accumulation periods\n",
    "The water balance represents the net gain or loss of water in an area due to precipitation (gain) and evaporation (loss).\n",
    "[ECMWF's convention](https://codes.ecmwf.int/grib/param-db/182), as used in ERA5, is that downward fluxes are positive and upward fluxes are negative.\n",
    "This means that\n",
    "total precipitation is always positive (or zero),\n",
    "potential evaporation is always negative (or zero),\n",
    "and the water balance is simply the sum of the two: _WB = TP + PEV_.\n",
    "\n",
    "Here, we calculate the water balance per point in the downloaded ERA5 data and accumulate it over the same periods as before (1, 3, 6, 12, 24, 36, and 48 months).\n",
    "\n",
    "The resulting accumulated time series for the example site defined in [](section-general_setup),\n",
    "Addis Ababa in Ethiopia in our example,\n",
    "are displayed in Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-wb-accumulated>`.\n",
    "This example clearly demonstrates how the water balance moves between positive and negative\n",
    "(net gain vs. net loss)\n",
    "and how this changes depending on the accumulation period.\n",
    "For example,\n",
    "the shortest accumulation periods\n",
    "(1â€“6 months)\n",
    "swing up and down seasonally,\n",
    "but the longer-term (e.g. 48-month) accumulated water balance tends to be negative except in specific periods (e.g. the mid-1960s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate water balance\n",
    "data_era5_waterbalance = calculate_waterbalance(data_era5_waterbalance_preprocessed)\n",
    "\n",
    "# Accumulate water balance\n",
    "data_era5_waterbalance = accumulate(data_era5_waterbalance, \"wb\")\n",
    "\n",
    "# Display result\n",
    "data_era5_waterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display accumulated precipitation at example site\n",
    "plot_accumulated_waterbalance(data_era5_waterbalance, example_site,\n",
    "                              glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-wb-accumulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-wb-accumulated\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-wb-accumulated\"\n",
    "\n",
    "Water balance from ERA5 accumulated over different accumulation periods, for the example site of Addis Ababa, Ethiopia.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "#### 4.3 Fit log-logistic distribution and compute SPEI\n",
    "While SPI assumes a gamma distribution for total precipitation,\n",
    "this assumption does not hold for the water balance.\n",
    "For SPEI,\n",
    "various distributions are used in the literature [[Stagge+15](https://doi.org/10.1002/joc.4267)].\n",
    "While [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] specifies that ERA5â€“Drought's SPEI is based on the generalised log-logistic distribution,\n",
    "following [[Vicente-Serrano+10](https://doi.org/10.1175/2009JCLI2909.1)],\n",
    "private communication with the authors indicates that a generalised logistic distribution is used instead.\n",
    "\n",
    "As before, the distribution is fitted to data in the reference window (1991â€“2020 by default),\n",
    "Here, we use\n",
    "[scipy.stats.genlogistic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genlogistic.html)\n",
    "to fit the generalised logistic distribution.\n",
    "This returns three parameters for each calendar month and accumulation period, namely\n",
    "shape (_c_), location (_Î¼_), and scale (_Î²_).\n",
    "\n",
    "The observed (accumulated) water balance values along the entire time series\n",
    "are then compared to the fitted parameters in terms of where they fall on the cumulative distribution function (CDF).\n",
    "From these CDF values,\n",
    "SPEI values\n",
    "for each data point (latitude, longitude, time)\n",
    "are calculated by transforming to a standard normal distribution.\n",
    "The zero-precipitation correction from [](section-spi) is not relevant to SPEI.\n",
    "\n",
    "Note that actually evaluating the CDF\n",
    "â€“ as opposed to [queueing it up in dask](https://docs.xarray.dev/en/stable/user-guide/dask.html), as done here â€“\n",
    "can be slow, especially for a large dataset like global ERA5 precipitation and evaporation.\n",
    "As such, if you are interested in a subset of the data,\n",
    "such as a specific site or period in time,\n",
    "it may be best to subset your data _before_ calculating the CDF rather than afterwards.\n",
    "An example of this is provided below in the comparison with ERA5â€“Drought SPEI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Select data in reference window\n",
    "data_era5_waterbalance_reference = data_era5_waterbalance.sel(**reference_window)\n",
    "\n",
    "# Fit generalised logistic distribution\n",
    "spei_parameters = fit_monthly_spei(data_era5_waterbalance_reference)\n",
    "\n",
    "# Compute CDF time series\n",
    "cdf = compute_cdf_spei(data_era5_waterbalance, spei_parameters)\n",
    "\n",
    "# Calculate SPI from adjusted CDF\n",
    "spei_reproduced = cdf_to_spei(cdf)\n",
    "\n",
    "# Display result\n",
    "spei_reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "#### 4.4 SPEI comparison: Time series in example site\n",
    "Having reproduced the SPEI index from ERA5 precipitation and potential evaporation data following the ERA5â€“Drought methodology,\n",
    "we can now compare the results to determine the reproducibility of ERA5â€“Drought.\n",
    "We first compare the datasets over time at the example site defined in [](section-general_setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149",
   "metadata": {},
   "source": [
    "As before,\n",
    "because the global calculation set up in the previous subsections can take a long time to execute,\n",
    "here we sub-select the downloaded ERA5 data and calculate SPEI for the example site only.\n",
    "For convenience, the full SPEI pipeline is wrapped into a single `calculate_spei_from_era5` function,\n",
    "as defined in [](section-code_setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Select only desired site\n",
    "data_era5_waterbalance_site = data_era5_waterbalance_preprocessed.sel(**example_site)\n",
    "\n",
    "# Calculate SPI\n",
    "spei_reproduced_site = calculate_spei_from_era5(data_era5_waterbalance_site, reference_window=reference_window)\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spei_reproduced_site = spei_reproduced_site.persist()\n",
    "\n",
    "# Display result\n",
    "spei_reproduced_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151",
   "metadata": {},
   "source": [
    "Next, we download the corresponding data from ERA5â€“Drought.\n",
    "Because of size limits on the CDS,\n",
    "the time series must be downloaded in parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Main request, based on template and example site\n",
    "request_era5drought_spei = {\n",
    "    \"variable\": [\"standardised_precipitation_evapotranspiration_index\"],\n",
    "} | request_era5drought_index | request_site\n",
    "\n",
    "# Split into batches of up to 20 years each\n",
    "subrequests_era5drought_spei = batch_requests(request_era5drought_spei, n=20)\n",
    "\n",
    "# Download data and load into xarray\n",
    "spei_era5drought_site = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, *subrequests_era5drought_spei)\n",
    "spei_era5drought_site = spei_era5drought_site.to_xarray(compat=\"equals\", join=\"outer\")\n",
    "spei_era5drought_site = spei_era5drought_site.chunk({\"time\": -1})  # Full time series in one chunk\n",
    "\n",
    "# Select only desired site (remove margins)\n",
    "spei_era5drought_site = spei_era5drought_site.sel(**example_site)\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spei_era5drought_site = spei_era5drought_site.persist()\n",
    "\n",
    "# Display result\n",
    "spei_era5drought_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153",
   "metadata": {},
   "source": [
    "Again, we examine the per-point difference in SPEI between ERA5â€“Drought and the reproduction for each calendar month and each accumulation period.\n",
    "We calculate the median difference _Î”_ and median absolute difference _|Î”|_,\n",
    "as well as the percentage of match-ups where _|Î”| â‰¥ 0.10_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPEI median differences\n",
    "spei_difference_site = comparison_monthly_statistics(spei_era5drought_site, spei_reproduced_site)\n",
    "\n",
    "# Display with style\n",
    "display_monthly_statistics(spei_difference_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "On first glance, the agreement in SPEI is considerably worse than in SPI.\n",
    "This shows in non-zero median and median absolute differences for most calendar monthâ€“accumulation period pairs,\n",
    "as well as larger percentages of match-ups that exceed the threshold of 0.10 difference.\n",
    "These patterns are visible in the time series comparison\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries>`)\n",
    "in the form of noticeable scatter about the 0-line,\n",
    "in addition to a few spikes like those seen in\n",
    "Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries>`.\n",
    "\n",
    "However,\n",
    "agreement is still excellent in general,\n",
    "and the discrepancies seen above rarely lead to differences in classification\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion>`).\n",
    "\n",
    "The most likely cause for the increased difference is the generalised logistic distribution.\n",
    "As noted above,\n",
    "it is not entirely clear which distribution underpins ERA5â€“Drought's SPEI values,\n",
    "and it is therefore entirely possible that the\n",
    "[scipy.stats.genlogistic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genlogistic.html)\n",
    "implementation used in this notebook is (slightly) different.\n",
    "For example,\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Generalized_logistic_distribution)\n",
    "lists four different _generalised logistic_ distributions.\n",
    "If the distribution used in ERA5â€“Drought is not equal to, but similar to, the implementation used in this notebook,\n",
    "that may well result in consistent, small differences in the exact values but good agreement overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series comparison (absolute values and differences)\n",
    "plot_time_series_comparison_spei(spei_era5drought_site, spei_reproduced_site, title_suffix=f\" at {label_site}\",\n",
    "                                 glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix comparison\n",
    "# e.g. are all \"extremely dry\" data in ERA5â€“Drought also \"extremely dry\" in the reproduction?\n",
    "plot_confusion_matrices_spei(spei_era5drought_site, spei_reproduced_site, title_suffix=f\" at {label_site}\",\n",
    "                             glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    "SPEI time series downloaded from ERA5â€“Drought and reproduced from ERA5 precipitation data (left) and the difference between the two (right), for the example site of Addis Ababa, Ethiopia.\n",
    "Colours in the left-hand column correspond to SPEI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Confusion matrix\n",
    ":sync: confusion\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion\"\n",
    "\n",
    "Confusion matrices for SPEI categories from ERA5â€“Drought vs. reproduced from ERA5, for the example site of Addis Ababa, Ethiopia, in 1940â€“2024.\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {},
   "source": [
    "#### 4.5 SPEI comparison: Regional snapshot\n",
    "Next, we investigate spatial patterns in SPEI and the difference therein across a wider region around the example site.\n",
    "This region is defined in [](section-general_setup).\n",
    "In this example, we look at part of the Horn of Africa using a box of 12Â° in all directions around Addis Ababa, Ethiopia.\n",
    "To reduce computing requirements, the comparison is performed for one year only,\n",
    "here 2024, again defined in [](section-general_setup).\n",
    "\n",
    "As in the time series comparison,\n",
    "we subselect the desired data from ERA5 and calculate the corresponding SPEI\n",
    "and\n",
    "download SPEI from ERA5â€“Drought for the desired region and time span:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Select only desired site\n",
    "data_era5_waterbalance_region = data_era5_waterbalance_preprocessed.sel(**example_region)\n",
    "\n",
    "# Window in which to evaluate SPI\n",
    "evaluation_window = {\"time\": slice(f\"{snapshot_year}-01-01\", f\"{snapshot_year}-12-01\")}  #  Slice (2024-01-01, 2024-12-01)\n",
    "\n",
    "# Calculate SPI\n",
    "spei_reproduced_region = calculate_spei_from_era5(data_era5_waterbalance_region, reference_window=reference_window,\n",
    "                                                  evaluation_window=evaluation_window)\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spei_reproduced_region = spei_reproduced_region.persist()\n",
    "\n",
    "# Display result\n",
    "spei_reproduced_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Main request, based on template and example region\n",
    "request_era5drought_spei = {\n",
    "    \"variable\": [\"standardised_precipitation_evapotranspiration_index\"],\n",
    "} | request_era5drought_index | request_region\n",
    "\n",
    "# Select only desired year\n",
    "request_era5drought_spei = request_era5drought_spei | {\"year\": [f\"{snapshot_year}\"],}\n",
    "\n",
    "# Download data and load into xarray\n",
    "spei_era5drought_region = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, request_era5drought_spei)\n",
    "spei_era5drought_region = spei_era5drought_region.to_xarray(compat=\"equals\", join=\"outer\")\n",
    "spei_era5drought_region = spei_era5drought_region.chunk({\"time\": -1})  # Full time series in one chunk\n",
    "\n",
    "# Persist in memory to speed up analysis â€“ this step may take a few minutes\n",
    "spei_era5drought_region = spei_era5drought_region.persist()\n",
    "\n",
    "# Display result\n",
    "spei_era5drought_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162",
   "metadata": {},
   "source": [
    "As before,\n",
    "we examine the per-point difference in SPI between ERA5â€“Drought and the reproduction for each calendar month and each accumulation period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPEI median differences\n",
    "spei_difference_region = comparison_monthly_statistics(spei_era5drought_region, spei_reproduced_region)\n",
    "\n",
    "# Display with style\n",
    "display_monthly_statistics(spei_difference_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "The regional comparison between ERA5â€“Drought and reproduced SPEI largely shows the same patterns as the time series comparison.\n",
    "Across most calendar months and accumulation periods,\n",
    "the differences are bigger than for SPI,\n",
    "but agreement remains good in general.\n",
    "The spatial distribution\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-geospatial>`)\n",
    "shows some patterns\n",
    "(e.g. pixels that have a similar offset in multiple accumulation periods)\n",
    "but appears mostly random.\n",
    "As a result of the bigger differences in SPEI,\n",
    "there are more pixels where the classification in SPEI differs between ERA5â€“Drought and the reproduction\n",
    "(Figure {numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion-region>`)\n",
    "than for SPI,\n",
    "particularly for wet categories and at â‰¥6-month accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_geospatial_comparison(spei_era5drought_region, spei_reproduced_region, var=\"SPEI\", time=f\"{snapshot_year}-12-01\",\n",
    "                           domain=domain_region,\n",
    "                           glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-geospatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix comparison\n",
    "# e.g. are all \"extremely dry\" data in ERA5â€“Drought also \"extremely dry\" in the reproduction?\n",
    "plot_confusion_matrices_spei(spei_era5drought_region, spei_reproduced_region, title_suffix=f\" in {label_region}\",\n",
    "                             glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion-region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Geospatial\n",
    ":sync: geospatial\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-geospatial\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-geospatial\"\n",
    "\n",
    "SPEI downloaded from ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference between the two (right), for the region around the example site of Addis Ababa, Ethiopia.\n",
    "Only one month (December 2024) is displayed.\n",
    "Colours correspond to SPEI categories (e.g. \"extremely dry\") in [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)].\n",
    "```\n",
    ":::\n",
    ":::{tab-item} Confusion matrix\n",
    ":sync: confusion\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion-region\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-confusion-region\"\n",
    "\n",
    "Confusion matrices for SPEI categories from ERA5â€“Drought vs. reproduced from ERA5, across the region around the example site of Addis Ababa, Ethiopia.\n",
    "Combines data for all months within one year (2024).\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168",
   "metadata": {},
   "source": [
    "#### 4.6 Quality flags: Shapiroâ€“Wilk normality test\n",
    "ERA5â€“Drought includes one quality flag for SPEI, namely the normality _Î±_,\n",
    "derived using the Shapiroâ€“Wilk test for normality [[Shapiro+65](https://doi.org/10.1093/biomet/52.3-4.591)].\n",
    "This _Î±_ quantifies how well the computed index values\n",
    "in the reference period\n",
    "(1991â€“2020)\n",
    "are described by a standard normal distribution.\n",
    "As such, _Î±_ is provided for each combination of calendar month and accumulation window,\n",
    "for each pixel.\n",
    "The authors of ERAâ€“Drought use a threshold of 0.05, meaning points where _Î±_ < 0.05 are rejected.\n",
    "\n",
    "In this subsection,\n",
    "we reproduce the _Î±_ quality flag and its derived mask,\n",
    "and compare their values to those provided in ERA5â€“Drought.\n",
    "Because this involves computing SPI,\n",
    "which is computationally expensive,\n",
    "the evaluation is performed over the example region\n",
    "(Horn of Africa)\n",
    "rather than globally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169",
   "metadata": {},
   "source": [
    "First, we reproduce SPEI across the desired region in the reference window and compute the corresponding Shapiroâ€“Wilk normalities and mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only desired site\n",
    "data_era5_waterbalance_region = data_era5_waterbalance_preprocessed.sel(**example_region)\n",
    "\n",
    "# Calculate SPEI\n",
    "spei_reproduced_region = calculate_spei_from_era5(data_era5_waterbalance_region, reference_window=reference_window,\n",
    "                                                  evaluation_window=reference_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Apply Shapiroâ€“Wilk normality test\n",
    "normality_reproduced = shapiro_wilk_normality(spei_reproduced_region)\n",
    "\n",
    "# Create mask from normality p-values\n",
    "# True: above threshold, allowed\n",
    "# False: below threshold, flagged\n",
    "normality_reproduced_mask = (normality_reproduced >= 0.05)\n",
    "\n",
    "# Display result\n",
    "normality_reproduced_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The CDS provides ERA5â€“Drought's _Î±_ flag for each accumulation period,\n",
    "but does not distinguish between them in the variable name.\n",
    "This means that _Î±_ must be downloaded separately for each accumulation period, renamed, and merged together,\n",
    "rather than downloading it for all in one request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup: Request for each accumulation period\n",
    "request_normality = {\n",
    "    \"variable\": [\"test_for_normality_spei\"],\n",
    "} | request_region | request_era5drought_flag\n",
    "\n",
    "requests_per_accumulation_period = {period: {\"accumulation_period\": [str(period)],}\n",
    "                                    for period in ACCUMULATION_PERIODS}\n",
    "\n",
    "subrequests_era5drought_normality = {period: (req | request_normality)\n",
    "                                       for period, req in requests_per_accumulation_period.items()}\n",
    "\n",
    "# Download data in individual requests\n",
    "normality_era5drought_mask = {period: ekd.from_source(\"cds\", ID_ERA5_DROUGHT, subreq)  # Download as field lists\n",
    "                              for period, subreq in subrequests_era5drought_normality.items()}\n",
    "\n",
    "# Pre-process: Convert to xarray, handle variable names, month dimension\n",
    "normality_era5drought_mask = preprocess_era5drought_qualityflag(normality_era5drought_mask, \"SPEI\")\n",
    "normality_era5drought_mask = normality_era5drought_mask.astype(bool)  # Convert to boolean array (values are only 0. or 1.)\n",
    "\n",
    "# Display in notebook\n",
    "normality_era5drought_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174",
   "metadata": {},
   "source": [
    "First,\n",
    "we quantitatively compare how often the values of the normality mask desired from _Î±_ in ERA5â€“Drought and the reproduction match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package probability and masks into dictionary for table function; note use unicode symbols / HTML\n",
    "normality_flags = {\"Î± < 0.05 [%]\": [normality_reproduced_mask, normality_era5drought_mask],\n",
    "                  }\n",
    "        \n",
    "# Compare probabilities per variable\n",
    "compare_quality_flags(normality_flags, title_suffix=f\" ({domain_region.name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176",
   "metadata": {},
   "source": [
    "Agreement between the normality quality flags provided in ERA5â€“Drought and those reproduced in this notebook is excellent (â‰¥98% **Final number** matching).\n",
    "In fact, agreement for SPEI-1 is noticeably better than for SPI-1 (**Final number** vs. **Final number**),\n",
    "despite the agreement in the index itself being worse.\n",
    "This excellent agreement is clearly visible in the geospatial distributions\n",
    "(Figures\n",
    "{numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei1>`\n",
    "and\n",
    "{numref}`{number} <indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei1>`),\n",
    "with differences seemingly randomly distributed.\n",
    "\n",
    "This result shows that while the fitted distributions themselves may differ between ERA5â€“Drought and the reproduction,\n",
    "they tend to either both pass or both fail the normality test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Package masks into dictionary for plotting function; note use of LaTeX instead of unicode/HTML symbols\n",
    "masks = {r\"$\\alpha < 0.05$\": [normality_era5drought_mask, normality_reproduced_mask],\n",
    "        }\n",
    "\n",
    "# Display quality flags â€“ this step may take a few minutes\n",
    "# SPI-1: Compare to table\n",
    "plot_geospatial_comparison_quality_flags(\"SPEI1\", example_month=12, masks=masks,\n",
    "                                         shared_mask=LAND, domain=domain_region,\n",
    "                                         glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei1\")\n",
    "\n",
    "# SPI-3: Compare to Keune+25 Fig 3.\n",
    "plot_geospatial_comparison_quality_flags(\"SPEI3\", example_month=12, masks=masks,\n",
    "                                         shared_mask=LAND, domain=domain_region,\n",
    "                                         glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} SPEI-1\n",
    ":sync: geospatial\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei1\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei1\"\n",
    "\n",
    "Shapiroâ€“Wilk normality _Î±_ for SPEI-1 and associated masks in ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference or mismatch between the two (right).\n",
    "The _Î±_ < 0.05 mask is displayed as the number of calendar months that get flagged and the oceans are masked,\n",
    "following [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] Fig. 3.\n",
    "This figure displays only the example region (Horn of Africa).\n",
    "```\n",
    ":::\n",
    ":::{tab-item} SPEI-3\n",
    ":sync: spi3\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei3\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-normality-region-spei3\"\n",
    "\n",
    "Shapiroâ€“Wilk normality _Î±_ for SPEI-3 and associated masks in ERA5â€“Drought (left) vs. reproduced from ERA5 precipitation data (middle) and the difference or mismatch between the two (right).\n",
    "The _Î±_ < 0.05 mask is displayed as the number of calendar months that get flagged and the oceans are masked,\n",
    "following [[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] Fig. 3.\n",
    "This figure displays only the example region (Horn of Africa).\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179",
   "metadata": {},
   "source": [
    "#### 4.7 Comparison of ERA5â€“Drought & Reproduced SPEI-index with quality flags (Addis Ababa, Ethiopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_ds_addis_masked = apply_sw_quality_mask(era5_quality_spei_addis, spei_ds.sel(sites=0), \"SPEI\")\n",
    "era5_masked = apply_sw_quality_mask(era5_quality_spei_addis, spei_addis_point, \"SPEI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_index_comparison_side_by_side(\"SPEI\", era5_masked, spei_ds_addis_masked, spei_categories) # takes a while"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182",
   "metadata": {},
   "source": [
    "**TODO point-to-make**: make comparison with quality flags- perhaps look at a location where there are more failed months? Otherwise, get rid since only 1 month fails SW test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.245188,
     "end_time": "2024-03-08T17:39:21.277354",
     "exception": false,
     "start_time": "2024-03-08T17:39:21.032166",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-ensemble)=\n",
    "### 5. Ensemble comparison\n",
    "One of the key strengths of ERA5â€“Drought is its inclusion of 10 ensemble members,\n",
    "propagated from ERA5,\n",
    "which can be used to probe\n",
    "(part of)\n",
    "the uncertainty in SPI and SPEI values.\n",
    "\n",
    "Here, we briefly demonstrate the reproducibility of the ERA5â€“Drought ensemble from the corresponding ERA5 ensemble members.\n",
    "To avoid repetition with the previous sections\n",
    "and\n",
    "reduce computational cost\n",
    "â€“ since the ensemble dataset is 10Ã— the size of the reanalysis â€“\n",
    "this section focuses on the case study of\n",
    "SPI and SPEI in one site.\n",
    "If you are keen to investigate the reproducibility of the ERA5â€“Drought ensemble more,\n",
    "the code provided in this notebook can easily be re-used to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184",
   "metadata": {},
   "source": [
    "#### 5.1 Compute SPI and SPEI from ERA5 ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185",
   "metadata": {},
   "source": [
    "As before,\n",
    "precipitation and potential evaporation are downloaded from\n",
    "the [_Complete ERA5 global atmospheric reanalysis_](https://doi.org/10.24381/cds.143582cf) dataset,\n",
    "but this time using the `edmo` (monthly ensemble) stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_precipitation_edmo = {\n",
    "    \"param\": \"228.128\",       # Variable: Total precipitation\n",
    "    \"stream\": \"edmo\",         # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template\n",
    "\n",
    "request_era5_evaporation_edmo = {\n",
    "    \"param\": \"251.228\", # Variable: Total potential evaporation.\n",
    "    \"stream\": \"edmo\",  # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and load into xarray\n",
    "data_era5_ens_waterbalance_cds = ekd.from_source(\"cds\", ID_ERA5, request_era5_precipitation_edmo,\n",
    "                                                 request_era5_evaporation_edmo)  # Download as field list\n",
    "\n",
    "data_era5_ens_waterbalance_cds = data_era5_ens_waterbalance_cds.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "\n",
    "# # Pre-process to desired format\n",
    "# # Note the change in variable name\n",
    "data_era5_ens_waterbalance_preprocessed = preprocess_era5(data_era5_ens_waterbalance_cds)\n",
    "\n",
    "# # Display in notebook, both \"tp\" and \"pev\".\n",
    "data_era5_ens_waterbalance_preprocessed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188",
   "metadata": {},
   "source": [
    "Use the `calculate_spi_from_era5` & `calculate_spei_from_era5` function for ensemble data.\n",
    "Precipitation and potential evaporation is accumulated for all the accumulation periods in ERA5 per ensemble member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the precipitation grid point and time slice for Ethiopia\n",
    "precipitation_ens_example_site = data_era5_ens_waterbalance_preprocessed.sel(**example_site)\n",
    "\n",
    "# Calculate SPI for grid point and time slice in Ethiopia\n",
    "spi_reproduced_site = calculate_spi_from_era5(precipitation_ens_example_site, reference_window=reference_window)\n",
    "\n",
    "# Calculate SPEI for grid point and time slice in Ethiopia\n",
    "spei_reproduced_site = calculate_spei_from_era5(precipitation_ens_example_site, reference_window=reference_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190",
   "metadata": {},
   "source": [
    "#### 5.2 Download SPI and SPEI ensembles from ERA5â€“Drought\n",
    "Next, we download the SPI and SPEI ensemble data from ERA5â€“Drought.\n",
    "Unlike in ERA5,\n",
    "the ensemble is not represented through a separate `number` dimension,\n",
    "but instead using 10-duplicate entries in the `time` dimension.\n",
    "To simplify the analysis,\n",
    "we restructure the downloaded dataset to match ERA5's setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main request, based on template and example site\n",
    "request_ens_era5drought_spi = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "} | request_ens_era5drought_index | request_site\n",
    "\n",
    "request_ens_era5drought_spei = {\n",
    "    \"variable\": [\"standardised_precipitation_evapotranspiration_index\"],\n",
    "} | request_ens_era5drought_index | request_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into batches per accumulation period\n",
    "subrequests_ens_era5drought_spi = batch_requests(request_ens_era5drought_spi, batch_key = \"accumulation_period\", n=1)\n",
    "subrequests_ens_era5drought_spei = batch_requests(request_ens_era5drought_spei, batch_key = \"accumulation_period\", n=1)\n",
    "\n",
    "# # Download SPI data and load into xarray\n",
    "spi_ens_era5drought_site = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, *subrequests_ens_era5drought_spi)\n",
    "spi_ens_era5drought_site = ens_drought_request(spi_ens_era5drought_site) # deduplicate timestamps, combine all accumulation periods.\n",
    "\n",
    "# # # Download SPEI data and load into xarray\n",
    "spei_ens_era5drought_site = ekd.from_source(\"cds\", ID_ERA5_DROUGHT, *subrequests_ens_era5drought_spei)\n",
    "spei_ens_era5drought_site = ens_drought_request(spei_ens_era5drought_site) # deduplicate timestamps, combine all accumulation periods.\n",
    "\n",
    "# # # Select only desired site (remove margins)\n",
    "spi_ens_era5drought_site = spi_ens_era5drought_site.sel(**example_site)\n",
    "spei_ens_era5drought_site = spei_ens_era5drought_site.sel(**example_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193",
   "metadata": {},
   "source": [
    "#### 5.3 Ensemble comparison: Time series in example site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPI median differences \n",
    "# TODO: Show for one member, then calculate for all members combined.\n",
    "spi_difference_site = comparison_monthly_statistics(spi_ens_era5drought_site, spi_reproduced_site)\n",
    "display_monthly_statistics(spi_difference_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SPI median differences\n",
    "spi_difference_site = comparison_monthly_statistics(spi_ens_era5drought_site, spi_reproduced_site)\n",
    "display_monthly_statistics(spi_difference_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_difference_site = comparison_monthly_statistics(spei_ens_era5drought_site, spei_reproduced_site)\n",
    "display_monthly_statistics(spei_difference_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(0, 10):  #### patch this code so titles show which plot is which ensemble member. is obvious but for full thing?\n",
    "    plot_time_series_comparison_spi(spi_ens_era5drought_site.sel(number=m), spi_reproduced_site.sel(number=m), title_suffix=f\" at {label_site}\",\n",
    "                                glue_label=f\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spi-timeseries_ens_{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_0\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_1\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_2\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_3\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_4\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_5\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_6\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_7\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_8\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_9\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series comparison (absolute values and differences)\n",
    "for m in range(0, 10):  #### patch this code so titles show which plot is which ensemble member. is obvious but for full thing?\n",
    "    plot_time_series_comparison_spei(spei_era5drought_site, spei_reproduced_site, title_suffix=f\" at {label_site}\",\n",
    "                                     glue_label=\"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_0\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_1\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_2\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_3\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\"\n",
    "\n",
    ":::{tab-item} Time series\n",
    ":sync: timeseries\n",
    "```{glue:figure} indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries_ens_4\n",
    ":name: \"indicator_derived-drought-historical-monthly_consistency_q01_fig-spei-timeseries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201",
   "metadata": {},
   "source": [
    "**TODO point-to-make**: each member from the drought-index ensemble is in fact reproduceable from each member from the precipitation / potential evaporation ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "(section-conclusion)=\n",
    "### 6. Conclusions\n",
    "**SPI**- As shown in Sectionâ€¯2, the C3S ERA5 Drought SPIâ€‘Indicator dataset and its manually reproduced counterpart are highly consistent. This agreement is evident across the full time series at a point location in Addis Ababa, Ethiopia, as well as regionally over the Horn of Africa. The median difference and median absolute difference are both close to 0, and the vast majority of pixels exhibit a nearâ€‘zero difference (defined here as |Î”| â‰¤ Îµ with Îµ = 1Ã—10â»âµ to avoid floatingâ€‘point artefacts) across all comparisons.\n",
    "\n",
    "Furthermore, the \"probability of zero precipitation\" quality flag was also shown to be reproducible, globally, with no discrepancy. Since the Shapiro-Wilks quality flag is dependent on the dataset after statistical fitting, there was discrepancy at certain months, for Addis Ababa, and other locations...\n",
    "\n",
    "We also examined discrepancies in droughtâ€‘severity categorisation between the C3S ERA5â€‘Drought dataset and the manually reproduced counterpart at individual locations, including Addis Ababa, London, and Denver. While the severity classifications were generally consistent between ERA5â€‘Drought and the reproduced dataset, there were instances at specific timestamps where the two SPI indicators diverged sufficiently to fall into different categories.\n",
    "\n",
    "Overall, \n",
    "\n",
    "**SPEI**- Following on from Section 3, \n",
    "\n",
    "**SPI/SPEI Ensemble**- Lastly, as was shown in Section 4, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## â„¹ï¸ If you want to know more\n",
    "\n",
    "### Key resources\n",
    "The CDS catalogue entries for the data used were:\n",
    "* Complete ERA5 global atmospheric reanalysis: [reanalysis-era5-complete](https://doi.org/10.24381/cds.143582cf)\n",
    "* ERA5 hourly data on single levels from 1940 to present: [reanalysis-era5-single-levels](https://doi.org/10.24381/cds.adbb2d47)\n",
    "* Monthly drought indices from 1940 to present derived from ERA5 reanalysis: [derived-drought-historical-monthly](https://doi.org/10.24381/9bea5e16)\n",
    "\n",
    "Code libraries used:\n",
    "* [earthkit](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-data](https://github.com/ecmwf/earthkit-data)\n",
    "  * [earthkit-plots](https://github.com/ecmwf/earthkit-plots)\n",
    "    \n",
    "### References\n",
    "\n",
    "[[ECIU+25](https://eciu.net/analysis/reports/2025/estimated-financial-losses-faced-by-uk-farmers-due-dry-weather-impacts-on-key-arable-crops)] Energy & Climate Intelligence Unit, â€˜Estimated financial losses faced by UK farmers due dry weather impacts on key arable cropsâ€™, Energy & Climate Intelligence Unit, London, United Kingdom, Dec. 2025.\n",
    "\n",
    "[[IPCC+23](https://doi.org/10.59327/IPCC/AR6-9789291691647)] IPCC, â€˜Climate Change 2023: Synthesis Report. Contribution of Working Groups I, II and III to the Sixth Assessment Report of the Intergovernmental Panel on Climate Changeâ€™, Intergovernmental Panel on Climate Change (IPCC), Geneva, Switzerland, Jul. 2023. doi: 10.59327/IPCC/AR6-9789291691647.\n",
    "\n",
    "[[UNICEF+24](https://www.unicef.org/media/165191/file/LACR-Flash-Update-11-November-2024.pdf)] UNICEF, â€˜Latin America and Caribbean Region Flash Update No. 2 (Climate-related crisis in the Amazon Region)â€™, UNICEF, Nov. 2024.\n",
    "\n",
    "[[Franch-Pardo+25](https://doi.org/10.48088/ejg.i.fra.16.2.286.297)] I. Franch-Pardo, P. A. F. Puig, and A. CerdÃ , â€˜Geospatial Technologies in Crisis Response: Analyzing the 2024 Floods in Valencia, Spainâ€™, European Journal of Geography, vol. 16, no. 2, pp. 286â€“297, Aug. 2025, doi: 10.48088/ejg.i.fra.16.2.286.297.\n",
    "\n",
    "[[McKee+93](https://climate.colostate.edu/pdfs/relationshipofdroughtfrequency.pdf)] T. B. McKee, N. J. Doesken, and J. Kleist, â€˜The relationship of drought frequency and duration to time scalesâ€™, in Eighth Conference on Applied Climatology, Anaheim, California, USA, Jan. 1993.\n",
    "\n",
    "[[Keune+25](https://doi.org/10.1038/s41597-025-04896-y)] J. Keune, F. Di Giuseppe, C. Barnard, E. Damasio da Costa, and F. Wetterhall, â€˜ERA5â€“Drought: Global drought indices based on ECMWF reanalysisâ€™, Scientific Data, vol. 12, p. 616, Apr. 2025, doi: 10.1038/s41597-025-04896-y.\n",
    "\n",
    "[[EDO+25](https://drought.emergency.copernicus.eu/data/factsheets/factsheet_spi.pdf)] EDO â€“ European Drought Observatory, â€˜EDO and GDO indicator factsheet: _Standardized Precipitation Index (SPI)_â€™, Copernicus Emergency Management Service, Mar. 2025. Accessed: Feb. 09, 2026. [Online]. Available: https://drought.emergency.copernicus.eu/data/factsheets/factsheet_spi.pdf\n",
    "\n",
    "[[Vicente-Serrano+10](https://doi.org/10.1175/2009JCLI2909.1)] S. M. Vicente-Serrano, S. BeguerÃ­a, and J. I. LÃ³pez-Moreno, â€˜A Multiscalar Drought Index Sensitive to Global Warming: The Standardized Precipitation Evapotranspiration Indexâ€™, Journal of Climate, vol. 23, no. 7, pp. 1696â€“1718, Apr. 2010, doi: 10.1175/2009JCLI2909.1.\n",
    "\n",
    "[[Soci+24](https://doi.org/10.1002/qj.4803)] C. Soci et al., â€˜The ERA5 global reanalysis from 1940 to 2022â€™, Quarterly Journal of the Royal Meteorological Society, vol. 150, no. 764, pp. 4014â€“4048, Jul. 2024, doi: 10.1002/qj.4803.\n",
    "\n",
    "[[Hersbach+20](https://doi.org/10.1002/qj.3803)] H. Hersbach et al., â€˜The ERA5 global reanalysisâ€™, Quarterly Journal of the Royal Meteorological Society, vol. 146, no. 730, pp. 1999â€“2049, May 2020, doi: 10.1002/qj.3803.\n",
    "\n",
    "[[Stagge+15](https://doi.org/10.1002/joc.4267)] J. H. Stagge, L. M. Tallaksen, L. Gudmundsson, A. F. Van Loon, and K. Stahl, â€˜Candidate Distributions for Climatological Drought Indices (SPI and SPEI)â€™, International Journal of Climatology, vol. 35, no. 13, pp. 4027â€“4040, Feb. 2015, doi: 10.1002/joc.4267.\n",
    "\n",
    "[[Gebrechorkos+19](https://doi.org/10.1038/s41598-019-47933-8)] S. H. Gebrechorkos, S. HÃ¼lsmann, and C. Bernhofer, â€˜Long-term trends in rainfall and temperature using high-resolution climate datasets in East Africaâ€™, Sci Rep, vol. 9, no. 1, p. 11376, Aug. 2019, doi: 10.1038/s41598-019-47933-8.\n",
    "\n",
    "[[Shapiro+65](https://doi.org/10.1093/biomet/52.3-4.591)] S. S. Shapiro and M. B. Wilk, â€˜An analysis of variance test for normality (complete samples)â€™, Biometrika, vol. 52, no. 3â€“4, pp. 591â€“611, Dec. 1965, doi: 10.1093/biomet/52.3-4.591."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
