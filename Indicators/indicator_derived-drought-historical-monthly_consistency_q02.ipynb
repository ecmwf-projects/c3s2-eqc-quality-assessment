{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Quality Assessment for ERA5 Drought Indicator: Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Production date: 2026-xx-xx\n",
    "\n",
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "\n",
    "Dataset version: 1.0.\n",
    "\n",
    "Produced by: Enis Gerxhalija, Olivier Burggraaff (National Physical Laboratory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ðŸŒ Use case: Retrieving drought indicators from the ERA5-Drought dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## â“ Quality assessment question\n",
    "* **Are the drought indicators in the ERA5-Drought dataset consistent with and reproducible from ERA5 data?**\n",
    "* **Are the drought indicators in the ERA5-Drought dataset presented in a format that ensures optimal usability for users?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Human-induced climate change is likely the primary driver behind the number of increased droughts and heavy precipitation since the 1950s, per the latest assessment report by the Intergovernmental Panel on Climate Change [IPCC, 2013](https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf). With further global warming at 1.5Â°C and above, heavy precipitation, flooding and drought events are projected to intensify and become more frequent in most regions of Africa, Asia, North America and Europe. The environmental and societal impact of such extreme weather events are far-reaching. In the United Kingdom alone, the 2020s have seen three of the five worst harvests on record, with extreme heat and drought in 2025 causing more than Â£800mn lost revenue in harvest, [Energy & Climate Intelligence Unit](https://mcusercontent.com/8ed7ad7972fae058e8f4fb7e8/files/6d02e6e7-8639-a44d-5a8c-2313124ef699/Costs_of_climate_analysis_011225.pdf). In 2023-2024, the Amazon region in Brazil faced an 18-month drought considered the most severe since drought monitoring began in 1954. By November 2024, it left 720 health centres in drought-affected areas of Brazil to become non-operational [UNICEF, 2024](https://www.unicef.org/media/165191/file/LACR-Flash-Update-11-November-2024.pdf).\n",
    "\n",
    "A large scientific effort has gone into identifying areas more prone to drought along with monitoring areas currently experiencing drought conditions and accurately quantifying their severity [reference]. The objective quantification of drought severity remains an ongoing endeavour amongst scientists as there is not one physical variable that describes a drought. One might assume that drought severity can be measured by the total precipitation in that region, but this would overlook water-loss from the land surface through evapotranspiration, soil moisture levels, temperature anomalies and other natural variables. There is however consensus that drought indices, proxies based on long-term and shorter-term historical weather data, can accurately quantify drought severity and their impact, with studies linking the variability of drought indices to crop yields, [Vicenteâ€Serrano et al.](https://doi.org/10.1080/01431160500296032), and frequency of wildfires [reference]. Two widely-employed drought indices are the Standardised Precipitation Index (SPI) [reference](), endorsed by the World Metereological Organisation (WMO), and the more recent Standardised Precipitation-Evapotranspiration Index (SPEI) [reference](). \n",
    "\n",
    "The ERA5-Drought dataset provides a reanalysis-based dataset of the aforementioned indices using the ECMWF Reanalysis version 5 (ERA5), at a resolution of 0.25Â° globally (around 28 km) from the start of the reanalysis (in 1940) to today, [Keune et al., â€˜ERA5â€“Droughtâ€™](https://doi.org/10.1038/s41597-025-04896-y). The ERA5-Drought dataset consists of 1 deterministic and 10 ensemble drought-index members from slightly different initial conditions, enabling an estimate of the uncertainty.\n",
    "\n",
    "This notebook aims to give users much-needed confidence and transparency in the calculation of the two drought indices along with their quality flags. The C3S ERA5-Drought dataset must be consistent with and reproducible from its origins. Here, we assess this consistency and reproducibility by comparing drought-indicators retrieved from the ERA5-Drought dataset with their equivalents calculated from the origin dataset (or similar). While a full analysis and reproduction of every record within the C3S ERA5-Drought dataset is outside the scope of quality assessment (as it would require high-performance computing infrastructure), a case study with a narrower scope probes these quality attributes of the dataset and can be a jumping-off point for further analysis by the reader."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ“¢ Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Conclusion 1\n",
    "* Conclusion 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ðŸ“‹ Methodology\n",
    "\n",
    "This quality assessment tests the consistency between drought indices retrieved from the [C3S ERA5-Drought dataset] and their equivalents calculated from the origin datasets, as well as the reproducibility and usability of said dataset.\n",
    "\n",
    "We will examine the SPI and SPEI drought indicators calculated from the following datasets:\n",
    "\n",
    "(include table here of the parameter, description of that parameters, and the origin dataset)\n",
    "\n",
    "The analysis and results are organised in the following steps, which are detailed in the sections below:\n",
    "\n",
    "**[](section-codesetup)**\n",
    " * Import all required libraries.\n",
    " * Define helper functions.\n",
    " * \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "\n",
    "**[](section-2)**\n",
    " * Define SPI Indicator\n",
    " * Download ERA5 precipitation\n",
    " * Accumulate\n",
    " * Calculate SPI\n",
    " * Calculate quality flags from ERA5 data\n",
    " * Download quality flags from ERA5-Drought\n",
    " * Compare quality flags\n",
    " * Download ERA5-Drought SPI\n",
    " * Comparison\n",
    " * \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "\n",
    "**[](section-3)**\n",
    " * Define SPEI Indicator\n",
    " * Download ERA5 potential evaporation\n",
    " * Accumulate\n",
    " * Calculate SPEI\n",
    " * Calculate quality flags from ERA5 data\n",
    " * Download quality flags from ERA5-Drought\n",
    " * Compare quality flags\n",
    " * Download ERA5-Drought SPEi\n",
    " * Comparison\n",
    " * \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "\n",
    "**[](section-4)**\n",
    " \n",
    "**[](section-5)** \n",
    "\n",
    "Any further notes on the method could go here (explanations, caveats or limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-codesetup)=\n",
    "### 1. Code setup\n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data)) and visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data. Because earthkit is in active development, some functionality may change after this notebook is published. If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Import required libraries\n",
    "In this section, we import all the relevant packages needed for running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Input / Output\n",
    "from pathlib import Path\n",
    "import earthkit.data as ekd\n",
    "import warnings\n",
    "\n",
    "# General data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "\n",
    "# Analysis\n",
    "import calendar\n",
    "from scipy import stats\n",
    "\n",
    "# Visualisation\n",
    "import earthkit.plots as ekp\n",
    "from earthkit.plots.styles import Style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "from tqdm import tqdm  # Progress bars\n",
    "\n",
    "# Visualisation in Jupyter book -- automatically ignored otherwise\n",
    "try:\n",
    "    from myst_nb import glue\n",
    "except ImportError:\n",
    "    glue = None\n",
    "\n",
    "# Type hints\n",
    "from typing import Callable, Iterable, Optional\n",
    "from scipy.stats import rv_continuous as Distribution\n",
    "from earthkit.plots.geo.domains import Domain\n",
    "AnyDomain = (Domain | str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "This section defines some functions and variables used in the following analysis, allowing code cells in later sections to be shorter and ensuring consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "##### Data (pre-)processing\n",
    "The following functions handle [data chunking in dask](https://docs.xarray.dev/en/latest/user-guide/dask.html) for computational efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rechunk(data: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Re-chunk a dataset into pre-determined optimal chunks. \"\"\"\n",
    "    # Might need to be adjusted for different coordinate names\n",
    "    return data.chunk({\"valid_time\": -1, \"latitude\": 103, \"longitude\": 360})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "##### Accumulation periods\n",
    "The following cells contain constants and functions used in accumulating variables (e.g. precipitation) over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants such as the accumulation periods to use\n",
    "ACCUMULATION_PERIODS = [1, 3, 6, 12, 24, 36, 48]  # Months\n",
    "MONTHS = range(1, 13)  # January to December (inclusive)\n",
    "\n",
    "# Perform accumulation\n",
    "def accum_var(data: xr.Dataset, var: str, *,\n",
    "              accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS, time_dim: Optional[str]=None) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Compute the precipitation / potential evaporation accumulation window. \n",
    "    \n",
    "    1. Convert precipitation/potential evaporation from meters to millimeters.\n",
    "    2. Compute monthly totals (accounting for days in month).\n",
    "    3. Add rolling accumulation windows on monthly totals.\n",
    "    \"\"\"\n",
    "    # Detect time dimension if not provided\n",
    "    # TO DO: Use the first dimension that contains \"time\"?\n",
    "    if time_dim is None:\n",
    "        if 'valid_time' in data.dims:\n",
    "            time_dim = 'valid_time'\n",
    "        elif 'forecast_reference_time' in data.dims:\n",
    "            time_dim = 'forecast_reference_time'\n",
    "        elif \"time\" in data.dims:\n",
    "            time_dim = \"time\"\n",
    "        else:\n",
    "            raise ValueError(\"No valid time dimension found. Expected 'valid_time' or 'forecast_reference_time'.\")\n",
    "\n",
    "    # Ensure time is sorted\n",
    "    # TO DO: Is this necessary?\n",
    "    data = data.sortby(time_dim)\n",
    "    \n",
    "    # Step 1: Convert to mm\n",
    "    data[f'{var}_mm'] = data[var] * 1000\n",
    "\n",
    "    # Step 2: Compute monthly totals\n",
    "    # TO DO: Is this necessary for the analysis (I don't think so) or only for the plot?\n",
    "    # In the latter case, you could (don't need to) either make this optional or split it out altogether\n",
    "    time_index = pd.to_datetime(data[time_dim].values)\n",
    "    \n",
    "    days_in_month = xr.DataArray(\n",
    "        time_index.days_in_month,\n",
    "        coords={time_dim: data[time_dim]},\n",
    "        dims=[time_dim]\n",
    "    )\n",
    "\n",
    "    data[f'{var}_mm_monthly_total'] = data[f'{var}_mm'] * days_in_month\n",
    "    data[f'{var}_mm_monthly_total'] = data[f'{var}_mm_monthly_total'].astype(\"float64\")\n",
    "\n",
    "    # Step 3: Add rolling accumulation windows\n",
    "    for period in accumulation_periods:\n",
    "        rolling_sum = data[f\"{var}_mm_monthly_total\"].rolling({time_dim: period}, center=False).sum()\n",
    "        data[f'{var}_mm_accum_{period}m'] = rolling_sum\n",
    "\n",
    "    data = data.chunk({time_dim: -1})\n",
    "\n",
    "    return data.drop_vars([f\"{var}\", f\"{var}_mm\", f\"{var}_mm_monthly_total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Calculating SPI / SPEI\n",
    "The following cells contain code for calculating SPI and SPEI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The following functions ... fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_monthly_distributions_xr(reference_data: xr.Dataset, var: str, *,\n",
    "                                 accumulation_periods: Iterable[int]=ACCUMULATION_PERIODS, time_dim: Optional[str]=None) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Fit gamma/genlogistic distributions for each month and accumulation period using xarray.\n",
    "    Data are assumed to have been sliced to the reference period.\n",
    "    \"\"\"\n",
    "    monthly_params = {}\n",
    "\n",
    "    # Detect time dimension if not provided\n",
    "    # TO DO: Use the first dimension that contains \"time\"?\n",
    "    # TO DO: Refactor so can be re-used\n",
    "    if time_dim is None:\n",
    "        if 'valid_time' in reference_data.dims:\n",
    "            time_dim = 'valid_time'\n",
    "        elif 'forecast_reference_time' in reference_data.dims:\n",
    "            time_dim = 'forecast_reference_time'\n",
    "        else:\n",
    "            raise ValueError(\"No valid time dimension found. Expected 'valid_time' or 'forecast_reference_time'.\")\n",
    "\n",
    "    for period in accumulation_periods:\n",
    "        var_name = f'{var}_mm_accum_{period}m'\n",
    "        for month in range(1, 13):\n",
    "            # Select month subset\n",
    "            month_subset = reference_data[var_name].where(reference_data[time_dim].dt.month == month, drop=True)\n",
    "\n",
    "            # Drop NaNs and flatten\n",
    "            values = month_subset.values.flatten()\n",
    "            values = values[~np.isnan(values)]\n",
    "            if len(values) > 0:\n",
    "                # TO DO: Make the fitting distribution an argument to the function,\n",
    "                # then use functools.partial to create defaults\n",
    "                # e.g. function call: (..., var: str, distribution: Callable, ...)\n",
    "                # and the part below becomes alpha, loc, beta = distribution.fit(values)\n",
    "                # and then define\n",
    "                # fit_monthly_spi  = partial(fit_monthly_distributions_xr, distribution=stats.gamma)\n",
    "                # fit_monthly_spei = partial(fit_monthly_distributions_xr, distribution=stats.genlogistic)\n",
    "                if var == \"tp\":\n",
    "                    alpha, loc, beta = stats.gamma.fit(values)\n",
    "                elif var == \"pev\" or \"wb\":\n",
    "                    alpha, loc, beta = stats.genlogistic.fit(values) # alpha is shape parameters, loc = location, beta is scale.\n",
    "\n",
    "            # Else?\n",
    "            monthly_params[(month, period)] = (alpha, loc, beta) # TODO: put into a xarray.\n",
    "    return monthly_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General fitting function\n",
    "def fit_monthly_distributions_new(reference_data: xr.Dataset, distribution: Distribution, *,\n",
    "                                  time_dim: Optional[str]=None) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Fit distributions (e.g. gamma) for each month and accumulation period using xarray parallelisation.\n",
    "    Data are assumed to have been sliced to the reference period.\n",
    "    \"\"\"\n",
    "    # Define fitting function\n",
    "    def fit(y):\n",
    "        y = y[np.isfinite(y)]\n",
    "        params = distribution.fit(y) #500 ,loc=-1000, scale = 5)\n",
    "        params = np.stack(params, axis=-1)  # Extend with axis for stats (alpha, loc, scale ...)\n",
    "        return params\n",
    "\n",
    "    # Split dataset by month\n",
    "    if time_dim is None:  # Detect time dimension if not provided\n",
    "        time_dim = next(dim for dim in reference_data.dims if \"time\" in dim)  # TO DO: Refactor so can be re-used\n",
    "    reference_data_by_month = reference_data.groupby(reference_data[time_dim].dt.month)\n",
    "\n",
    "    # Apply fitting function by month\n",
    "    params = xr.apply_ufunc(fit, reference_data_by_month,\n",
    "                            input_core_dims=[[time_dim]], output_core_dims=[[\"stat\"]],\n",
    "                            vectorize=True,\n",
    "                            dask=\"parallelized\",\n",
    "                            dask_gufunc_kwargs={\"output_sizes\": {\"stat\": distribution.numargs+2}},  # e.g. 3 for gamma (alpha, loc, scale)\n",
    "                            output_dtypes=[np.float64],\n",
    "                           )\n",
    "    params = params.chunk({\"month\": -1})\n",
    "\n",
    "    return params\n",
    "\n",
    "# Fitting functions for SPI, SPEI specifically\n",
    "fit_monthly_spi  = partial(fit_monthly_distributions_new, distribution=stats.gamma) # partial function\n",
    "fit_monthly_spei = partial(fit_monthly_distributions_new, distribution=stats.genlogistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The following functions ... applying fitted distributions to calculate SPI / SPEI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General computing function\n",
    "def compute_monthly_series_new(data: xr.Dataset, monthly_params: xr.Dataset, distribution: Distribution, *,\n",
    "                               index_name: Optional[str]=None, time_dim: Optional[str]=None) -> tuple[xr.Dataset]:\n",
    "    \"\"\"\n",
    "    Compute SPI time series for each accumulation period using fitted distribution parameters.\n",
    "    Returns two datasets: CDF values and index (SPI/SPEI) values.\n",
    "    \"\"\"\n",
    "    # Create a month dimension for broadcasting with the one in monthly_params\n",
    "    if time_dim is None:  # Detect time dimension if not provided\n",
    "        time_dim = next(dim for dim in data.dims if \"time\" in dim)  # TO DO: Refactor so can be re-used\n",
    "    month_da = data[time_dim].dt.month.rename(\"month\")\n",
    "\n",
    "    params_fitted = monthly_params\n",
    "    \n",
    "    # Extract parameters\n",
    "    nr_params = params_fitted.sizes[\"stat\"]  # 3 for gamma and genlogistic\n",
    "    params_extracted = [params_fitted.sel(stat=j).sel(month=month_da) for j in range(nr_params)]\n",
    "\n",
    "    # Calculate CDF values by month\n",
    "    cdf = xr.apply_ufunc(distribution.cdf, data, *params_extracted,\n",
    "                         input_core_dims=[[], [], [], []], output_core_dims=[[]],\n",
    "                         vectorize=True, dask=\"parallelized\",\n",
    "                         output_dtypes=[np.float64],\n",
    "                         keep_attrs=True\n",
    "                        )\n",
    "    cdf = cdf.chunk({time_dim: -1})\n",
    "    \n",
    "    clipped = cdf.clip(1e-16, 1 - 1e-16)\n",
    "\n",
    "    # Convert CDF to index\n",
    "    index = xr.apply_ufunc(stats.norm.ppf, clipped,\n",
    "                           input_core_dims=[[]], output_core_dims=[[]],\n",
    "                           vectorize=True, dask=\"parallelized\",\n",
    "                           output_dtypes=[np.float64],\n",
    "                           keep_attrs=True\n",
    "                          )\n",
    "\n",
    "    # Optional: Rename variables in index dataset to e.g. SPI12\n",
    "    if index_name:\n",
    "        accumulation_variables = {var: var.split(\"_\")[-1][:-1] for var in index.variables if \"accum\" in var}  # Get periods as number strings\n",
    "        rename_variables = {var: f\"{index_name}{accumulation_period}\" for var, accumulation_period in accumulation_variables.items()}\n",
    "        index = index.rename_vars(rename_variables)\n",
    "\n",
    "    return cdf, index\n",
    "\n",
    "# Computing functions for SPI, SPEI specifically\n",
    "compute_monthly_spi  = partial(compute_monthly_series_new, distribution=stats.gamma,       index_name=\"SPI\")\n",
    "compute_monthly_spei = partial(compute_monthly_series_new, distribution=stats.genlogistic, index_name=\"SPEI\")\n",
    "\n",
    "def compute_spi_dataset(data, accum_periods, n_points = 1000):\n",
    "    \"\"\"\n",
    "    Fit gamma distribution for each month and accumulation period,\n",
    "    then compute SPI, CDF, and PDF for a linspace of precipitation values.\n",
    "    \"\"\"\n",
    "    result_vars = {}\n",
    "\n",
    "    for period in accum_periods:\n",
    "        var_name = f'tp_mm_accum_{period}m'\n",
    "        \n",
    "        tp_values = data[var_name]\n",
    "\n",
    "        # Prepare storage lists\n",
    "        spi_list, cdf_list, pdf_list, precip_list = [], [], [], []\n",
    "\n",
    "        for month in range(1, 13):\n",
    "            # Select month subset\n",
    "            month_data = tp_values.where(tp_values['valid_time.month'] == month, drop=True).values\n",
    "            month_data = month_data[month_data > 0]                \n",
    "            month_data = month_data[~np.isnan(month_data)]\n",
    "\n",
    "                \n",
    "            # Fit gamma distribution\n",
    "            alpha, loc, beta = stats.gamma.fit(month_data, floc=0)\n",
    "\n",
    "            vals = np.linspace(month_data.min(), month_data.max(), n_points)\n",
    "\n",
    "            # Compute PDF, CDF, SPI\n",
    "            cdf_vals = stats.gamma.cdf(vals, a=alpha, loc=loc, scale=beta)\n",
    "            spi_vals = stats.norm.ppf(cdf_vals)\n",
    "            pdf_vals = stats.gamma.pdf(vals, a=alpha, loc=loc, scale=beta)\n",
    "\n",
    "            # Append to lists\n",
    "            precip_list.append(vals)\n",
    "            spi_list.append(spi_vals)\n",
    "            cdf_list.append(cdf_vals)\n",
    "            pdf_list.append(pdf_vals)\n",
    "\n",
    "            \n",
    "        # Convert lists to DataArrays\n",
    "        months = np.arange(1, 13)\n",
    "        \n",
    "        result_vars[f'precip_{period}m'] = xr.DataArray(precip_list, dims=['month', 'value_index'], coords={'month': months})\n",
    "        result_vars[f'SPI_{period}m'] = xr.DataArray(spi_list, dims=['month', 'value_index'], coords={'month': months})\n",
    "        result_vars[f'CDF_{period}m'] = xr.DataArray(cdf_list, dims=['month', 'value_index'], coords={'month': months})\n",
    "        result_vars[f'PDF_{period}m'] = xr.DataArray(pdf_list, dims=['month', 'value_index'], coords={'month': months})\n",
    "\n",
    "    return xr.Dataset(result_vars)\n",
    "    \n",
    "def zero_precip_monthly_xr(prec_data: xr.Dataset, cdf_ds: xr.Dataset, reference_window, accum_periods: Iterable[int]=ACCUMULATION_PERIODS):\n",
    "    \"\"\"\n",
    "    Adjust CDF for zero precipitation probability in xarray.\n",
    "    \"\"\"\n",
    "    # Slice reference period, find time variable, and months.\n",
    "    reference_data = prec_data.sel(**reference_window)\n",
    "\n",
    "    reference_data = reference_data.to_array(\"accumulation_period\")\n",
    "    \n",
    "    time_dim = next(dim for dim in reference_data.dims if \"time\" in dim)  # TO DO: Refactor so can be re-used\n",
    "    month = reference_data[time_dim].dt.month\n",
    "\n",
    "    # Threshold precipitation\n",
    "    prec_eps = 0.01\n",
    "\n",
    "    # All months with precipitation less than precipitation.\n",
    "    is_zero = (reference_data <= prec_eps)\n",
    "\n",
    "    # Zero precipitation stats. \n",
    "    n_zero  = is_zero.groupby(month).sum(dim=time_dim)    \n",
    "                                         \n",
    "    # Count total months per calendar month\n",
    "    n_month = reference_data.groupby(month).count(dim=time_dim)\n",
    "\n",
    "    # Ratio of months with zero precipitation\n",
    "    ratio_zero = n_zero / n_month\n",
    "\n",
    "    # Weighted probability with zero precipitation.\n",
    "    p_zero = xr.where(\n",
    "        n_zero > 0,\n",
    "        (n_zero + 1) / (2 * (n_month + 1)),\n",
    "        0\n",
    "    ) \n",
    "\n",
    "    cdf = cdf_ds.to_array(\"accumulation_period\")\n",
    "    \n",
    "    cdf_data_by_month = cdf.groupby(\"valid_time.month\") \n",
    "\n",
    "    adjusted_cdf = cdf_data_by_month.map(\n",
    "        lambda x: p_zero.sel(month=x[\"valid_time.month\"]) + (1 - p_zero.sel(month=x[\"valid_time.month\"])) * x\n",
    "    ) #  pass formula onto each month and then just pass back to adjusted_cdf\n",
    "    \n",
    "    # Convert back to Dataset\n",
    "    adjusted_cdf = adjusted_cdf.to_dataset(\"accumulation_period\")\n",
    "\n",
    "    # Summary of stats\n",
    "    stats_summary = xr.Dataset({\n",
    "        \"Zero-Precip Count\": n_zero,\n",
    "        \"Total Months\": n_month,\n",
    "        \"Prob Zero Precip\": p_zero,\n",
    "        \"Historical Ratio\": ratio_zero,\n",
    "    })\n",
    "\n",
    "    stats_summary = stats_summary.assign_coords(accumulation_period=(\"accumulation_period\", accum_periods))\n",
    "    \n",
    "    return adjusted_cdf, stats_summary \n",
    "    \n",
    "def xr_shapiro_test(spi_ds: xr.Dataset,accum_periods: Iterable[int]=ACCUMULATION_PERIODS, months = range(1,13) )  :\n",
    "    # TODO: Optimise this function with dask and adapt to above.\n",
    "    spi_ref = spi_ds.sel(valid_time=slice(\"1991-01-01\", \"2020-12-31\"))\n",
    "\n",
    "    spi_ref = spi_ref.chunk({'valid_time': -1})        # make valid_time one chunk\n",
    "    \n",
    "    spi_ref = spi_ref.where(np.isfinite(spi_ref)) # Mask non-finite values before masking.\n",
    "    \n",
    "    spi_ref_by_month = spi_ref.groupby(\"valid_time.month\")\n",
    "    \n",
    "    # Perform shapiro on xarray\n",
    "    stat, pval = xr.apply_ufunc(stats.shapiro, spi_ref_by_month, \n",
    "                           input_core_dims=[['valid_time']], output_core_dims=[[],[]],\n",
    "                           vectorize=True, dask=\"parallelized\",\n",
    "                           output_dtypes=[np.float64, np.float64],\n",
    "                           keep_attrs=True\n",
    "                          )\n",
    "    \n",
    "    normality = xr.where(pval < 0.05, 0, 1) #  Values < 0.05 â†’ 0\n",
    "    \n",
    "    return stat, pval, normality\n",
    "\n",
    "def cdf_to_spi_transform(adjusted_cdf_ds):\n",
    "\n",
    "    clipped = adjusted_cdf_ds.clip(1e-16, 1 - 1e-16)\n",
    "    \n",
    "    # Convert CDF to index\n",
    "    adjusted_spi_ds = xr.apply_ufunc(stats.norm.ppf, clipped, 0.0, 1.0,  \n",
    "                           input_core_dims=[[], [], []], output_core_dims=[[]],\n",
    "                           vectorize=True, dask=\"parallelized\",\n",
    "                           output_dtypes=[np.float64],\n",
    "                           keep_attrs=True\n",
    "    )\n",
    "    \n",
    "    accumulation_variables = {var: var.split(\"_\")[-1][:-1] for var in adjusted_spi_ds.variables if \"accum\" in var}  # Get periods as number strings\n",
    "    rename_variables = {var: f\"{\"SPI\"}{accumulation_period}\" for var, accumulation_period in accumulation_variables.items()}\n",
    "    \n",
    "    return adjusted_spi_ds.rename_vars(rename_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "##### Helper functions for reading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def era5_drought_api_multiple(indicator, var, accum_period = [1, 3, 6, 12, 24, 36, 48]):\n",
    "    ind = indicator.strip().upper()\n",
    "    if ind not in {\"SPI\", \"SPEI\"}:\n",
    "        raise ValueError(\"indicator must be 'SPI' or 'SPEI'\")\n",
    "    ind = ind.lower()\n",
    "\n",
    "    var_key = var.strip().lower()\n",
    "    if var_key not in {\"prob_zero\", \"quality\"}:\n",
    "        raise ValueError(\"var must be 'prob_zero' or 'quality'\")\n",
    "    if var_key == \"prob_zero\":\n",
    "        dataset_name = \"derived-drought-historical-monthly\"\n",
    "        request_var = f\"probability_of_zero_precipitation_{ind}\"\n",
    "        source_var_name = \"pzero\"\n",
    "        rename_prefix = \"prob_zero\"\n",
    "    else:\n",
    "        dataset_name = \"derived-drought-historical-monthly\"\n",
    "        request_var = f\"test_for_normality_{ind}\"\n",
    "        source_var_name = \"significance\"\n",
    "        rename_prefix = \"significance\"\n",
    "    \n",
    "\n",
    "    out = []\n",
    "    \n",
    "    for p in accum_period:\n",
    "        request = {\n",
    "            \"variable\": [request_var],\n",
    "            \"accumulation_period\": [str(p)],\n",
    "            \"version\": \"1_0\",\n",
    "            \"product_type\": [\"reanalysis\"],\n",
    "            \"dataset_type\": \"consolidated_dataset\",\n",
    "            \"month\": [f\"{m:02d}\" for m in range(1, 13)],\n",
    "        }\n",
    "\n",
    "        ds = ekd.from_source(\"cds\", dataset_name, request).to_xarray(compat=\"equals\")\n",
    "        \n",
    "        if source_var_name not in ds.variables:\n",
    "            raise KeyError(\n",
    "                f\"Expected variable '{source_var_name}' not found for period {p}. \"\n",
    "                f\"Available: {list(ds.variables)}\"\n",
    "            )\n",
    "\n",
    "        new_name = f\"{rename_prefix}_{p}\"\n",
    "        ds_renamed = ds.rename({source_var_name: new_name})[[new_name]]\n",
    "        out.append(ds_renamed)\n",
    "\n",
    "    out = xr.merge(out, compat=\"override\")\n",
    "    out.to_array(\"accumulation_period\")\n",
    "    out.assign_coords(accumulation_period=(\"accumulation_period\", ACCUMULATION_PERIODS))\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-2)=\n",
    "### 2. Calculate SPI at one location from ERA5 reanalysis data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Download monthly precipitation data \n",
    "First, we download the monthly-mean total precipitation data from the ERA5 reanalysis.\n",
    "Generally,\n",
    "one would use the [_ERA5 monthly averaged data on single levels from 1940 to present_ (reanalysis-era5-single-levels-monthly-means)](https://doi.org/10.24381/cds.f17050d7) dataset for this,\n",
    "which provides pre-calculated monthly means at 0.25Â° by 0.25Â° resolution.\n",
    "For this assessment,\n",
    "to be as close to the ERA5-Drought data processing pipeline as possible\n",
    "and\n",
    "to make use of some of MARS's functionalities (see [below](section-4)),\n",
    "we instead use the [_Complete ERA5 global atmospheric reanalysis_ (reanalysis-era5-complete)](https://doi.org/10.24381/cds.143582cf) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "In this assessment,\n",
    "we will calculate SPI and SPEI for each month\n",
    "(with different accumulation periods, see below)\n",
    "for the years 1940â€“2024.\n",
    "For the reference period,\n",
    "we will use the World Meteorological Organization (WMO) current standard 30-year reference period of 1991â€“2020,\n",
    "which is also used in ERA5-Drought.\n",
    "Both of these date ranges can be adjusted in the cell below when running the analysis yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your preferred analysis and reference periods\n",
    "years           = (1940, 2024)  # Years for the analysis (inclusive)\n",
    "years_reference = (1991, 2020)  # Years for the reference period (inclusive)\n",
    "\n",
    "# Derived variables for convenience:\n",
    "reference_window = {\"valid_time\": slice(f\"{years_reference[0]}-01-01\", f\"{years_reference[1]}-12-01\"),}  #  Slice (1991-01-01, 2020-12-01)\n",
    "entire_window = {\"valid_time\": slice(f\"{years[0]}-01-01\", f\"{years[1]}-12-01\"),}  #  Slice (1940-01-01, 2024-12-01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Having defined our target years, we can now define our CDS request.\n",
    "First, we define a template with some default parameters\n",
    "(e.g. years, data format)\n",
    "that will also be used later in the notebook.\n",
    "Additional information for specific downloads\n",
    "(e.g. variable, data stream)\n",
    "is mixed into this template where relevant.\n",
    "\n",
    "This notebook uses [earthkit-data](https://github.com/ecmwf/earthkit-data) to download files from the CDS.\n",
    "If you intend to run this notebook multiple times, it is highly recommended that you [enable caching](https://earthkit-data.readthedocs.io/en/latest/guide/caching.html) to prevent having to download the same files multiple times.\n",
    "If you prefer not to use earthkit, the following requests can also be used with the [cdsapi module](https://cds.climate.copernicus.eu/how-to-api#linux-use-client-step).\n",
    "In either case (earthkit-data or cdsapi), it is required to set up a CDS account and API key as explained [on the CDS website](https://cds.climate.copernicus.eu/how-to-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_ERA5 = \"reanalysis-era5-complete\"\n",
    "\n",
    "request_era5_template = {\n",
    "    \"class\": \"ea\",            # Default for ERA5\n",
    "    # Dates: ERA5 takes these in the format 19400101/19400201/.../20241101/20241201\n",
    "    # The following line generates a string in said format from the chosen year range\n",
    "    \"date\": \"/\".join(f\"{year}{month:02}01\"\n",
    "            for year in range(years[0] ,years[1]+1)\n",
    "            for month in MONTHS),\n",
    "    \"expver\": \"1\",            # ERA5 consolidated data\n",
    "    \"levtype\": \"sfc\",         # Surface\n",
    "    \"grid\": \"0.25/0.25\",      # Grid: 0.25Â° by 0.25Â°\n",
    "    \"type\": \"fc\",             # Forecast\n",
    "    \"data_format\": \"netcdf\",  # NetCDF data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "In this section, we want to download \n",
    "total precipitation data (variable `228.128`)\n",
    "from the\n",
    "`moda` stream (monthly-mean reanalysis data),\n",
    "so we mix this information into the template\n",
    "and submit the request to the CDS.\n",
    "More information about formatting these requests is available in the [MARS ERA5 catalogue](https://apps.ecmwf.int/data-catalogues/era5/?class=ea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_precipitation_moda = {\n",
    "    \"param\": \"228.128\",       # Variable: Total precipitation\n",
    "    \"stream\": \"moda\",         # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and convert to desired format\n",
    "era5_monthly_mean_reanal = ekd.from_source(\"cds\", ID_ERA5, request_era5_precipitation_moda)  # Download as field list\n",
    "era5_monthly_mean_reanal = era5_monthly_mean_reanal.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "era5_monthly_mean_reanal = rechunk(era5_monthly_mean_reanal)  # Re-chunk for speed gain in fitting\n",
    "era5_monthly_mean_reanal  # Display in notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "#### 1. Calculate moving average for different accumulation periods.\n",
    "A time series of precipitation for one grid point is extracted and precipitation is accumulated over the previous $n$ months using a moving window. Since the origin precipitation data from ERA5 is from the monthly mean dataset, we calculate the total precipitation for that month by multiplying with the total number of days in that month, correcting for leap years.\n",
    "\n",
    "The different accumulation windows are used to determine the timescale of the drought. The longer the drought, typically the more severe the impact it will have.\n",
    "\n",
    "* **1-, 3-month window**: useful for soil moisture, flow in small creaks.\n",
    "* **6-, 12-month window**: looking at reservoir storage, reduced stream flow.\n",
    "* **24-, 36-, 48-month window**: groundwater recharge, reduced reservoir. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "TO DO: Some text about the user choosing their point here, which point did we choose and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your preferred site for the SPI example\n",
    "example_site = {\"latitude\": 9.25, \"longitude\": 40.5,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the grid point and time slice for Ethiopia\n",
    "precipitation_example_site = era5_monthly_mean_reanal.sel(**example_site)\n",
    "\n",
    "# Perform the accumulation for each accumulation period\n",
    "precipitation_example_site = accum_var(precipitation_example_site, \"tp\")\n",
    "\n",
    "# Display result\n",
    "precipitation_example_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Refactor so the same function can be re-used for TPâ€“PEV later\n",
    "plt.figure(figsize=(12, 6))\n",
    "for p in ACCUMULATION_PERIODS:\n",
    "    var_name = f'tp_mm_accum_{p}m'\n",
    "    plt.plot(precipitation_example_site['valid_time'].values, precipitation_example_site[var_name].values, label=f'{p}-month')\n",
    "\n",
    "# Customize plot\n",
    "plt.title(f\"Precipitation Accumulation at ({example_site['latitude']} Â°N, {example_site['longitude']} Â°E)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Precipitation [mm]\")\n",
    "plt.legend(title=\"Accumulation period\", reverse=True) # plot legend in reverse to match order of the lines (top-to-bottom).\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Fit gamma distribution (over calendar months) to different accumulation periods.\n",
    "\n",
    "The gamma distribution [reference] is fitted only to the data within the reference period (1991-2020). A separate distribution is fitted for each calendar month per accumulation window. \n",
    "\n",
    "For e.g. : in the 3-month accumulation window, a gamma distribution is fitted on all 30 Januaries in that reference period, all the Februaries (30 of them) and so forth... \n",
    "\n",
    "This fitting is done with the [scipy.stats.gamma](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html) object in Python. Three parameters are then outputted per calendar month, per accumulation period: the shape ($\\alpha$), location ($\\beta$) and scale ($\\lambda$) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily moved into separate cell for testing -- merge back into fitting cell below when done\n",
    "precipitation_example_site_reference = precipitation_example_site.sel(**reference_window) # select only reference precipitation window.\n",
    "precipitation_example_site_entire = precipitation_example_site.sel(**entire_window) # select only reference precipitation window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OB function testing (new)\n",
    "params_fitted = fit_monthly_spi(precipitation_example_site_reference)\n",
    "params_fitted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Compute SPI series\n",
    "\n",
    "From the parameters from the gamma distribution fitting, we calculate the cumulative distribution function or CDF, $F(x, \\alpha, \\beta, \\lambda)$, up to the accumulated precipitation $x$, from the probability distribution function or PDF, $f(u, \\alpha, \\beta, \\lambda)$:\n",
    "\n",
    "\\begin{equation}\n",
    "F(x, \\alpha, \\beta, \\lambda) = \\int_{0}^{x}f(u, \\alpha, \\beta, \\lambda) \\, du.\n",
    "\\end{equation}\n",
    "\n",
    "A one-to-one mapping of SPI-index to accumulated precipitation value is then obtained by transforming the cumulative probability values to a standard normal distribution with a mean ($\\mu$) of zero and standard deviation ($\\sigma$) of 1. This mapping is applied to the historical record of the accumulated precipitation values in that calendar month and accumulation window.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{SPI-index} = \\Phi^{-1}\\big(F(x, \\alpha, \\beta, \\lambda)\\big)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SPI series -- new function\n",
    "cdf_ds, spi_ds = compute_monthly_spi(precipitation_example_site_entire, params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Plot of Precipitation vs CDF (for different accumulation windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "spi_month_ds = spi_ds_prec.where(spi_ds_prec.month == 5, drop=True)\n",
    "\n",
    "for p in accum_periods:\n",
    "    var1_name = f'SPI_{p}m'\n",
    "    var2_name = f'CDF_{p}m'\n",
    "    var3_name = f'precip_{p}m'\n",
    "    cs = CubicSpline(spi_month_ds[var2_name].values.ravel(), spi_month_ds[var3_name].values.ravel())\n",
    "    x_range = np.arange(-0.01, 1.01, 0.01)\n",
    "    plt.plot(cs(x_range), x_range, label=f'{p}-month')\n",
    "    # plt.scatter(spi_ds[var1_name].values, cdf_ds[var2_name].values, label=f'{p}-month')\n",
    "    # plt.scatter(spi_month_ds[var1_name].values, spi_month_ds[var3_name].values, label=f'{p}-month', s=10)\n",
    "\n",
    "# Customize plot\n",
    "plt.title('CDF vs Precipitaiton')\n",
    "plt.xlabel('Precipitation (mm)')\n",
    "plt.ylabel('CDF')\n",
    "plt.ylim([0,1])\n",
    "plt.legend(title='Accumulation Period')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Plot of Precipitation vs SPI (for different accumulation windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "spi_month_ds = spi_ds_prec.where(spi_ds_prec.month == 5, drop=True)\n",
    "\n",
    "for p in accum_periods:\n",
    "    var1_name = f'SPI_{p}m'\n",
    "    var2_name = f'CDF_{p}m'\n",
    "    var3_name = f'precip_{p}m'\n",
    "    cs = CubicSpline(spi_month_ds[var1_name].values.ravel(), spi_month_ds[var3_name].values.ravel())\n",
    "    x_range = np.arange(-3, 3, 0.01)\n",
    "    plt.plot(x_range, cs(x_range), label=f'{p}-month')\n",
    "    # plt.scatter(spi_ds[var1_name].values, cdf_ds[var2_name].values, label=f'{p}-month')\n",
    "    # plt.scatter(spi_month_ds[var1_name].values, spi_month_ds[var3_name].values, label=f'{p}-month', s=10)\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Precipitation vs SPI')\n",
    "plt.xlabel('SPI')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.legend(title='Accumulation Period')\n",
    "# plt.xlim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Plot of SPI vs CDF (for different accumulation windows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "spi_month_ds = spi_ds_prec.where(spi_ds_prec.month == 5, drop=True)\n",
    "\n",
    "for p in accum_periods:\n",
    "    var1_name = f'SPI_{p}m'\n",
    "    var2_name = f'CDF_{p}m'\n",
    "    var3_name = f'precip_{p}m'\n",
    "    cs = CubicSpline(spi_month_ds[var1_name].values.ravel(), spi_month_ds[var2_name].values.ravel())\n",
    "    x_range = np.arange(-3, 3, 0.01)\n",
    "    plt.plot(x_range, cs(x_range), label=f'{p}-month')\n",
    "    # plt.scatter(spi_ds[var1_name].values, cdf_ds[var2_name].values, label=f'{p}-month')\n",
    "    # plt.scatter(spi_month_ds[var1_name].values, spi_month_ds[var3_name].values, label=f'{p}-month', s=10)\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Precipitation vs SPI')\n",
    "plt.xlabel('SPI')\n",
    "plt.ylabel('Precipitation (mm)')\n",
    "plt.legend(title='Accumulation Period')\n",
    "# plt.xlim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Calculating historical ratio of months without precipitation and finding zero adjusted SPI (ref dataset)\n",
    "In regions of extremely low precipitation (e.g. the Sahara desert), months may have little to no accumulated precipitation. This poses a problem when fitting the gamma distribution since it is defined only for positive, real values. Furthermore, a criteria is set so that out of the 30 months in the reference period, per calendar month & accumulation window, 10 months must have non-zero accumulated precipitations. Otherwise, the calendar month is reported as having no value.\n",
    "\n",
    "Months with zero precipitation are defined as less than 0.1 mm by the [Copernicus European (EDO) and Global (GDO) Drought Observatories](https://drought.emergency.copernicus.eu/). The ERA5-Drought dataset appears to define months with zero precipitation as having an accumulated precipitation exactly equal to zero. \n",
    "\n",
    "To get around some months having zero precipitation, the CDF is adjusted with the historical occurrence $p_{0}$ of periods with zero precipitation [Stagge et al., â€˜Candidate Distributions for Climatological Drought Indices](https://doi.org/10.1002/joc.4267).\n",
    "\n",
    "\\begin{equation}\n",
    "F_{p_{0}}(x_{p>0},  \\alpha, \\beta, \\lambda) = p_{0} + \\big(1 - p_{0}\\big) \\, F(x_{p>0},  \\alpha, \\beta, \\lambda),\n",
    "\\end{equation}\n",
    "\n",
    "where $F_{p_{0}}(x_{p>0},  \\alpha, \\beta, \\lambda)$ is the CDF adjusted for zero precipitation.\n",
    "\n",
    "This simple treatment can lead to a z-distribution that is skewed, with a non-zero mean. Therefore, special care must be taken, and $p_{0}$ must be adjusted for the \"centre of probability mass\" following:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bar{p}_{0} = \\frac{n_{p=0} + 1}{2(n + 1)},\n",
    "\\end{equation}\n",
    "\n",
    "where $n_{p=0}$ are the number of calendar months in the reference period per accumulation window, and n are the total number of calendar months (30 reference calendar months).\n",
    "\n",
    "\\begin{equation}\n",
    "F_{\\bar{p}_{0}}(x, \\alpha, \\beta, \\lambda) =\n",
    "\\begin{cases}\n",
    "\\bar{p}_{0} + (1 - \\bar{p}_{0}) \\, F(x_{p>0},  \\alpha, \\beta, \\lambda), & x > 0, \\\\[6pt]\n",
    "\\frac{n_{p=0} + 1}{2(n+1)}, & x = 0.\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "This maintains the mean SPI value of zero, allowing for an objective statistical comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_cdf_ds, stats_sum = zero_precip_monthly_xr(precipitation_example_site_entire, cdf_ds, reference_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5. Adjust SPI values with zero precipitation probability.\n",
    "\n",
    "The CDF adjusted for months of zero precipitation is once again transformed to the z-normal distribution:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Adjusted SPI-index} = \\Phi^{-1}\\big(F_{\\bar{p}_{0}}(x,  \\alpha, \\beta, \\lambda)\\big)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_to_spi_transform(adjusted_cdf_ds):\n",
    "\n",
    "    clipped = adjusted_cdf_ds.clip(1e-16, 1 - 1e-16)\n",
    "    \n",
    "    # Convert CDF to index\n",
    "    adjusted_spi_ds = xr.apply_ufunc(stats.norm.ppf, clipped, 0.0, 1.0,  \n",
    "                           input_core_dims=[[], [], []], output_core_dims=[[]],\n",
    "                           vectorize=True, dask=\"parallelized\",\n",
    "                           output_dtypes=[np.float64],\n",
    "                           keep_attrs=True\n",
    "    )\n",
    "    \n",
    "    accumulation_variables = {var: var.split(\"_\")[-1][:-1] for var in adjusted_spi_ds.variables if \"accum\" in var}  # Get periods as number strings\n",
    "    rename_variables = {var: f\"{\"SPI\"}{accumulation_period}\" for var, accumulation_period in accumulation_variables.items()}\n",
    "    \n",
    "    return adjusted_spi_ds.rename_vars(rename_variables)\n",
    "\n",
    "adjusted_spi_ds = cdf_to_spi_transform(adjusted_cdf_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Importing ERA5-Drought SPI data from dataset for comparison.\n",
    "Data request must be \"weaved\" as request too big for entire time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_dataset = \"derived-drought-historical-monthly\"\n",
    "\n",
    "spi_request1 = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"1\",\n",
    "        \"3\",\n",
    "        \"6\",\n",
    "        \"12\",\n",
    "        \"24\",\n",
    "        \"36\",\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1940\", \"1941\", \"1942\",\n",
    "        \"1943\", \"1944\", \"1945\",\n",
    "        \"1946\", \"1947\", \"1948\",\n",
    "        \"1949\", \"1950\", \"1951\",\n",
    "        \"1952\", \"1953\", \"1954\",\n",
    "        \"1955\", \"1956\", \"1957\",\n",
    "        \"1958\", \"1959\", \"1960\",\n",
    "        \"1961\", \"1962\", \"1963\",\n",
    "        \"1964\", \"1965\", \"1966\",\n",
    "        \"1967\", \"1968\", \"1969\",\n",
    "        \"1970\", \"1971\", \"1972\",\n",
    "        \"1973\", \"1974\", \"1975\",\n",
    "        \"1976\", \"1977\", \"1978\",\n",
    "        \"1979\", \"1980\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\": [9.45, 40.25, 8.95, 40.75]\n",
    "}\n",
    "\n",
    "spi_request2 = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"1\",\n",
    "        \"3\",\n",
    "        \"6\",\n",
    "        \"12\",\n",
    "        \"24\",\n",
    "        \"36\",\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1981\", \"1982\", \"1983\",\n",
    "        \"1984\", \"1985\", \"1986\",\n",
    "        \"1987\", \"1988\", \"1989\",\n",
    "        \"1990\", \"1991\", \"1992\",\n",
    "        \"1993\", \"1994\", \"1995\",\n",
    "        \"1996\", \"1997\", \"1998\",\n",
    "        \"1999\", \"2000\", \"2001\",\n",
    "        \"2002\", \"2003\", \"2004\",\n",
    "        \"2005\", \"2006\", \"2007\",\n",
    "        \"2008\", \"2009\", \"2010\",\n",
    "        \"2011\", \"2012\", \"2013\",\n",
    "        \"2014\", \"2015\", \"2016\",\n",
    "        \"2017\", \"2018\", \"2019\",\n",
    "        \"2020\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\": [9.45, 40.25, 8.95, 40.75] # Ethiopia\n",
    "}\n",
    "\n",
    "era5_drought_spi = ekd.from_source(\"cds\", drought_dataset, spi_request1, spi_request2) # Sends request for this dataset to CDS.\n",
    "era5_drought_spi = era5_drought_spi.to_xarray(compat=\"equals\") # Converts to xarray.\n",
    "era5_drought_spi = era5_drought_spi.sel(lat=9.25,lon=40.5, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "#### Comparison of the calculated SPI-index vs ERA5-Drought SPI-index (qualatitive)\n",
    "Now that we have calculated the SPI-index for one grid point, for all accumulation windows, we make a qualatitive and quantitative comparison with the corresponding data in the ERA5-Drought dataset. \n",
    "\n",
    "First, we plot the timeseries of the SPI drought index, calculated and from the derived dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey=True, constrained_layout=True)\n",
    "fig.suptitle('ERA5-Drought SPI vs Calculated SPI for varying windows.', fontsize=16)\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for position, period in enumerate(ACCUMULATION_PERIODS):\n",
    "    ax = axs[position]\n",
    "\n",
    "    # Plot ERA5 drought SPI\n",
    "    ax.plot(era5_drought_spi[f\"SPI{period}\"].time,\n",
    "            era5_drought_spi[f\"SPI{period}\"],\n",
    "            label=f\"ERA5_Drought-SPI{period}\",\n",
    "            color=\"tab:blue\")\n",
    "\n",
    "    # Plot calculated SPI\n",
    "    ax.plot(adjusted_spi_ds[f\"SPI{period}\"].valid_time,\n",
    "            adjusted_spi_ds[f\"SPI{period}\"],\n",
    "            label=f\"Calculated SPI{period}\",\n",
    "            color=\"tab:orange\")\n",
    "\n",
    "    # Title for each subplot\n",
    "    ax.sharex(axs[0])\n",
    "    ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('SPI')    \n",
    "    ax.grid(True)\n",
    "\n",
    "# Remove unused axes\n",
    "for i in range(len(ACCUMULATION_PERIODS), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "#### Comparison of the calculated SPI-index vs ERA5-Drought SPI-index (quantative- plot of residuals & frequency histogram).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual  = adjusted_spi_ds_focus[f\"SPI1\"] - era5_drought_spi[f\"SPI1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_spi_ds_focus = adjusted_spi_ds.rename({\n",
    "    \"valid_time\": \"time\",\n",
    "    \"latitude\": \"lat\",\n",
    "    \"longitude\": \"lon\",\n",
    "}) # for alignment\n",
    "\n",
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey=False, constrained_layout=True)\n",
    "fig.suptitle('Residual SPI for varying windows.', fontsize=16)\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for position, period in enumerate(ACCUMULATION_PERIODS):\n",
    "    ax = axs[position]\n",
    "    # Plot residual between ERA5-SPI & Calculated-SPI\n",
    "    ax.plot(residual.time,\n",
    "            residual,\n",
    "            label=f\"Residual-SPI{period}\",\n",
    "            color=\"tab:blue\")\n",
    "\n",
    "    # Title for each subplot\n",
    "    ax.sharex(axs[0])\n",
    "    ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Residual SPI')    \n",
    "    ax.grid(True)\n",
    "    # ax.set_ylim([-1e-5, 1e-5])\n",
    "\n",
    "# Remove unused axes\n",
    "for i in range(len(ACCUMULATION_PERIODS), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_spi_ds_focus = adjusted_spi_ds.rename({\n",
    "    \"valid_time\": \"time\",\n",
    "    \"latitude\": \"lat\",\n",
    "    \"longitude\": \"lon\",\n",
    "}) # for alignment\n",
    "\n",
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=False, sharey=False, constrained_layout=True)\n",
    "fig.suptitle('Residual SPI for varying windows.', fontsize=16)\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for position, period in enumerate(accum_periods):\n",
    "    ax = axs[position]\n",
    "    \n",
    "    residual  = adjusted_spi_ds_focus[f\"SPI_{period}m\"] - era5_drought_spi[f\"SPI{period}\"]\n",
    "    \n",
    "    vals = (residual.values).ravel() \n",
    "    \n",
    "    finite_mask = np.isfinite(vals)\n",
    "    \n",
    "    vals = vals[finite_mask]\n",
    "\n",
    "    count = vals.size\n",
    "    mean_val = np.nanmean(vals)\n",
    "    std_val = np.nanstd(vals)\n",
    "\n",
    "    freq, bin_edges = np.histogram(vals, bins=20)\n",
    "    rel_freq = freq / count\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Plot relative frequency histogram\n",
    "    ax.bar(bin_centers, rel_freq, width=(bin_edges[1] - bin_edges[0]))\n",
    "    \n",
    "    ax.annotate(\n",
    "            f\"Mean residual - SPI {period}: {mean_val: .7f}\\n Std residual- SPI {period}: {std_val: .7f}\",\n",
    "            xy=(0.02, 0.95), xycoords=\"axes fraction\",  # position in axes coords\n",
    "            fontsize=10,\n",
    "            ha=\"left\", va=\"top\",\n",
    "        )\n",
    "    \n",
    "    # Title for each subplot\n",
    "    ax.sharex(axs[0])\n",
    "    ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "    ax.set_xlabel('Residual SPI')\n",
    "    ax.set_ylabel('Frequency')    \n",
    "    ax.grid(True)\n",
    "    \n",
    "# Remove unused axes\n",
    "for i in range(len(accum_periods), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "####  6. Comparison of Probability of Zero Precipitation to that from ERA5-Drought dataset.\n",
    "You can also import the \"probability of zero precipitation\" for a given calendar month, in the reference period, per accumulation period instead of calculating it as we have done. \n",
    "\n",
    "Due to improper formatting from ERA5-Drought, you are unable to send an API request to download the data for all accumulation periods at once. If you try to do so, you will find that your xarray only contains the data for the last accumulation period (in this case, the 48-month window). \n",
    "\n",
    "We have written a simple helper function, \"era5_api_multiple\" that sends separate API requests, concatenating the data into a single xarray, to then use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_spi_zero_all = era5_drought_api_multiple(indicator = \"spi\", var = \"prob_zero\")\n",
    "prob_spi_zero_all_ds = prob_spi_zero_all.sel(lat=9.25,lon=40.5, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_zero_diff = prob_spi_zero_all_ds.groupby('time.month') - stats_sum[\"Zero-Precip Count\"]\n",
    "cond =  (prob_zero_diff != 0).compute()\n",
    "mis_match = prob_zero_diff.where(cond, drop=True)\n",
    "mis_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "#### 7. Quality control using the Shapiro-Wilks test on calculated SPI data.\n",
    "Quality control is performed by the ERA5-Drought team over the entire dataset. This is done by testing if the calculated distribution of the estimated drought indices over the reference period follows a normal distribution with mean 0 and standard deviation 1. \n",
    "\n",
    "This test is performed using the Shapiro-Wilks test for normality [S. S. SHAPIRO, M. B. WILK, An analysis of variance test for normality (complete samples), Biometrika, Volume 52, Issue 3-4, December 1965, Pages 591â€“611](https://doi.org/10.1093/biomet/52.3-4.591), with a $\\alpha$ = 0.05 on the data in the reference period (1991-2020). \n",
    "\n",
    "If the resultant p-value is less than $\\alpha$ = 0.05, the corresponding quality parameter is set to 0 (bad), otherwise set to 1 (good)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### We perform this test over the calculated SPI values, that are adjusted for zero-precipitation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pval, sig = xr_shapiro_test(adjusted_spi_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Importing Shapiro-Wilks SPI Significance Test results from ERA5-Drought dataset.\n",
    "You can also import the quality flags from ERA5-Drought, for every calendar month, in the reference period, per accumulation period. \n",
    "\n",
    "Due to improper formatting from ERA5-Drought, you are unable to send an API request to download this data for all accumulation periods at once. If you try to do so, you will find that your xarray only contains the data for the last accumulation period (in this case, the 48-month window). \n",
    "\n",
    "We have written a simple script that sends separate API requests, concatenating the data into a single xarray, to then use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_spi_all = era5_drought_api_multiple(indicator = \"spi\", var = \"quality\")\n",
    "quality_spi_all = quality_spi_all.sel(lat=9.25, lon = 40.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Comparison of significance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_diff = quality_spi_all.groupby('time.month') - sig\n",
    "cond =  (sig_diff != 0).compute()\n",
    "# Does cond have any True anywhere?\n",
    "any_true = cond.any().compute()   # -> bool\n",
    "\n",
    "if not any_true:\n",
    "    print(\"Values from ERA5 Significance match calculated significance values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "#### Calculating ERA5-Drought SPI (across a region)\n",
    "Repeat calculations here but very quickly (i.e. just follow the steps from before but without all the steps and plots in between)\n",
    "All functions should be written so that they can take data with only one (lat, lon) point as before or the entire dataset at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Accumulate precipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_periods = [48]\n",
    "\n",
    "# Select latitude and longitude box (keeping small for smaller compute time, recommended 10 x 10)\n",
    "lon_min, lon_max = 19.0, 21.5   \n",
    "lat_min, lat_max = 41.0, 43.5\n",
    "\n",
    "# Subset (latitude is descending in ERA5)\n",
    "ds_loc = era5_monthly_mean_reanal.sel(\n",
    "    latitude=slice(lat_max, lat_min),\n",
    "    longitude=slice(lon_min, lon_max),\n",
    ")\n",
    "\n",
    "ds_loc = accum_var(ds_loc, var = \"tp\")\n",
    "\n",
    "precipitation_example_site_reference = ds_loc.sel(**reference_window) # select only reference precipitation window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Fit gamma distribution onto site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fitted = fit_monthly_spi(precipitation_example_site_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Calculate SPI over region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_example_site_entire = ds_loc.sel(**entire_window) # select only reference precipitation window.\n",
    "cdf_ds, spi_ds = compute_monthly_spi(precipitation_example_site_entire, params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Adjust for zero precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_cdf_ds, stats_sum = zero_precip_monthly_xr(precipitation_example_site_entire, cdf_ds, reference_window) # takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_spi_ds = cdf_to_spi_transform(adjusted_cdf_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"derived-drought-historical-monthly\"\n",
    "\n",
    "request1 = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1940\", \"1941\", \"1942\",\n",
    "        \"1943\", \"1944\", \"1945\",\n",
    "        \"1946\", \"1947\", \"1948\",\n",
    "        \"1949\", \"1950\", \"1951\",\n",
    "        \"1952\", \"1953\", \"1954\",\n",
    "        \"1955\", \"1956\", \"1957\",\n",
    "        \"1958\", \"1959\", \"1960\",\n",
    "        \"1961\", \"1962\", \"1963\",\n",
    "        \"1964\", \"1965\", \"1966\",\n",
    "        \"1967\", \"1968\", \"1969\",\n",
    "        \"1970\", \"1971\", \"1972\",\n",
    "        \"1973\", \"1974\", \"1975\",\n",
    "        \"1976\", \"1977\", \"1978\",\n",
    "        \"1979\", \"1980\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ], \n",
    "    \"area\": [43.5, 19.0, 41.0, 21.5]  # lat, lon \n",
    "}\n",
    "\n",
    "request2 = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1981\", \"1982\", \"1983\",\n",
    "        \"1984\", \"1985\", \"1986\",\n",
    "        \"1987\", \"1988\", \"1989\",\n",
    "        \"1990\", \"1991\", \"1992\",\n",
    "        \"1993\", \"1994\", \"1995\",\n",
    "        \"1996\", \"1997\", \"1998\",\n",
    "        \"1999\", \"2000\", \"2001\",\n",
    "        \"2002\", \"2003\", \"2004\",\n",
    "        \"2005\", \"2006\", \"2007\",\n",
    "        \"2008\", \"2009\", \"2010\",\n",
    "        \"2011\", \"2012\", \"2013\",\n",
    "        \"2014\", \"2015\", \"2016\",\n",
    "        \"2017\", \"2018\", \"2019\",\n",
    "        \"2020\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\": [43.5, 19.0, 41.0, 21.5] # lat, lon \n",
    "}\n",
    "\n",
    "era5_spi = ekd.from_source(\"cds\", dataset, request1,request2) # Sends request for this dataset to CDS.\n",
    "era5_spi = era5_spi.to_xarray(compat=\"equals\") # Converts to xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_spi_ds = adjusted_spi_ds.rename({\n",
    "    \"valid_time\": \"time\",\n",
    "    \"latitude\": \"lat\",\n",
    "    \"longitude\": \"lon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_drought, adjusted_spi_ds = xr.align(spi_drought, adjusted_spi_ds, join=\"left\")   # only overlapping coords\n",
    "# spi_diff_mean = spi_diff.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_diff_mean = abs(adjusted_spi_ds[\"SPI48\"]-spi_drought[\"SPI48\"]).mean(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_diff = abs(adjusted_spi_ds[\"SPI48\"]-spi_drought[\"SPI48\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one time slice and one ensemble\n",
    "from earthkit.plots.styles import Style\n",
    "from earthkit.plots.geo import domains\n",
    "\n",
    "global_mean_map = spi_diff\n",
    "\n",
    "balkans = domains.Domain.from_bbox(\n",
    "    bbox=[15, 25, 36, 47],\n",
    "    name=\"Balkans\",\n",
    ")\n",
    "# Convert to NumPy arrays\n",
    "\n",
    "mean_values = global_mean_map.to_numpy()\n",
    "lat_values = global_mean_map.lat.to_numpy()\n",
    "lon_values = global_mean_map.lon.to_numpy()\n",
    " \n",
    "# Create meshgrid\n",
    "\n",
    "lon_grid, lat_grid = np.meshgrid(lon_values, lat_values)\n",
    " \n",
    "# # Plot with EarthKit\n",
    "\n",
    "SPI_STYLE = Style(cmap='viridis', vmin = -0.1, vmax = 0.1, normalize=False)\n",
    "\n",
    "# Create figure with 2 columns\n",
    "fig = ekp.Figure(rows=1, columns=1, size=(12, 6))  \n",
    "\n",
    "# First subplot (left)\n",
    "subplot = fig.add_map(domain=balkans, row=0, column=0)\n",
    "subplot.grid_cells(mean_values, x=lon_grid, y=lat_grid,style=SPI_STYLE)\n",
    "subplot.legend(location=\"right\")\n",
    "\n",
    "# Add decorations\n",
    "fig.title(\"ERA5 - Calculated SPI\")\n",
    "fig.land()\n",
    "fig.coastlines()\n",
    "fig.borders()\n",
    "fig.gridlines()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-3)=\n",
    "###  3. Calculating ERA5-Drought SPEI from reanalysis data.\n",
    "The steps to calculating the SPEI-index are exactly the same as calculating the SPI index, with the only modification being that the SPEI integrates both the precipitation and potential evapotranspiration (PET) data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 0. Importing monthly-average potential evaporation data.\n",
    "\n",
    "We import the monthly-mean potential evaporation data from the \"ERA5 monthly-averaged data on single levels from 1940 to present\" dataset.(https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-monthly-means?tab=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_pev_moda = {\n",
    "    \"param\": \"251.228\",       # Variable: Potential evaporation (pev)\n",
    "    \"stream\": \"moda\",         # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and convert to desired format\n",
    "era5_monthly_mean_pev_reanal = ekd.from_source(\"cds\", ID_ERA5, request_era5_pev_moda)  # Download as field list\n",
    "era5_monthly_mean_pev_reanal = era5_monthly_mean_pev_reanal.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "era5_monthly_mean_pev_reanal = rechunk(era5_monthly_mean_pev_reanal)  # Re-chunk for speed gain in fitting\n",
    "era5_monthly_mean_pev_reanal  # Display in notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. Calculate moving average for different accumulation periods (PET/PEV & TP).\n",
    "\n",
    "A time series of both precipitation & potential evaporation (PET/PEV) from one grid point are extracted and the precipitation & potential evaporation are accumulated over the previous $n$ months using a moving window, analogous to the SPI.\n",
    "\n",
    "Note, [ECMWF convention](https://codes.ecmwf.int/grib/param-db/182) is that negative values for PEV/PET indicate evaporation, whereas positive values indicate condensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the grid point and time slice for Ethiopia\n",
    "pev_example_site = era5_monthly_mean_pev_reanal.sel(**example_site)\n",
    "\n",
    "# Perform the accumulation for each accumulation period\n",
    "pev_example_site = accum_var(pev_example_site, \"pev\")\n",
    "\n",
    "# Display result\n",
    "pev_example_site\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for p in ACCUMULATION_PERIODS:\n",
    "    var_name = f'pev_mm_accum_{p}m'\n",
    "    plt.plot(pev_example_site['valid_time'].values, pev_example_site[var_name].values, label=f'{p}-month')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Potential Evaporation Accumulation at (9.25Â°N, 40.5Â°E)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PEV (mm)')\n",
    "plt.legend(title='Accumulation Period')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_ds = xr.Dataset(\n",
    "    {\n",
    "        f\"wb_{var.replace('tp_', '')}\": precipitation_example_site[var]\n",
    "                                       + pev_example_site[var.replace(\"tp_\", \"pev_\")]\n",
    "        for var in precipitation_example_site.data_vars # loop through every variable.\n",
    "        if var.startswith(\"tp_\") and var.replace(\"tp_\", \"pev_\") in pev_example_site.data_vars\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot of the accumulated water balance (P-PET).\n",
    "Since the ECMWF convention is that a negative value of PET indicates evaporation, care must be taken when subtracting the precipitation by the potential evaporation (PEV/PET).\n",
    "\n",
    "The negative of PEV/PET must be applied, meaning that $P âˆ’ (âˆ’PET) = P + PET$ in this case. \n",
    "\n",
    "This approach aligns with the definition of the water balance, where a negative water balance value indicates that more water is potentially being transferred to the atmosphere. It also makes sense when interpreting the accumulated plots of both potential evaporation and water balance in a country like Ethiopia (below), where one might expect more evaporation and in fact has a negative water balance (as is the case).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for p in ACCUMULATION_PERIODS:\n",
    "    var_name = f'wb_mm_accum_{p}m'\n",
    "    plt.plot(wb_ds['valid_time'].values, wb_ds[var_name].values, label=f'{p}-month')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Total Precipitation - (- Potential Evaporation) at (9.25Â°N, 40.5Â°E)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TP - PEV (mm)')\n",
    "plt.legend(title='Accumulation Period')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Fit Generalised Log-Logistic Distribution to PET.\n",
    "\n",
    "The general log-logistic distribution [reference] is fitted only to the data within the reference period (1991-2020), similar to the gamma distribution being fitted in the calculation of the SPI-index. A separate distribution is fitted for each calendar month per accumulation window.\n",
    "\n",
    "This fitting is done with the [scipy.stats.genlogistic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.genlogistic.html) object in Python. Three parameters are then outputted per calendar month, per accumulation period: the shape (), location () and scale () parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit log logistic distributions\n",
    "log_params_fitted = fit_monthly_spei(wb_ds.sel(**reference_window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. Compute SPEI series.\n",
    "\n",
    "Similar to the calculation for the SPI index, the three parameters from the fitted general log-logistic distribution are taken and the cumulative distribution function (CDF) is calculated up to the accumulated water balance, from the probability distribution function (PDF).\n",
    "\n",
    "As $ P âˆ’ PET $ is barely identical to 0, no modifications analogous to the SPI such as adjusting for zero precipitation, are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fitted = log_params_fitted.rename({v: v.replace(\"tp_\", \"wb_\")\n",
    "                                          for v in log_params_fitted.data_vars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SPI series\n",
    "cdf_spei_ds, spei_ds = compute_monthly_spei(wb_ds, params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Quality control using the Shapiro-Wilks test on calculated SPEI data.\n",
    "\n",
    "Shapiro-Wilks test is performed on the calculated SPEI index below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pval, sig = xr_shapiro_test(spei_ds.sel(**reference_window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "##### Importing Shapiro-Wilks SPI Significance Test results from ERA5-Drought dataset.\n",
    "Quality flags ar imported from ERA5-Drought, for every calendar month, in the reference period, per accumulation period for the SPEI index.\n",
    "\n",
    "Due to improper formatting from ERA5-Drought, you are unable to send an API request to download this data for all accumulation periods at once. If you try to do so, you will find that your xarray only contains the data for the last accumulation period (in this case, the 48-month window). \n",
    "\n",
    "We have written a simple script that sends separate API requests, concatenating the data into a single xarray, to then use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_spei_all = era5_drought_api_multiple(indicator = \"spei\", var = \"quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "##### Comparing Calculated Shapiro-Wilks SPI Significance Test with that from ERA5-Drought dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select quality flags at one location and compare that with dataset.\n",
    "quality_spei_all_ds = quality_spei_all.sel(lat=9.25,lon=40.5, method=\"nearest\")\n",
    "\n",
    "sig_diff = quality_spei_all_ds.groupby('time.month') - sig\n",
    "cond =  (sig_diff != 0).compute()\n",
    "# Does cond have any True anywhere?\n",
    "any_true = cond.any().compute()   # -> bool\n",
    "\n",
    "if not any_true:\n",
    "    print(\"Values from ERA5 Significance match calculated significance values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Comparison of the calculated SPEI-index vs ERA5-Drought SPEI-index (qualatitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"derived-drought-historical-monthly\"\n",
    "request1 = {\n",
    "    \"variable\": [\"standardised_precipitation_evapotranspiration_index\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"1\",\n",
    "        \"3\",\n",
    "        \"6\",\n",
    "        \"12\",\n",
    "        \"24\",\n",
    "        \"36\",\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1940\", \"1941\", \"1942\",\n",
    "        \"1943\", \"1944\", \"1945\",\n",
    "        \"1946\", \"1947\", \"1948\",\n",
    "        \"1949\", \"1950\", \"1951\",\n",
    "        \"1952\", \"1953\", \"1954\",\n",
    "        \"1955\", \"1956\", \"1957\",\n",
    "        \"1958\", \"1959\", \"1960\",\n",
    "        \"1961\", \"1962\", \"1963\",\n",
    "        \"1964\", \"1965\", \"1966\",\n",
    "        \"1967\", \"1968\", \"1969\",\n",
    "        \"1970\", \"1971\", \"1972\",\n",
    "        \"1973\", \"1974\", \"1975\",\n",
    "        \"1976\", \"1977\", \"1978\",\n",
    "        \"1979\", \"1980\", \"1981\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\": [9.45, 40.25, 8.95, 40.75]\n",
    "}\n",
    "\n",
    "request2 = {\n",
    "    \"variable\": [\"standardised_precipitation_evapotranspiration_index\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"1\",\n",
    "        \"3\",\n",
    "        \"6\",\n",
    "        \"12\",\n",
    "        \"24\",\n",
    "        \"36\",\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"reanalysis\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1982\", \"1983\", \"1984\",\n",
    "        \"1985\", \"1986\", \"1987\",\n",
    "        \"1988\", \"1989\", \"1990\",\n",
    "        \"1991\", \"1992\", \"1993\",\n",
    "        \"1994\", \"1995\", \"1996\",\n",
    "        \"1997\", \"1998\", \"1999\",\n",
    "        \"2000\", \"2001\", \"2002\",\n",
    "        \"2003\", \"2004\", \"2005\",\n",
    "        \"2006\", \"2007\", \"2008\",\n",
    "        \"2009\", \"2010\", \"2011\",\n",
    "        \"2012\", \"2013\", \"2014\",\n",
    "        \"2015\", \"2016\", \"2017\",\n",
    "        \"2018\", \"2019\", \"2020\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\": [9.45, 40.25, 8.95, 40.75]\n",
    "}\n",
    "\n",
    "data_spei = ekd.from_source(\"cds\", dataset, request1,request2) # Sends request for this dataset to CDS.\n",
    "data_spei = data_spei.to_xarray(compat=\"equals\") # Converts to xarray.\n",
    "data_spei = data_spei.sel(lat=9.25,lon=40.5, method=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey=True, constrained_layout=True)\n",
    "fig.suptitle('ERA5-Drought SPEI vs Calculated SPEI for varying windows.', fontsize=16)\n",
    "\n",
    "data_spei_focus, spei_ds_focus = xr.align(data_spei, spei_ds, join = \"override\")   # only overlapping coords\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for position, period in enumerate(ACCUMULATION_PERIODS):\n",
    "    ax = axs[position]\n",
    "\n",
    "    # Plot ERA5 drought SPI\n",
    "    ax.plot(data_spei_focus[f\"SPEI{period}\"].time,\n",
    "            data_spei_focus[f\"SPEI{period}\"],\n",
    "            label=f\"ERA5_Drought-SPEI{period}\",\n",
    "            color=\"tab:blue\")\n",
    "\n",
    "    # Plot calculated SPI\n",
    "    ax.plot(spei_ds[f\"SPEI{period}\"].valid_time,\n",
    "            spei_ds[f\"SPEI{period}\"],\n",
    "            label=f\"Calculated SPEI{period}\",\n",
    "            color=\"tab:orange\")\n",
    "\n",
    "    # Title for each subplot\n",
    "    ax.sharex(axs[0])\n",
    "    ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('SPEI')    \n",
    "    ax.grid(True)\n",
    "\n",
    "# Remove unused axes\n",
    "for i in range(len(accum_periods), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Comparison of the calculated SPEI-index vs ERA5-Drought SPEI-index (quantatitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_periods = [1, 3, 6, 12, 24, 36, 48]\n",
    "\n",
    "spei_ds_focus = spei_ds.rename({\n",
    "    \"valid_time\": \"time\",\n",
    "    \"latitude\": \"lat\",\n",
    "    \"longitude\": \"lon\",\n",
    "}) # for alignment\n",
    "\n",
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey=False, constrained_layout=True)\n",
    "fig.suptitle('Residual SPEI for varying windows.', fontsize=16)\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for position, period in enumerate(accum_periods):\n",
    "    ax = axs[position]\n",
    "    residual  = spei_ds_focus[f\"SPEI{period}\"] - data_spei_focus[f\"SPEI{period}\"]\n",
    "    # Plot residual between ERA5-SPI & Calculated-SPI\n",
    "    ax.plot(residual.time,\n",
    "            residual,\n",
    "            label=f\"Residual-SPEI\",\n",
    "            color=\"tab:blue\")\n",
    "\n",
    "    # Title for each subplot\n",
    "    ax.sharex(axs[0])\n",
    "    ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Residual SPEI')    \n",
    "    ax.grid(True)\n",
    "    # ax.set_ylim([-1e-5, 1e-5])\n",
    "\n",
    "# Remove unused axes\n",
    "for i in range(len(accum_periods), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Comparison of the calculated SPEI-index vs ERA5-Drought SPEI-index with quality flags (quantatitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_periods = [1, 3, 6, 12, 24, 36, 48]\n",
    "\n",
    "for period in accum_periods:\n",
    "    drought_spi = data_spei_focus[f\"SPEI{period}\"].copy()\n",
    "    calc_spi = spei_ds_focus[f\"SPEI{period}\"].copy() # copy so it doesn't change.\n",
    "    \n",
    "    for month in range(1,13):        \n",
    "        significance = quality_spei_all_ds[f\"significance_{period}\"].sel(time=f\"2020-{month:02d}-01\").compute().item()\n",
    "        if significance == 0:\n",
    "            drought_spi = drought_spi.where(drought_spi.time.dt.month != month, other=np.nan) # keeps EVERY other month- the selected one becomes nan. \n",
    "            calc_spi = calc_spi.where(calc_spi.time.dt.month != month, other=np.nan)\n",
    "        else:\n",
    "            pass \n",
    "    \n",
    "    data_spei_focus[f\"SPEI{period}\"] = drought_spi # bring it back.\n",
    "    adjusted_spi_ds[f\"SPEI{period}\"] = calc_spi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_periods = [1, 3, 6, 12, 24, 36, 48]\n",
    "\n",
    "# data_spei_focus, spei_ds_focus = xr.align(data_spei_focus, spei_ds_focus, join = \"override\")   # only overlapping coords\n",
    "\n",
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey=False, constrained_layout=True)\n",
    "fig.suptitle('Residual SPEI for varying windows w/ quality flags.', fontsize=16)\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for position, period in enumerate(accum_periods):\n",
    "    ax = axs[position]\n",
    "    residual  = adjusted_spi_ds[f\"SPEI{period}\"] - data_spei_focus[f\"SPEI{period}\"]\n",
    "    # Plot residual between ERA5-SPI & Calculated-SPI\n",
    "    ax.plot(residual.time,\n",
    "            residual,\n",
    "            label=f\"Residual-SPEI\",\n",
    "            color=\"tab:blue\")\n",
    "\n",
    "    # Title for each subplot\n",
    "    ax.sharex(axs[0])\n",
    "    ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Residual SPEI')    \n",
    "    ax.grid(True)\n",
    "    # ax.set_ylim([-1e-5, 1e-5])\n",
    "\n",
    "# Remove unused axes\n",
    "for i in range(len(accum_periods), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.245188,
     "end_time": "2024-03-08T17:39:21.277354",
     "exception": false,
     "start_time": "2024-03-08T17:39:21.032166",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-4)=\n",
    "### 4. Calculating the SPI/SPEI Ensemble Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Reading in ensemble precipitation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_ERA5 = \"reanalysis-era5-complete\"\n",
    "\n",
    "request_era5_template = {\n",
    "    \"class\": \"ea\",            # Default for ERA5\n",
    "    # Dates: ERA5 takes these in the format 19400101/19400201/.../20241101/20241201\n",
    "    # The following line generates a string in said format from the chosen year range\n",
    "    \"date\": \"/\".join(f\"{year}{month:02}01\"\n",
    "            for year in range(years[0] ,years[1]+1)\n",
    "            for month in MONTHS),\n",
    "    \"expver\": \"1\",            # ERA5 consolidated data\n",
    "    \"levtype\": \"sfc\",         # Surface\n",
    "    \"grid\": \"0.25/0.25\",      # Grid: 0.25Â° by 0.25Â°\n",
    "    \"type\": \"fc\",             # Forecast\n",
    "    \"data_format\": \"netcdf\",  # NetCDF data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_precipitation_edmo = {\n",
    "    \"param\": \"228.128\",       # Variable: Total precipitation\n",
    "    \"stream\": \"edmo\",         # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_precipitation_edmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and convert to desired format\n",
    "era5_monthly_mean_ens = ekd.from_source(\"cds\", ID_ERA5, request_era5_precipitation_edmo)  # Download as field list\n",
    "era5_monthly_mean_ens = era5_monthly_mean_ens.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "era5_tp_monthly_mean_ens = rechunk(era5_monthly_mean_ens)  # Re-chunk for speed gain in fitting\n",
    "era5_tp_monthly_mean_ens  # Display in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Reading in ensemble potential evaporation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5_pev_edmo = {\n",
    "    \"param\": \"251.228\",       # Variable: Potential evaporation (pev)\n",
    "    \"stream\": \"edmo\",         # Data stream: Monthly mean reanalysis\n",
    "} | request_era5_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data and convert to desired format\n",
    "era5_pev_monthly_mean_ens = ekd.from_source(\"cds\", ID_ERA5, request_era5_pev_edmo)  # Download as field list\n",
    "era5_pev_monthly_mean_ens = era5_pev_monthly_mean_ens.to_xarray(compat=\"equals\")  # Convert to xarray dataset\n",
    "era5_pev_monthly_mean_ens = rechunk(era5_pev_monthly_mean_ens)  # Re-chunk for speed gain in fitting\n",
    "era5_pev_monthly_mean_ens  # Display in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Accumulate precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_site = {\"latitude\": 9.25, \"longitude\": 40.5,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the grid point and time slice for Ethiopia\n",
    "precipitation_example_site = era5_tp_monthly_mean_ens.sel(**example_site)\n",
    "\n",
    "# Perform the accumulation for each accumulation period\n",
    "precipitation_ens_example_site = accum_var(precipitation_example_site, \"tp\")\n",
    "\n",
    "# Display result\n",
    "precipitation_ens_example_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Accumulate potential evaporation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the grid point and time slice for Ethiopia\n",
    "pev_example_site = era5_pev_monthly_mean_ens.sel(**example_site)\n",
    "\n",
    "# Perform the accumulation for each accumulation period\n",
    "pev_ens_example_site = accum_var(pev_example_site, \"pev\")\n",
    "\n",
    "# Display result\n",
    "pev_ens_example_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Calculate the water balance (P - PET)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_ens_example_site = xr.Dataset(\n",
    "    {\n",
    "        f\"wb_{var.replace('tp_', '')}\": precipitation_ens_example_site[var]\n",
    "                                       + pev_ens_example_site[var.replace(\"tp_\", \"pev_\")]\n",
    "        for var in precipitation_ens_example_site.data_vars # loop through every variable.\n",
    "        if var.startswith(\"tp_\") and var.replace(\"tp_\", \"pev_\") in pev_ens_example_site.data_vars\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_ens_example_site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fit gamma distribution to ensemble precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit log logistic distributions\n",
    "gamma_ens_params_fitted = fit_monthly_spi(precipitation_ens_example_site.sel(**reference_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_ens_params_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fit log-logistic distribution to water balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_logistic_ens_params_fitted = fit_monthly_spei(wb_ens_example_site.sel(**reference_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_logistic_ens_params_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {},
   "source": [
    "#### Calculate SPI ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SPI series -- new function\n",
    "cdf_ens_ds, spi_ens_ds = compute_monthly_spi(precipitation_ens_example_site, gamma_ens_params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "#### Calculate SPEI ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SPEI series -- new function\n",
    "cdf_wb_ens_ds, spei_ens_ds = compute_monthly_spei(wb_ens_example_site, log_logistic_ens_params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Quality control using the Shapiro-Wilks test on calculated ensemble SPI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_spi_stat, ens_spi_pval, ens_spi_sig = xr_shapiro_test(spi_ens_ds.sel(**reference_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"derived-drought-historical-monthly\"\n",
    "request = {\n",
    "    \"variable\": [\"test_for_normality_spi\"],\n",
    "    \"accumulation_period\": [\n",
    "        \"1\",\n",
    "        \"3\",\n",
    "        \"6\",\n",
    "        \"12\",\n",
    "        \"24\",\n",
    "        \"36\",\n",
    "        \"48\"\n",
    "    ],\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"ensemble_members\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Quality control using the Shapiro-Wilks test on calculated ensemble SPEI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_spei_stat, ens_spei_pval, ens_spei_sig = xr_shapiro_test(spei_ens_ds.sel(**reference_window))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147",
   "metadata": {},
   "source": [
    "#### Reading in ensemble SPI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_ens_dataset = \"derived-drought-historical-monthly\"\n",
    "spi_ens_request = {\n",
    "    \"variable\": [\"standardised_precipitation_index\"],\n",
    "    \"accumulation_period\": [\"1\", \"12\", \"48\"], # 1 is also already downloaded.\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"ensemble_members\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1940\", \"1941\", \"1942\",\n",
    "        \"1943\", \"1944\", \"1945\",\n",
    "        \"1946\", \"1947\", \"1948\",\n",
    "        \"1949\", \"1950\", \"1951\",\n",
    "        \"1952\", \"1953\", \"1954\",\n",
    "        \"1955\", \"1956\", \"1957\",\n",
    "        \"1958\", \"1959\", \"1960\",\n",
    "        \"1961\", \"1962\", \"1963\",\n",
    "        \"1964\", \"1965\", \"1966\",\n",
    "        \"1967\", \"1968\", \"1969\",\n",
    "        \"1970\", \"1971\", \"1972\",\n",
    "        \"1973\", \"1974\", \"1975\",\n",
    "        \"1976\", \"1977\", \"1978\",\n",
    "        \"1979\", \"1980\", \"1981\",\n",
    "        \"1982\", \"1983\", \"1984\",\n",
    "        \"1985\", \"1986\", \"1987\",\n",
    "        \"1988\", \"1989\", \"1990\",\n",
    "        \"1991\", \"1992\", \"1993\",\n",
    "        \"1994\", \"1995\", \"1996\",\n",
    "        \"1997\", \"1998\", \"1999\",\n",
    "        \"2000\", \"2001\", \"2002\",\n",
    "        \"2003\", \"2004\", \"2005\",\n",
    "        \"2006\", \"2007\", \"2008\",\n",
    "        \"2009\", \"2010\", \"2011\",\n",
    "        \"2012\", \"2013\", \"2014\",\n",
    "        \"2015\", \"2016\", \"2017\",\n",
    "        \"2018\", \"2019\", \"2020\",\n",
    "        \"2021\", \"2022\", \"2023\",\n",
    "        \"2024\", \"2025\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\":[10, 40, 9, 41]\n",
    "}\n",
    "\n",
    "point_drought_ens_ = ekd.from_source(\"cds\", spi_ens_dataset, spi_ens_request) # Sends request for this dataset to CDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_drought_ens_ = point_drought_ens_.to_xarray(\n",
    "    compat=\"override\",\n",
    "    combine=\"nested\",     # <- key: disable by-coords alignment\n",
    "    concat_dim=\"time\",    # <- key: explicit concat dimension\n",
    "    coords=\"minimal\",\n",
    "    data_vars=\"minimal\",\n",
    "    join=\"override\",      # avoids reindex conflicts\n",
    "    parallel=False\n",
    ")\n",
    "\n",
    "point_drought_ens_ = point_drought_ens_.sel(lat = 9.25, lon = 40.5) # note there are duplicate timestamps. each one is a ensemble member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ens(dataset, no_ens = 10):\n",
    "    _, index = np.unique(dataset['time'], return_index=True)\n",
    "    \n",
    "    ens_dataset = []\n",
    "    \n",
    "    for i in range(1,no_ens+1):\n",
    "        ens_member = dataset.isel(time = index + i)    \n",
    "        ens_dataset.append(ens_member)\n",
    "        \n",
    "    drought_ens = xr.concat(ens_dataset, dim=\"number\")\n",
    "    drought_ens = drought_ens.assign_coords(number=np.arange(1,11))  # or 1..10 if you prefer\n",
    "\n",
    "    return drought_ens\n",
    "    \n",
    "spi_ens = create_ens(point_drought_ens_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_ens_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_ens_ds = spi_ens_ds.assign_coords({\"number\": (spi_ens_ds.number + 1)} ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual  = spi_ens_ds[f\"SPI1\"] - spi_ens[f\"SPI1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_ens_ds[\"number\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156",
   "metadata": {},
   "source": [
    "#### Time-series comparison of SPI at one location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both datasets use the same time coordinate name\n",
    "# (Choose either to rename; here I rename spi_ens_ds.valid_time -> time)\n",
    "# spi_ens_ds = spi_ens_ds.rename({\"valid_time\": \"time\"})\n",
    "\n",
    "\n",
    "ACCUMULATION_PERIODS_focus = [1, 12, 48]\n",
    "\n",
    "# Create a 4x2 grid of subplots\n",
    "fig, axs = plt.subplots(4, 2, figsize=(16, 12), sharex=True, sharey=True, constrained_layout=True)\n",
    "fig.suptitle('ERA5-Drought SPI-Ensemble vs Calculated SPI-Ensemble for varying windows.', fontsize=16)\n",
    "\n",
    "# Flatten axs for easy indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "for m in range(1,5):\n",
    "    calculated = spi_ens_ds.sel(number=m)\n",
    "    era5 = spi_ens.sel(number=m)\n",
    "    for position, period in enumerate(ACCUMULATION_PERIODS_focus):\n",
    "        ax = axs[position]\n",
    "\n",
    "        var = f\"SPI{period}\"  # minimal change: pick the variable for this window\n",
    "\n",
    "        # Plot ERA5 drought SPI (DataArray)\n",
    "        ax.plot(era5[\"time\"].values,\n",
    "                era5.values,\n",
    "                label=f\"ERA5_Drought-SPI{period}\",\n",
    "                color=\"tab:blue\",\n",
    "                alpha=0.8)\n",
    "\n",
    "        # Plot calculated SPI (DataArray)\n",
    "        ax.plot(calculated.values,\n",
    "                calculated.values,\n",
    "                label=f\"Calculated SPI{period}\",\n",
    "                color=\"tab:orange\",\n",
    "                alpha=0.8)\n",
    "\n",
    "        # Title for each subplot\n",
    "        ax.set_title(f\"{period}-Month Window\", fontsize=10)\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('SPI')\n",
    "        ax.grid(True)\n",
    "\n",
    "# Remove unused axes\n",
    "for i in range(len(accum_periods), len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_PERIODS_focus = [1, 12, 48]  # choose the periods you want\n",
    "\n",
    "# Loop over each ensemble member and make one figure per member\n",
    "for m in range(1, 11):  # 1..10 members\n",
    "    calculated = spi_ens_ds.sel(number=m)\n",
    "    era5 = spi_ens.sel(number=m)\n",
    "\n",
    "    # Create a grid of subplots for the selected periods (here: 3 periods â†’ 2x2 to leave one empty)\n",
    "    nrows, ncols = 2, 2  # adjust if you change number of periods\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(12, 8), sharex=True, sharey=True, constrained_layout=True)\n",
    "    fig.suptitle(f'ERA5-Drought vs Calculated SPI â€” Member {m}', fontsize=16)\n",
    "\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for position, period in enumerate(ACCUMULATION_PERIODS_focus):\n",
    "        ax = axs[position]\n",
    "        var = f\"SPI{period}\"\n",
    "\n",
    "        # Select the DataArray for this period and sort by time\n",
    "        # (Assumes both have coord named \"time\"; otherwise rename once above)\n",
    "        era5_da = era5[var].sortby(\"time\")\n",
    "        calc_da = calculated[var].sortby(\"time\")\n",
    "\n",
    "        # Plot ERA5\n",
    "        ax.plot(\n",
    "            era5_da[\"time\"].values,\n",
    "            era5_da.values,\n",
    "            label=f\"ERA5_Drought-SPI{period}\",\n",
    "            color=\"tab:blue\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Plot Calculated\n",
    "        ax.plot(\n",
    "            calc_da[\"time\"].values,\n",
    "            calc_da.values,\n",
    "            label=f\"Calculated SPI{period}\",\n",
    "            color=\"tab:orange\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        # Titles & axes\n",
    "        ax.set_title(f\"{period}-Month Window\", fontsize=11)\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"SPI\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Remove any unused axes (e.g., if 3 periods in a 2x2 grid)\n",
    "    for i in range(len(ACCUMULATION_PERIODS_focus), len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    # Build a single legend per figure (deduplicate handles)\n",
    "    handles, labels = [], []\n",
    "    for ax in axs[:len(ACCUMULATION_PERIODS_focus)]:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        for hh, ll in zip(h, l):\n",
    "            if ll not in labels:\n",
    "                handles.append(hh)\n",
    "                labels.append(ll)\n",
    "\n",
    "    fig.legend(handles, labels, loc=\"upper left\", ncol=2, frameon=True)\n",
    "\n",
    "    # Optionally save each member's figure\n",
    "    # fig.savefig(f\"spi_era5_vs_calc_member_{m}.png\", dpi=200)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Reading in ensemble SPEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_ens_dataset = \"derived-drought-historical-monthly\"\n",
    "spi_ens_request = {\n",
    "    \"variable\": [\"standardised_precipitation_evaporation_index\"],\n",
    "    \"accumulation_period\": [\"1\", \"12\", \"48\"], # 1 is also already downloaded.\n",
    "    \"version\": \"1_0\",\n",
    "    \"product_type\": [\"ensemble_members\"],\n",
    "    \"dataset_type\": \"consolidated_dataset\",\n",
    "    \"year\": [\n",
    "        \"1940\", \"1941\", \"1942\",\n",
    "        \"1943\", \"1944\", \"1945\",\n",
    "        \"1946\", \"1947\", \"1948\",\n",
    "        \"1949\", \"1950\", \"1951\",\n",
    "        \"1952\", \"1953\", \"1954\",\n",
    "        \"1955\", \"1956\", \"1957\",\n",
    "        \"1958\", \"1959\", \"1960\",\n",
    "        \"1961\", \"1962\", \"1963\",\n",
    "        \"1964\", \"1965\", \"1966\",\n",
    "        \"1967\", \"1968\", \"1969\",\n",
    "        \"1970\", \"1971\", \"1972\",\n",
    "        \"1973\", \"1974\", \"1975\",\n",
    "        \"1976\", \"1977\", \"1978\",\n",
    "        \"1979\", \"1980\", \"1981\",\n",
    "        \"1982\", \"1983\", \"1984\",\n",
    "        \"1985\", \"1986\", \"1987\",\n",
    "        \"1988\", \"1989\", \"1990\",\n",
    "        \"1991\", \"1992\", \"1993\",\n",
    "        \"1994\", \"1995\", \"1996\",\n",
    "        \"1997\", \"1998\", \"1999\",\n",
    "        \"2000\", \"2001\", \"2002\",\n",
    "        \"2003\", \"2004\", \"2005\",\n",
    "        \"2006\", \"2007\", \"2008\",\n",
    "        \"2009\", \"2010\", \"2011\",\n",
    "        \"2012\", \"2013\", \"2014\",\n",
    "        \"2015\", \"2016\", \"2017\",\n",
    "        \"2018\", \"2019\", \"2020\",\n",
    "        \"2021\", \"2022\", \"2023\",\n",
    "        \"2024\", \"2025\"\n",
    "    ],\n",
    "    \"month\": [\n",
    "        \"01\", \"02\", \"03\",\n",
    "        \"04\", \"05\", \"06\",\n",
    "        \"07\", \"08\", \"09\",\n",
    "        \"10\", \"11\", \"12\"\n",
    "    ],\n",
    "    \"area\":[10, 40, 9, 41]\n",
    "}\n",
    "\n",
    "point_drought_ens_ = ekd.from_source(\"cds\", spi_ens_dataset, spi_ens_request) # Sends request for this dataset to CDS.\n",
    "point_drought_ens_ = point_drought_ens_.to_xarray(compat=\"equals\") # Converts to xarray.\n",
    "point_drought_ens_ = point_drought_ens_.sel(lat = 9.25, lon = 40.5) # note there are duplicate timestamps. each one is a ensemble member."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Selecting drought index from ensemble at one location (lon=9.5, lat = 40.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_drought_ens_ = point_drought_ens_.sel(lon = 9.5, lat = 40.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ensemble(da, time_dim=\"time\", member_dim=\"member\"):\n",
    "    times = pd.Index(da[time_dim].values)\n",
    "    member_ids = pd.Series(times).groupby(times).cumcount().to_numpy()\n",
    "    \n",
    "    # Create MultiIndex\n",
    "    mi = pd.MultiIndex.from_arrays([times, member_ids], names=[time_dim, member_dim])\n",
    "    \n",
    "    # Assign MultiIndex and rename the dimension to something temporary\n",
    "    da = da.rename({time_dim: \"tmp\"}).assign_coords(tmp=mi)\n",
    "    \n",
    "    # Unstack to get (time, member)\n",
    "    return da.unstack()\n",
    "\n",
    "ens = make_ensemble(point_drought_ens_[\"SPI1\"])  # or pass the whole Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## â„¹ï¸ If you want to know more\n",
    "\n",
    "### Key resources\n",
    "The CDS catalogue entries for the data used were:\n",
    "* Complete ERA5 global atmospheric reanalysis: [reanalysis-era5-complete](https://doi.org/10.24381/cds.143582cf)\n",
    "* Monthly drought indices from 1940 to present derived from ERA5 reanalysis: [derived-drought-historical-monthly](https://doi.org/10.24381/9bea5e16)\n",
    "\n",
    "Code libraries used:\n",
    "* [earthkit](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-data](https://github.com/ecmwf/earthkit-data)\n",
    "  * [earthkit-plots](https://github.com/ecmwf/earthkit-plots)\n",
    "\n",
    "### References\n",
    "\n",
    "List the references used in the Notebook here.\n",
    "\n",
    "E.g.\n",
    "\n",
    "[[1]](https://doi.org/10.1038/s41598-018-20628-2) Rodriguez, D., De Voil, P., Hudson, D., Brown, J. N., Hayman, P., Marrou, H., & Meinke, H. (2018). Predicting optimum crop designs using crop models and seasonal climate forecasts. Scientific reports, 8(1), 2231."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
