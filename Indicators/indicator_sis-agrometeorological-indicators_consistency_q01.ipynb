{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Validation and intercomparison of AgERA5 and other reanalysis datasets for agricultural applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Production date: DD-MM-2025\n",
    "\n",
    "**Please note that this repository is used for development and review, so quality assessments should be considered work in progress until they are merged into the main branch.**\n",
    "\n",
    "Dataset version: 2.0.\n",
    "\n",
    "Produced by: C3S2_521 contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üåç Use case: Agricultural yield estimation and prediction based on reanalysis data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## ‚ùì Quality assessment question\n",
    "* Is AgERA5 fit-for-purpose as an input dataset for crop yield models?\n",
    "* How do reanalysis datasets compare to observations, and to each other, for agriculturally relevant variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Introduction:\n",
    "\n",
    "* Introduction to crop yield estimation -> [PCSE/WOFOST](https://github.com/ajwdewit/pcse) [[deWit+19]](https://doi.org/10.1016/j.agsy.2018.06.018).\n",
    "* AgERA5 dataset, reanalysis in general\n",
    "* Validation of datasets\n",
    "\n",
    "[[CDS AgERA5]](https://doi.org/10.24381/cds.6c68c9bb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üì¢ Quality assessment statement\n",
    "\n",
    "```{admonition} These are the key outcomes of this assessment\n",
    ":class: note\n",
    "* Finding 1\n",
    "* Finding 2\n",
    "* Finding 3\n",
    "* etc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üìã Methodology\n",
    "\n",
    "**Agrometeorological indicators from 1979 to present derived from reanalysis** (*AgERA5*; [doi 10.24381/cds.6c68c9bb](https://doi.org/10.24381/cds.6c68c9bb)).\n",
    "\n",
    "A ‚Äòfree text‚Äô introduction to the data analysis steps or a description of the literature synthesis, with a justification of the approach taken, and limitations mentioned. **Mention which CDS catalogue entry is used, including a link, and also any other entries used for the assessment**.\n",
    "\n",
    "Variables of interest for a crop growth simulator such as [PCSE/WOFOST](https://github.com/ajwdewit/pcse):\n",
    "\n",
    "| Variable name     | Statistic (24h) | Unit     | Example assessment |\n",
    "|-------------------|-----------------|----------|--------------------|\n",
    "| Solar irradiation | Total           | J/m¬≤/day | example |\n",
    "| Temperature (2m)  | Minimum         | ¬∞C       | example |\n",
    "|                   | Maximum         |          |         |\n",
    "|                   | Mean            |          |         |\n",
    "| Vapour pressure   | Mean            | kPa      | example |\n",
    "| Rain              | Total           | cm/day   | example |\n",
    "| Wind speed (2m)   | Mean            | m/s      | example |\n",
    "| Snow depth        | Mean            | cm       | example |\n",
    "\n",
    "[Source](https://pcse.readthedocs.io/en/stable/code.html#pcse.base.WeatherDataContainer)\n",
    "E0, ES0, ET0 are taken from evapotranspiration calculation\n",
    "\n",
    "The analysis and results are organised in the following steps, which are detailed in the sections below:\n",
    "\n",
    "**[](section-setup)**\n",
    "\n",
    "**[](section-download)**\n",
    " * AgERA5, ERA5-Land, E-OBS, ...\n",
    "\n",
    "**[](section-results)** \n",
    " * Point-by-point comparison\n",
    " * Time series comparison\n",
    " * Geospatial comparison\n",
    "\n",
    "Any further notes on the method could go here (explanations, caveats or limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## üìà Analysis and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-setup)=\n",
    "### 1. Code setup\n",
    "#### Imports\n",
    "```{note}\n",
    "This notebook uses [earthkit](https://github.com/ecmwf/earthkit) for \n",
    "downloading ([earthkit-data](https://github.com/ecmwf/earthkit-data)) \n",
    "and \n",
    "visualising ([earthkit-plots](https://github.com/ecmwf/earthkit-plots)) data.\n",
    "Because earthkit is in active development, some functionality may change after this notebook is published.\n",
    "If any part of the code stops functioning, please raise an issue on our GitHub repository so it can be fixed.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Earthkit\n",
    "import earthkit.data as ekd\n",
    "import earthkit.plots as ekp\n",
    "\n",
    "# General data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Visualisation\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type hints for helper functions\n",
    "from typing import Callable, Optional, Iterable\n",
    "\n",
    "# For pre-defining functions\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data (pre-)processing\n",
    "# Unit conversion\n",
    "def convert_unit(dataset: xr.Dataset, key: str, conversion: Callable, new_unit: str) -> None:\n",
    "    \"\"\" Convert the units of dataset[key] to new_unit using a conversion function (e.g. lambda x: x*1000 for m to mm), in-place. \"\"\"\n",
    "    # Metadata handling\n",
    "    metadata_old = dataset[key].attrs\n",
    "    metadata_new = metadata_old | {\"units\": new_unit}\n",
    "\n",
    "    # Apply changes\n",
    "    dataset[key] = conversion(dataset[key]).assign_attrs(**metadata_new)\n",
    "\n",
    "convert_m2cm = partial(convert_unit, conversion=(lambda x: x*100), new_unit=\"cm\")  # meter -> centimeter\n",
    "convert_m2mm = partial(convert_unit, conversion=(lambda x: x*1000), new_unit=\"cm\")  # meter -> millimeter\n",
    "convert_K2C = partial(convert_unit, conversion=(lambda x: x-273.15), new_unit=\"¬∞C\")  # Kelvin -> Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display\n",
    "# Labels\n",
    "def label_with_unit(data: xr.Dataset, key: str, *, latex=False) -> str:\n",
    "    \"\"\" Extract the full name with unit for a key in a dataset. \"\"\"\n",
    "    long_name = data[key].long_name\n",
    "    unit = data[key].units\n",
    "    if latex:\n",
    "        unit = ekp.metadata.units.format_units(data[key].units)\n",
    "    return f\"{long_name} [{unit}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistics\n",
    "# pd.set_option(\"display.precision\", 2)  # Display 2 decimals in Pandas tables by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting functions\n",
    "# Colour maps\n",
    "def find_percentile(*data_arrays: Iterable[xr.DataArray], percentile: float, round: str=None) -> float:\n",
    "    \"\"\"\n",
    "    Find the specified percentile across all of the provided datasets.\n",
    "    Used for making consistent colour maps.\n",
    "    \"\"\"\n",
    "    data_flat = np.concatenate([arr.to_numpy().ravel() for arr in data_arrays])\n",
    "    perc = np.nanpercentile(data_flat, percentile)\n",
    "    if round == \"up\":\n",
    "        perc = np.ceil(perc)\n",
    "    elif round == \"down\":\n",
    "        perc = np.floor(perc)\n",
    "    return perc\n",
    "\n",
    "cmap_percentile = 0.5\n",
    "find_vmin = partial(find_percentile, percentile=cmap_percentile)\n",
    "find_vmax = partial(find_percentile, percentile=100-cmap_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "(section-download)=\n",
    "### 2. Download data\n",
    "#### General setup\n",
    "This notebook uses [earthkit-data](https://github.com/ecmwf/earthkit-data) to download files from the CDS.\n",
    "If you intend to run this notebook multiple times, it is highly recommended that you [enable caching](https://earthkit-data.readthedocs.io/en/latest/guide/caching.html) to prevent having to download the same files multiple times.\n",
    "\n",
    "We will be downloading multiple datasets in this notebook.\n",
    "In this section, we define the parameters common to all datasets: time and space.\n",
    "This way, these only need to be changed in one place if you wish to modify the notebook for your own use case.\n",
    "\n",
    "In this example, we will be looking at data for the United Kingdom and Ireland every day in January‚ÄìSeptember 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_domain = {\n",
    "    \"area\": [60, -12, 48, 4]  # North, West, South, East\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_time = {\n",
    "    \"year\": \"2023\",\n",
    "    \"month\": [f\"{mo:02}\" for mo in range(1, 10)],\n",
    "    \"day\": [f\"{d:02}\" for d in range(1, 32)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We can define a helper function that adds the time and domain parameters, as well as a dictionary of parameters specific to one dataset (e.g. AgERA5, ERA5-Land), to a number of requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_request(request_dataset: dict, *requests: dict) -> dict:\n",
    "    \"\"\" Combine default requests (time + domain) with a dataset-specific default request (request_dataset) and any number of individual (e.g. variable-specific) requests. \"\"\"\n",
    "    base_request = request_time | request_domain | request_dataset\n",
    "    updated_requests = [base_request | req for req in requests]\n",
    "    return updated_requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### AgERA5\n",
    "We now define parameters unique to AgERA5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "agera5_ID = \"sis-agrometeorological-indicators\"\n",
    "\n",
    "request_agera5 = {\n",
    "    \"version\": \"2_0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Next, we specify the variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_irradiation = {\n",
    "    \"variable\": \"solar_radiation_flux\",\n",
    "}\n",
    "\n",
    "# Temperature has to be split into separate requests because of size limits\n",
    "request_temperature_min = {\n",
    "    \"variable\": \"2m_temperature\",\n",
    "    \"statistic\": [\"24_hour_minimum\"],\n",
    "}\n",
    "\n",
    "request_temperature_max = {\n",
    "    \"variable\": \"2m_temperature\",\n",
    "    \"statistic\": [\"24_hour_maximum\"],\n",
    "}\n",
    "\n",
    "request_temperature_mean = {\n",
    "    \"variable\": \"2m_temperature\",\n",
    "    \"statistic\": [\"24_hour_mean\"],\n",
    "}\n",
    "\n",
    "request_rain = {\n",
    "    \"variable\": \"precipitation_flux\",\n",
    "}\n",
    "\n",
    "request_wind = {\n",
    "    \"variable\": \"10m_wind_speed\",\n",
    "    \"statistic\": [\"24_hour_mean\"],\n",
    "}\n",
    "\n",
    "request_snow = {\n",
    "    \"variable\": \"snow_thickness\",\n",
    "    \"statistic\": [\"24_hour_mean\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The requests for specific variables are combined with the default, time, and domain parameters and passed to earthkit for download from the CDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_agera5_combined = make_full_request(request_agera5,\n",
    "                                             request_irradiation,\n",
    "                                             request_temperature_min, request_temperature_max, request_temperature_mean,\n",
    "                                             request_rain,\n",
    "                                             request_wind,\n",
    "                                             request_snow,\n",
    "                                            )\n",
    "\n",
    "ds_agera5 = ekd.from_source(\"cds\", agera5_ID, *requests_agera5_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Earthkit-data downloads the dataset as a [field list](https://earthkit-data.readthedocs.io/en/latest/guide/data.html), which can be manipulated directly.\n",
    "Here, we convert it to an Xarray object for ease of use later (when comparing multiple datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AgERA5 data type from earthkit-data:\", type(ds_agera5))\n",
    "data_agera5 = ds_agera5.to_xarray(compat=\"equals\")\n",
    "print(\"AgERA5 data type in Xarray:\", type(data_agera5))\n",
    "data_agera5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Finally, let us pre-define a consistent order for the variables, for use in the [results section](section-results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"Temperature_Air_2m_Min_24h\", \"Temperature_Air_2m_Mean_24h\", \"Temperature_Air_2m_Max_24h\", \n",
    "             \"Solar_Radiation_Flux\", \n",
    "             \"Wind_Speed_10m_Mean_24h\",\n",
    "             \"Precipitation_Flux\",\n",
    "             \"Snow_Thickness_Mean_24h\"\n",
    "            ]\n",
    "\n",
    "# For plotting:\n",
    "nvars = len(variables)\n",
    "nvars_half = int(np.ceil(nvars / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### ERA5-Land\n",
    "We now define parameters unique to ERA5-Land and the variables of interest.\n",
    "This will involve two CDS datasets.\n",
    "The [*ERA5-Land hourly data from 1950 to present*](https://doi.org/10.24381/cds.e2161bac) dataset contains hourly data for variables like 2m temperature as well as accumulated data for variables like solar irradiation.\n",
    "For the present use case, we are only interested in the daily accumulated data.\n",
    "[*ERA5-Land post-processed daily statistics from 1950 to present*](https://doi.org/10.24381/cds.e9c9c792) provides daily minimum/maximum/mean statistics for the hourly variables, saving us the effort of aggregating these ourselves.\n",
    "In the following subsections, we will download the data (accumulated and daily statistics) and harmonise these to the same format as AgERA5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "##### Accumulated data from ERA5-Land\n",
    "Per the [documentation for ERA5-Land](https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation#heading-Accumulations):\n",
    "The accumulations in the short forecasts of ERA5-Land (with hourly steps from 01 to 24) are treated the same as those in ERA-Interim or ERA-Interim/Land, i.e., they are accumulated from the beginning of the forecast to the end of the forecast step. For example, runoff at day=D, step=12 will provide runoff accumulated from day=D, time=0 to day=D, time=12. The maximum accumulation is over 24 hours, i.e., from day=D, time=0 to day=D+1,time=0 (step=24). For the CDS time, or validity time, of 00 UTC, the accumulations are over the 24 hours ending at 00 UTC i.e. the accumulation is during the previous day.\n",
    "\n",
    "In practice, this means that we need to download data for *day+1* (e.g. 2 January 2024) to get the total accumulated value for *day* (1 January 2024).\n",
    "Our existing `request_time` will provide data for 2023-12-31 ‚Äì 2024-09-29, so we need to add one extra day.\n",
    "This is achieved by adding a second request for just the last day to the earthkit-data download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5land_ID = \"reanalysis-era5-land\"\n",
    "\n",
    "request_era5land = {\n",
    "    \"time\": [\"00:00\"],\n",
    "    \"data_format\": \"grib\",\n",
    "    \"download_format\": \"unarchived\",\n",
    "}\n",
    "\n",
    "request_era5land_extratime = {\n",
    "    \"month\": \"10\",\n",
    "    \"day\": \"01\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_irradation = {\n",
    "    \"variable\": [\"surface_solar_radiation_downwards\"],\n",
    "}\n",
    "\n",
    "request_rain = {\n",
    "    \"variable\": [\"total_precipitation\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_era5land_irradiation, request_era5land_rain = make_full_request(request_era5land,\n",
    "                                                                        request_irradation,\n",
    "                                                                        request_rain,\n",
    "                                                                       )\n",
    "\n",
    "ds_era5land_accumulated = ekd.from_source(\"cds\", era5land_ID, request_era5land_irradiation, request_era5land_irradiation | request_era5land_extratime,\n",
    "                                                              request_era5land_rain, request_era5land_rain | request_era5land_extratime)\n",
    "data_era5land_accumulated = ds_era5land_accumulated.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "When we inspect the resulting dataset (in Xarray format), we see that the `forecast_reference_time` coordinate conveniently matches the variable to the day of accumulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land_accumulated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "##### Daily statistics from the post-processed ERA5-Land dataset\n",
    "The daily statistics are indexed according to the day they apply to, meaning we do not need to worry about adding extra days here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5land_ID = \"derived-era5-land-daily-statistics\"\n",
    "\n",
    "request_era5land = {\n",
    "    \"time_zone\": \"utc+00:00\",\n",
    "    \"frequency\": \"1_hourly\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature has to be split into separate requests because of size limits\n",
    "request_temperature_min = {\n",
    "    \"variable\": \"2m_temperature\",\n",
    "    \"daily_statistic\": \"daily_minimum\",\n",
    "}\n",
    "\n",
    "request_temperature_max = {\n",
    "    \"variable\": \"2m_temperature\",\n",
    "    \"daily_statistic\": [\"daily_maximum\"],\n",
    "}\n",
    "\n",
    "request_temperature_mean = {\n",
    "    \"variable\": \"2m_temperature\",\n",
    "    \"daily_statistic\": [\"daily_mean\"],\n",
    "}\n",
    "\n",
    "# request_vapour_pressure : Not available\n",
    "\n",
    "request_wind_u = {\n",
    "    \"variable\": \"10m_u_component_of_wind\",\n",
    "    \"daily_statistic\": [\"daily_mean\"],\n",
    "}\n",
    "\n",
    "request_wind_v = {\n",
    "    \"variable\": \"10m_v_component_of_wind\",\n",
    "    \"daily_statistic\": [\"daily_mean\"],\n",
    "}\n",
    "\n",
    "request_snow = {\n",
    "    \"variable\": \"snow_depth\",\n",
    "    \"daily_statistic\": [\"daily_mean\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "We download the different variables separately in anticipation of the harmonisation step in the next subsection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_era5land_combined = make_full_request(request_era5land,\n",
    "                                               request_temperature_min, request_temperature_max, request_temperature_mean,\n",
    "                                               request_wind_u, request_wind_v,\n",
    "                                               request_snow,\n",
    "                                              )\n",
    "\n",
    "ds_era5land = [ekd.from_source(\"cds\", era5land_ID, req) for req in requests_era5land_combined]\n",
    "data_era5land = [ds.to_xarray() for ds in ds_era5land]\n",
    "data_era5land_temperature_min, data_era5land_temperature_max, data_era5land_temperature_mean, data_era5land_wind_u, data_era5land_wind_v, data_era5land_snow = data_era5land"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "##### Harmonisation\n",
    "The ERA5-Land dataset is structured differently from AgERA5 and requires some processing before the two can be intercompared.\n",
    "This involves renaming coordinates and variables, and adjusting units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "For the accumulated data, we need to rename the variables and coordinates to match those in AgERA5, and convert the units for precipitation to mm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land_accumulated = data_era5land_accumulated.rename({\"ssrd\": \"Solar_Radiation_Flux\",\n",
    "                                                              \"tp\": \"Precipitation_Flux\",\n",
    "                                                              \"forecast_reference_time\": \"time\", \n",
    "                                                              \"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "\n",
    "convert_m2mm(data_era5land_accumulated, \"Precipitation_Flux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "The temperature statistics are downloaded as simply `t2m`.\n",
    "These need to be renamed before they can be combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land_temperature_min = data_era5land_temperature_min.rename({\"t2m\": \"Temperature_Air_2m_Min_24h\"})\n",
    "data_era5land_temperature_max = data_era5land_temperature_max.rename({\"t2m\": \"Temperature_Air_2m_Max_24h\"})\n",
    "data_era5land_temperature_mean = data_era5land_temperature_mean.rename({\"t2m\": \"Temperature_Air_2m_Mean_24h\"})\n",
    "data_era5land_temperature = xr.merge([data_era5land_temperature_min, data_era5land_temperature_max, data_era5land_temperature_mean], compat=\"equals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "The 10 m wind speed is calculated from the two variables representing its U (east‚Äìwest) and V (north‚Äìsouth) components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land_wind = xr.merge([data_era5land_wind_u, data_era5land_wind_v], compat=\"equals\")\n",
    "data_era5land_wind = data_era5land_wind.assign(\n",
    "    {\"Wind_Speed_10m_Mean_24h\": xr.ufuncs.sqrt(data_era5land_wind[\"u10\"]**2 + data_era5land_wind[\"v10\"]**2)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Lastly, we rename the snow variable and change its unit to match AgERA5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land_snow = data_era5land_snow.rename({\"sde\": \"Snow_Thickness_Mean_24h\"})\n",
    "convert_m2cm(data_era5land_snow, \"Snow_Thickness_Mean_24h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "Now we can combine the pre-processed variables into a single Xarray dataset.\n",
    "We also rename the coordinates to match AgERA5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land = xr.merge([data_era5land_temperature, data_era5land_wind, data_era5land_snow], compat=\"equals\")\n",
    "data_era5land = data_era5land.rename({\"valid_time\": \"time\", \"latitude\": \"lat\", \"longitude\": \"lon\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "Lastly, we combine the pre-processed and accumulated variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_era5land = xr.merge([data_era5land_accumulated, data_era5land], compat=\"equals\")\n",
    "data_era5land"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### E-OBS\n",
    "We now define parameters unique to E-OBS and the variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_ID = \"insitu-gridded-observations-europe\"\n",
    "request_eobs = {\n",
    "    \"product_type\": \"ensemble_mean\",\n",
    "    \"variable\": [\n",
    "        \"mean_temperature\",\n",
    "        \"minimum_temperature\",\n",
    "        \"maximum_temperature\",\n",
    "        \"precipitation_amount\",\n",
    "        \"surface_shortwave_downwelling_radiation\",\n",
    "        \"wind_speed\"\n",
    "    ],\n",
    "    \"grid_resolution\": \"0_1deg\",\n",
    "    \"period\": \"2011_2024\",\n",
    "    \"version\": [\"30_0e\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eobs = ekd.from_source(\"cds\", eobs_ID, request_eobs | request_domain)\n",
    "data_eobs = ds_eobs.to_xarray(compat=\"equals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs_ID = \"insitu-gridded-observations-europe\"\n",
    "request_eobs = {\n",
    "    \"product_type\": \"ensemble_mean\",\n",
    "    \"variable\": [\n",
    "        \"mean_temperature\",\n",
    "    ],\n",
    "    \"grid_resolution\": \"0_1deg\",\n",
    "    \"period\": \"2011_2024\",\n",
    "    \"version\": [\"30_0e\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do individually to avoid xr error?\n",
    "ds_eobs = ekd.from_source(\"cds\", eobs_ID, request_eobs | request_domain)\n",
    "data_eobs = ds_eobs.to_xarray(compat=\"equals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Rename variables and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "#### General harmonisation\n",
    "##### Grid alignment\n",
    "Before the data can be analysed, we must make sure their coordinates are aligned equally.\n",
    "All of the datasets used here are provided on a regular 0.1¬∞ by 0.1¬∞ grid, so no regridding is necessary.\n",
    "However, two steps need to be taken before the data can be compared directly:\n",
    "* Their representation as floating-point numbers can cause very small differences to appear, which do not reflect any real differences in the data but are difficult for software (in this case Xarray) to work with. Knowing that the data are on a regular 0.1¬∞ by 0.1¬∞ grid, we can simply round all of the coordinates to 2 digits to force them to be the same.\n",
    "* The bounds of the datasets (in space and in time) are slightly different and need to be aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [data_agera5, data_era5land]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round coordinates before alignment to avoid floating-point errors\n",
    "# Cannot be a dict-comp with coord in lat/lon because of symbol table issues\n",
    "d = 2\n",
    "round_mapping = {\"lat\": (lambda dataset: dataset[\"lat\"].round(d)),\n",
    "                 \"lon\": (lambda dataset: dataset[\"lon\"].round(d))}\n",
    "\n",
    "datasets_rounded = [dataset.assign_coords(round_mapping) for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align data using an inner join\n",
    "data_agera5, data_era5land, data_eobs = xr.align(*datasets_rounded, data_eobs, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "##### Units and variable names\n",
    "We also convert the temperatures from Kelvin to degrees Celsius, which are more commonly used in agricultural studies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_temperature = [f\"Temperature_Air_2m_{stat}_24h\" for stat in (\"Min\", \"Max\", \"Mean\")]\n",
    "for variable in variables_temperature:\n",
    "    convert_K2C(data_agera5, variable)\n",
    "    convert_K2C(data_era5land, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Lastly, we harmonise the variable \"long\" names and units, as stored in xarray metadata, to simplify the analysis steps and figures later on.\n",
    "This is not strictly necessary, but it is convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_metadata(data_array: xr.DataArray, **updates) -> xr.DataArray:\n",
    "    \"\"\" Adjust metadata using a new dictionary. Returns a new object. \"\"\"\n",
    "    metadata_old = data_array.attrs\n",
    "    metadata_new = metadata_old | updates\n",
    "    data_array = data_array.assign_attrs(**metadata_new)\n",
    "    return data_array\n",
    "\n",
    "def adjust_names(dataset: xr.Dataset, dataset_name: str) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Adjust the names and units of pre-defined variables in a dataset.\n",
    "    Also adds the name of the dataset to its attrs for easy acces.\n",
    "    \"\"\"\n",
    "    # Rename variables\n",
    "    dataset[\"Solar_Radiation_Flux\"] = adjust_metadata(dataset[\"Solar_Radiation_Flux\"], \n",
    "                                                      long_name=\"Surface solar radiation downwards\", units=\"J m-2 d-1\")\n",
    "    dataset[\"Temperature_Air_2m_Min_24h\"] = adjust_metadata(dataset[\"Temperature_Air_2m_Min_24h\"], \n",
    "                                                            long_name=\"Minimum air temperature\", units=\"¬∞C\")\n",
    "    dataset[\"Temperature_Air_2m_Mean_24h\"] = adjust_metadata(dataset[\"Temperature_Air_2m_Mean_24h\"], \n",
    "                                                            long_name=\"Mean air temperature\", units=\"¬∞C\")\n",
    "    dataset[\"Temperature_Air_2m_Max_24h\"] = adjust_metadata(dataset[\"Temperature_Air_2m_Max_24h\"], \n",
    "                                                            long_name=\"Maximum air temperature\", units=\"¬∞C\")\n",
    "    dataset[\"Wind_Speed_10m_Mean_24h\"] = adjust_metadata(dataset[\"Wind_Speed_10m_Mean_24h\"], \n",
    "                                                            long_name=\"Wind speed at 10m\", units=\"m s-1\")\n",
    "    dataset[\"Precipitation_Flux\"] = adjust_metadata(dataset[\"Precipitation_Flux\"], \n",
    "                                                            long_name=\"Total precipitation\", units=\"mm d-1\")\n",
    "    dataset[\"Snow_Thickness_Mean_24h\"] = adjust_metadata(dataset[\"Snow_Thickness_Mean_24h\"], \n",
    "                                                            long_name=\"Snow depth\", units=\"cm\")\n",
    "    \n",
    "    # Assign dataset name\n",
    "    dataset = dataset.assign_attrs({\"name\": dataset_name})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agera5 = adjust_names(data_agera5, \"AgERA5\")\n",
    "data_era5land = adjust_names(data_era5land, \"ERA5-Land\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.245188,
     "end_time": "2024-03-08T17:39:21.277354",
     "exception": false,
     "start_time": "2024-03-08T17:39:21.032166",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(section-results)=\n",
    "### 3. Results\n",
    "Describe what is done in this step/section and what the `code` in the cell does (if code is included). \n",
    "\n",
    "If this is the **results section**, we expect the final plots to be created here with a description of how to interpret them, and what information can be extracted for the specific use case and user question. The information in the 'quality assessment statement' should be derived here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "#### Point-by-point comparison\n",
    "Here, we compare the different variables 1-to-1 between the different datasets, across their entire spatial and temporal domain, to determine the typical differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "We start with a histogram of the 1-to-1 differences as well as the corresponding statistics: median absolute deviation (MAD), median bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = data_agera5 - data_era5land\n",
    "# Turn into function that (checks and?) preserves units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_by_variable(data: xr.Dataset, variables: Optional[Iterable[str]]) -> None:\n",
    "    \"\"\" Given a dataset, calculate a number of statistics for each variable and return the result in a table. \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = differences.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = p.agg([\"median\"]).rename({\"median\": \"Bias\"})\n",
    "mad = p.abs().agg([\"median\"]).rename({\"median\": \"MAD\"})\n",
    "\n",
    "stats = pd.concat([md, mad])\n",
    "stats = stats[variables].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.style \\\n",
    "     .format(precision=3)  \\\n",
    "     .set_caption(\"AgERA5 $-$ ERA5-Land\")  \\\n",
    "     .relabel_index([label_with_unit(data_agera5, var) for var in stats.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, axs = plt.subplots(nrows=nvars_half, ncols=2, figsize=(8, 8), layout=\"constrained\")\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Plot individual scatter plots\n",
    "for ax, var in zip(axs, variables):\n",
    "    diff = differences[var]\n",
    "\n",
    "    # Symmetric x axis\n",
    "    low, high = find_vmin(diff), find_vmax(diff)\n",
    "    lim = max(abs(low), abs(high))\n",
    "    bins = np.linspace(-lim, lim, 500)\n",
    "\n",
    "    # Plot differences\n",
    "    try:  # Account for missing variables\n",
    "        ax.hist(diff.values.ravel(),\n",
    "                bins=bins, color=\"black\")\n",
    "    except KeyError:\n",
    "        print(f\"KeyError: no variable `{var}` in one of the datasets\")\n",
    "\n",
    "    ax.set_xlabel(f\"$\\\\Delta$ {label_with_unit(data_agera5, var, latex=True)}\")\n",
    "    ax.set_xlim(-lim, lim)\n",
    "\n",
    "# Visual settings\n",
    "for ax in axs:\n",
    "    ax.grid(True, axis=\"both\", linestyle=\"--\")\n",
    "    ax.set_title(\"\")\n",
    "\n",
    "fig.suptitle(\"Distribution of differences: AgERA5 $-$ ERA5-Land\")\n",
    "\n",
    "# Show result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "We can use a scatter density plot to look for patterns in the 1-to-1 comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, axs = plt.subplots(nrows=nvars_half, ncols=2, figsize=(10, 20), layout=\"constrained\")\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Plot individual scatter plots\n",
    "for ax, var in zip(axs, variables):\n",
    "    try:  # Account for missing variables\n",
    "        ax.hexbin(data_agera5[var].values.ravel(), data_era5land[var].values.ravel(),\n",
    "                  gridsize=500, mincnt=1, cmap=\"cividis\")\n",
    "    except KeyError:\n",
    "        print(f\"KeyError: no variable `{var}` in one of the datasets\")\n",
    "\n",
    "    ax.text(0.05, 0.95, label_with_unit(data_agera5, var, latex=True), \n",
    "            horizontalalignment=\"left\", verticalalignment=\"top\", transform=ax.transAxes,\n",
    "            bbox={\"facecolor\": \"white\", \"edgecolor\": \"black\", \"alpha\": 1})\n",
    "\n",
    "# Visual settings\n",
    "for ax in axs:\n",
    "    ax.grid(True, axis=\"both\", linestyle=\"--\")\n",
    "    ax.set_aspect(\"equal\", \"box\")\n",
    "    ax.set_xlabel(data_agera5.name)\n",
    "    ax.set_ylabel(data_era5land.name)\n",
    "    ax.set_title(\"\")\n",
    "\n",
    "fig.suptitle(f\"Point-by-point comparison\")\n",
    "\n",
    "# Show result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "#### Time series comparison\n",
    "In this section, we compare time series from the various datasets at a few chosen sites.\n",
    "First, we define our test site(s) and select only the data at those locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = {\"lat\": 52.5, \"lon\": 0.0, \"method\": \"nearest\"}\n",
    "# Nearest is necessary because of floating-point errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_agera5 = data_agera5.sel(**selection)\n",
    "timeseries_era5land = data_era5land.sel(**selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "We now create a plot showing all variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series comparison statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, axs = plt.subplots(nrows=nvars, figsize=(10, 20), sharex=True, layout=\"constrained\")\n",
    "\n",
    "# Plot individual time series\n",
    "for j, timeseries in enumerate([timeseries_agera5, timeseries_era5land]):\n",
    "    for ax, var in zip(axs, variables):\n",
    "        try:  # Account for missing variables\n",
    "            timeseries[var].plot(ax=ax)\n",
    "        except KeyError:\n",
    "            print(f\"KeyError: no variable `{var}` in dataset {j}\")\n",
    "\n",
    "        ax.set_ylabel(label_with_unit(timeseries, var, latex=True))\n",
    "\n",
    "# Visual settings\n",
    "for ax in axs:\n",
    "    ax.grid(True, axis=\"both\", linestyle=\"-\")\n",
    "    ax.tick_params(\"x\", labelbottom=True)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_title(\"\")\n",
    "\n",
    "fig.suptitle(f\"Time series comparison at ({selection['lat']} ¬∞N, {selection['lon']} ¬∞E)\")\n",
    "\n",
    "# Show result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.007051,
     "end_time": "2024-03-08T17:23:56.492658",
     "exception": false,
     "start_time": "2024-03-08T17:23:56.485607",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Geospatial comparison\n",
    "In this section, we visually compare the datasets in space on a single day, using earthkit-plots.\n",
    "This requires a bit of setup, namely defining the domain (time, space, datasets) and defining some plot parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define domain for plot (time, space, datasets)\n",
    "date = f\"{request_time['year']}0101\"  # 1 January\n",
    "domain = ekp.geo.domains.union([\"United Kingdom\", \"Ireland\"], name=\"UK & Ireland\")\n",
    "datasets_singleday = [dataset.sel(time=date) for dataset in (data_agera5, data_era5land)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define styles for earthkit-plots\n",
    "# Temperature: Share between min/mean/max\n",
    "temperature_data = [dataset[key] for key in variables_temperature for dataset in datasets_singleday]\n",
    "temperature_vmin = find_vmin(*temperature_data, round=\"down\")\n",
    "temperature_vmax = find_vmax(*temperature_data, round=\"up\")\n",
    "style_temperature = ekp.styles.Style(\n",
    "    levels = np.arange(temperature_vmin, temperature_vmax+2, 2),\n",
    "    extend = \"both\",\n",
    ")\n",
    "\n",
    "# Surface radiation: Start at 0\n",
    "surface_radiation_data = [dataset[\"Solar_Radiation_Flux\"] for dataset in datasets_singleday]\n",
    "surface_radiation_vmax = find_vmax(*surface_radiation_data)\n",
    "style_surface_radiation = ekp.styles.Style(\n",
    "    levels = np.linspace(0, surface_radiation_vmax, 10),\n",
    "    extend = \"max\",\n",
    ")\n",
    "\n",
    "# Precipitation: Start at 0\n",
    "precipitation_data = [dataset[\"Precipitation_Flux\"] for dataset in datasets_singleday]\n",
    "precipitation_vmax = find_vmax(*precipitation_data, round=\"up\")\n",
    "style_precipitation = ekp.styles.Style(\n",
    "    levels = np.linspace(0, precipitation_vmax, 10),\n",
    "    extend = \"max\",\n",
    ")\n",
    "\n",
    "# Wind speed: Start at 0\n",
    "wind_data = [dataset[\"Wind_Speed_10m_Mean_24h\"] for dataset in datasets_singleday]\n",
    "wind_vmax = find_vmax(*wind_data, round=\"up\")\n",
    "style_wind = ekp.styles.Style(\n",
    "    levels = np.linspace(0, wind_vmax, 10),\n",
    "    extend = \"max\",\n",
    ")\n",
    "\n",
    "# Snow depth: Start at 0\n",
    "snow_data = [dataset[\"Snow_Thickness_Mean_24h\"] for dataset in datasets_singleday]\n",
    "snow_vmax = find_vmax(*snow_data, round=\"up\")\n",
    "style_snow = ekp.styles.Style(\n",
    "    levels = np.linspace(0, snow_vmax, 10),\n",
    "    extend = \"max\",\n",
    ")\n",
    "\n",
    "## Link styles to variable names\n",
    "style_dict = {\n",
    "    variable: style_temperature for variable in variables_temperature\n",
    "} | {  # Combine temperature variables (all the same) with others (all different)\n",
    "    \"Solar_Radiation_Flux\": style_surface_radiation,\n",
    "    \"Precipitation_Flux\": style_precipitation,\n",
    "    \"Wind_Speed_10m_Mean_24h\": style_wind,\n",
    "    \"Snow_Thickness_Mean_24h\": style_snow,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig = ekp.Figure(rows=nvars, columns=2, size=(10, 20))\n",
    "\n",
    "# Plot variables\n",
    "for row, variable in enumerate(variables):\n",
    "    # Get style from dictionary\n",
    "    style = style_dict[variable]\n",
    "\n",
    "    # Plot individual datasets\n",
    "    for col, dataset in enumerate(datasets_singleday):\n",
    "        subplot = fig.add_map(domain=domain)\n",
    "        try:  # Account for missing variables\n",
    "            subplot.grid_cells(dataset, z=variable, style=style)\n",
    "        except KeyError:\n",
    "            print(f\"KeyError: no variable `{variable}` in dataset {col}\")\n",
    "\n",
    "        # Text\n",
    "        ax = subplot.ax\n",
    "        ax.text(0.05, 0.95, f\"{dataset.name}: {variable}\", \n",
    "            horizontalalignment=\"left\", verticalalignment=\"top\", transform=ax.transAxes,\n",
    "            bbox={\"facecolor\": \"white\", \"edgecolor\": \"black\", \"alpha\": 1})\n",
    "\n",
    "# Decorate figures\n",
    "fig.land()\n",
    "fig.coastlines()\n",
    "fig.gridlines()\n",
    "fig.legend()\n",
    "fig.title(\"Geospatial intercomparison: {time:%-d %B %Y}\")\n",
    "\n",
    "# Show result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "Note that differences in snow thickness are highest in areas where you wouldn't generally have crops anyway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.271597,
     "end_time": "2024-03-08T17:40:01.664067",
     "exception": false,
     "start_time": "2024-03-08T17:40:01.392470",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## ‚ÑπÔ∏è If you want to know more\n",
    "\n",
    "### Key resources\n",
    "The CDS catalogue entries for the data used were:\n",
    "* Agrometeorological indicators from 1979 to present derived from reanalysis (AgERA5): [sis-agrometeorological-indicators](https://doi.org/10.24381/cds.6c68c9bb)\n",
    "* ERA5-Land hourly data from 1950 to present: [reanalysis-era5-land](https://doi.org/10.24381/cds.e2161bac)\n",
    "* ERA5-Land post-processed daily statistics from 1950 to present: [derived-era5-land-daily-statistics](https://doi.org/10.24381/cds.e9c9c792)\n",
    "\n",
    "Code libraries used:\n",
    "* [earthkit](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-data](https://github.com/ecmwf/earthkit)\n",
    "  * [earthkit-plots](https://github.com/ecmwf/earthkit-plots)\n",
    "\n",
    "More about crop yield estimation:\n",
    "* [A gentle introduction to WOFOST](https://www.wur.nl/en/show/a-gentle-introduction-to-wofost.htm)\n",
    "* [Crop yield prediction based on reanalysis and crop phenology data in the agroclimatic zones](https://doi.org/10.1007/s00704-024-05046-x)\n",
    "* [Historical trends and future projections of compound cloudy-rainy events during the global winter wheat harvest phase](https://doi.org/10.1016/j.agrformet.2025.110637)\n",
    "\n",
    "More about reanalysis data:\n",
    "* [The ERA5 global reanalysis](https://doi.org/10.1002/qj.3803)\n",
    "* [ERA5-Land: a state-of-the-art global reanalysis dataset for land applications](https://doi.org/10.5194/essd-13-4349-2021)\n",
    "* AgERA5\n",
    "  * [Algorithm Theoretical Basis (ATBD)](https://confluence.ecmwf.int/pages/viewpage.action?pageId=278550984)\n",
    "  * [Product User Guide and Specification (PUGS)](https://confluence.ecmwf.int/pages/viewpage.action?pageId=278551004)\n",
    "  * [Global Agriculture Downscaling and bias correction](https://confluence.ecmwf.int/display/CKB/Global+Agriculture+Downscaling+and+bias+correction)\n",
    "  * [AgERA5tools Python package](https://github.com/ajwdewit/agera5tools)\n",
    "\n",
    "Validation case studies for AgERA5:\n",
    "* [AgERA5, MERRA-2 in Guinea-Bissau](https://doi.org/10.3390/hydrology12070161)\n",
    "* [AgERA5, ERA5, CHIRP/CHIRPS, ENACTS, TAMSAT, PERSIANN-CDR/PERSIANN-CCS-CDR in Ghana and Zambia](https://doi.org/10.1007/s00704-025-05462-7)\n",
    "* [AgERA5, ERA5-Land, E-OBS, CHELSA-W5E5, MSWEP, CHIRPS05, IMERG V06 in Greece](https://doi.org/10.1016/j.atmosres.2024.107888)\n",
    "* [AgERA5, ERA5-Land, MERRA-2, PERSIANN-CDR in Peru](https://doi.org/10.1590/2318-0331.302520240068)\n",
    "* [AgERA5, CHIRPS, PERSIANN in Sri Lanka](https://doi.org/10.1109/MERCon63886.2024.10689062)\n",
    "\n",
    "### References\n",
    "[[CDS AgERA5]](https://doi.org/10.24381/cds.6c68c9bb) Boogaard, H., Schubert, J., De Wit, A., Lazebnik, J., Hutjes, R., Van der Grijn, G., (2020): Agrometeorological indicators from 1979 to present derived from reanalysis. Copernicus Climate Change Service (C3S) Climate Data Store (CDS). DOI: 10.24381/cds.6c68c9bb (Accessed on DD-MMM-YYYY)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 968.520731,
   "end_time": "2024-03-08T17:40:03.783430",
   "environment_variables": {},
   "exception": null,
   "input_path": "D520.3.2.3b.SEASONAL_multimodel-bias_v5.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T17:23:55.262699",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
